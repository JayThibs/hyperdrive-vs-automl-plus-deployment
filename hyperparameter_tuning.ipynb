{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/hyperdrive-vs-automl-plus-deployment/blob/main/hyperparameter_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tuning using HyperDrive"
      ],
      "metadata": {
        "id": "ab7AZwd-Wa9S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment and Import Dependencies\n",
        "\n",
        "Here we specify the conda dependencies."
      ],
      "metadata": {
        "id": "JCE-mKVP6sCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\n",
        "\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- pip=20.2.4\n",
        "- pip:\n",
        "    - azureml-defaults\n",
        "    - scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting conda_dependencies.yml\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "id": "7gDTnHm54LH8",
        "outputId": "f9437794-6fb5-4531-b890-32f59817b342"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "# Creating a conda environment for model training. It needs to be included in ScriptRunConfig.\n",
        "\n",
        "sklearn_env = Environment.from_conda_specification(name='sklearn_env', file_path='./conda_dependencies.yml')"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "npQZM5w74LH9",
        "gather": {
          "logged": 1617818547808
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.24.0\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "id": "nZbdttQy4Un6",
        "gather": {
          "logged": 1617818551233
        },
        "outputId": "2ae043eb-7509-4170-dfd8-a61955a8ec28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write Training File for our Hyperdrive Model"
      ],
      "metadata": {
        "id": "L-WUPuRAXfj9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train.py\n",
        "\n",
        "import pandas as pd\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "import argparse\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "from azureml.core.run import Run\n",
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "import datetime\n",
        "\n",
        "# Data Exploration was done in a notebook beforehand\n",
        "\n",
        "# def dates(X):\n",
        "#     \"\"\"\n",
        "#     date_recorded: this might be a useful variable for this analysis, although the year itself would be \n",
        "#     useless in a practical scenario moving into the future. We will convert this column into a datetime, \n",
        "#     and we will also create 'year_recorded' and 'month_recorded' columns just in case those levels prove \n",
        "#     to be useful. A visual inspection of both casts significant doubt on that possibility, but we'll proceed \n",
        "#     for now. We will delete date_recorded itself, since random forest cannot accept datetime\n",
        "#     \"\"\"\n",
        "#     for i in [X]:\n",
        "#         i['date_recorded'] = pd.to_datetime(i['date_recorded'])\n",
        "#         i['year_recorded'] = i['date_recorded'].apply(lambda x: x.year)\n",
        "#         i['month_recorded'] = i['date_recorded'].apply(lambda x: x.month)\n",
        "#         i['date_recorded'] = (pd.to_datetime(i['date_recorded'])).apply(lambda x: x.toordinal())\n",
        "#     return X\n",
        "\n",
        "\n",
        "# def date_parser(df):\n",
        "#     date_recorder = list(map(lambda x: datetime.datetime.strptime(str(x), '%Y-%m-%d'),\n",
        "#                              df['date_recorded'].values))\n",
        "#     df['year_recorder'] = list(map(lambda x: int(x.strftime('%Y')), date_recorder))\n",
        "#     df['weekday_recorder'] = list(map(lambda x: int(x.strftime('%w')), date_recorder))\n",
        "#     df['yearly_week_recorder'] = list(map(lambda x: int(x.strftime('%W')), date_recorder))\n",
        "#     df['month_recorder'] = list(map(lambda x: int(x.strftime('%m')), date_recorder))\n",
        "#     df['age'] = df['year_recorder'].values - df['construction_year'].values\n",
        "#     del df['date_recorded']\n",
        "#     return df\n",
        "\n",
        "\n",
        "def bools(X):\n",
        "    \"\"\"\n",
        "    public_meeting: we will fill the nulls as 'False'\n",
        "    permit: we will fill the nulls as 'False'\n",
        "    \"\"\"\n",
        "    z = ['public_meeting', 'permit']\n",
        "    for i in z:\n",
        "        X[i].fillna(False, inplace = True)\n",
        "        X[i] = X[i].apply(lambda x: float(x))\n",
        "    return X\n",
        "\n",
        "\n",
        "def small_n(X):\n",
        "    \"Collapsing small categorical value counts into 'other'\"\n",
        "    cols = [i for i in X.columns if type(X[i].iloc[0]) == str]\n",
        "    X[cols] = X[cols].where(X[cols].apply(lambda x: x.map(x.value_counts())) > 100, \"other\")\n",
        "    return X\n",
        "\n",
        "\n",
        "\n",
        "# We loaded the dataset into Azure and we are grabbing it here.\n",
        "\n",
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "# download config file in azure and put it in the current Notebooks folder\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "dataset = Dataset.get_by_name(ws, name='Pump-it-Up-dataset')\n",
        "df = dataset.to_pandas_dataframe()\n",
        "y = df['status_group']\n",
        "del df['status_group']\n",
        "X = df\n",
        "\n",
        "# A lot of null values for construction year. Of course, this is a missing value (a placeholder).\n",
        "# For modeling purposes, this is actually fine, but we'll have trouble with visualizations if we\n",
        "# compare the results for different years, so we'll set the value to something closer to\n",
        "# the other values that aren't placeholders. Let's look at the unique years and set the null\n",
        "# values to 50 years sooner.\n",
        "# Alright, let's set it to 1910\n",
        "X.loc[X['construction_year'] < 1950, 'construction_year'] = 1910\n",
        "\n",
        "# Cleaning up the features of our dataset\n",
        "# X = dates(X)\n",
        "# x = date_parser(X)\n",
        "X = bools(X)\n",
        "X['population'] = np.log(X['population'])\n",
        "X = small_n(X)\n",
        "\n",
        "# Splitting the dataset into a training and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "run = Run.get_context()\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Adds arguments to script\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    # Setting the hyperparameters we will be optimizing for you Random Forest model\n",
        "    parser.add_argument('--max_depth', type=int, default=5, help='The maximum depth of the trees.')\n",
        "    parser.add_argument('--min_samples_split', type=int, default=4, help='The minimum number of samples required to split an internal node.')\n",
        "    parser.add_argument('--n_estimators', type=int, default=750, help='The number of trees in the forest.')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    run.log(\"Max depth of the trees:\", np.int(args.max_depth))\n",
        "    run.log(\"Minimum number of samples required to split:\", np.int(args.min_samples_split))\n",
        "    run.log(\"Number of trees:\", np.int(args.n_estimators))\n",
        "\n",
        "    # Fitting a Random Forest model to our data. \n",
        "    # Sidenote: I also tried XGBoost on my local machine, but it did not perform as well.\n",
        "    # RF has a score of 0.811, XGBoost has a score of 0.745\n",
        "    # Since I did not use a validation set, it's possible that I'm just overfitting with RF.\n",
        "    # But I wanted to focus on the end-to-end process for this project so I didn't bother with \n",
        "    # a validation set.\n",
        "    rf = RandomForestClassifier(max_depth=args.max_depth,\n",
        "                                min_samples_split=args.min_samples_split,\n",
        "                                n_estimators=args.n_estimators,\n",
        "                                criterion='gini',\n",
        "                                oob_score=True,\n",
        "                                random_state=42,\n",
        "                                n_jobs=-1).fit(X_train, y_train)\n",
        "    \n",
        "    # Predicting on the test set\n",
        "    predictions = rf.predict(X_test)\n",
        "    pred = pd.DataFrame(predictions, columns = [y_test.columns[0]])\n",
        "\n",
        "    # Calculate recall to test how well we do on True Positives\n",
        "    # We can imagine a real scenario where we want to build a model\n",
        "    # that does not miss the non-functioning water pumps, and we\n",
        "    # care much less functioning water pumps that are incorrectly\n",
        "    # predicted as non-functional. \n",
        "    recall = recall_score(y_test, pred, average='micro')\n",
        "    run.log(\"Recall\", np.float(recall))\n",
        "\n",
        "    os.makedirs('outputs', exist_ok=True)\n",
        "    joblib.dump(rf, 'outputs/rf_model.pkl')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting train.py\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "id": "qp9Pu3N09Q3Q",
        "outputId": "89fb77c7-ac9e-495c-a2ba-9975fefbe1d9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "\n",
        "Getting our data and initialize a workspace object from persisted configuration. We placed the config file in .\\config.json."
      ],
      "metadata": {
        "id": "3Fmunj8Z5FPI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "\n",
        "# download config file in azure and put it in the current Notebooks folder\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"Pump-it-Up-Data-Mining-the-Water-Table\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-142186\n",
            "Azure region: southcentralus\n",
            "Subscription id: f5091c60-1c3c-430f-8d81-d802f6bf2414\n",
            "Resource group: aml-quickstarts-142186\n"
          ]
        }
      ],
      "execution_count": 29,
      "metadata": {
        "gather": {
          "logged": 1617823512998
        },
        "id": "LqRY53Mc4LH6",
        "outputId": "1c8697a2-6dff-4b3a-e41f-b261a43bc993"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We loaded the dataset into Azure and we are grabbing it here.\n",
        "from azureml.core import Dataset\n",
        "\n",
        "# If you get an error during training and try to rerun this cell, it may get stuck in execution.\n",
        "# I'm not sure what's the issue, but it gets resolved by stopping compute before rerunning the notebook.\n",
        "dataset = Dataset.get_by_name(ws, name='Pump-it-Up-dataset')\n",
        "df = dataset.to_pandas_dataframe()\n",
        "y = df['status_group']\n",
        "del df['status_group']\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-51fe05efc183>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# If you get an error during training and try to rerun this cell, it may get stuck in execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# I'm not sure what's the issue, but it gets resolved by stopping compute before rerunning the notebook.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pump-it-Up-dataset'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas_dataframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'status_group'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activity_info'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/abstract_dataset.py\u001b[0m in \u001b[0;36mget_by_name\u001b[0;34m(workspace, name, version)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTabularDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileDataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \"\"\"\n\u001b[0;32m---> 89\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAbstractDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m         \u001b[0mAbstractDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_track_lineage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/abstract_dataset.py\u001b[0m in \u001b[0;36m_get_by_name\u001b[0;34m(workspace, name, version)\u001b[0m\n\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dto_to_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0mwarn_deprecated_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/_dataset_rest_helper.py\u001b[0m in \u001b[0;36m_dto_to_dataset\u001b[0;34m(workspace, dto)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mdefinition\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataflow_json\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mproperties\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproperties\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             registration=registration)\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DATASET_TYPE_FILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         return FileDataset._create(\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activity_info'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/abstract_dataset.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, definition, properties, registration, telemetry_info)\u001b[0m\n\u001b[1;32m    555\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_partition_format\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_partition_format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_steps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0mpartition_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/_loggerfactory.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_LoggerFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_activity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivity_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_dimensions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'activity_info'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error_code'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/data/abstract_dataset.py\u001b[0m in \u001b[0;36m_dataflow\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mUserErrorException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset definition is missing. Please check how the dataset is created.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registration\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0mdataprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datastore_helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_auth_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_definition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataprep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataflow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/_datastore_helper.py\u001b[0m in \u001b[0;36m_set_auth_type\u001b[0;34m(workspace)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mget_engine_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aml_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSetAmlAuthMessageArgument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAuthType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSERVICEPRINCIPAL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mget_engine_api\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aml_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSetAmlAuthMessageArgument\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAuthType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDERIVED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/_aml_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mengine_api_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_environment_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msend_message_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/api.py\u001b[0m in \u001b[0;36mset_aml_auth\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mupdate_aml_env_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_engine_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_aml_auth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtypedefinitions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSetAmlAuthMessageArgument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCancellationToken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Engine.SetAmlAuth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/engine.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_relaunch_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_was_relaunched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_relaunch_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_last_message_id\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/api.py\u001b[0m in \u001b[0;36mconnect_to_requests_channel\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconnect_to_requests_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine_server_secret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_host_secret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequests_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost_secret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine_server_port\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_host_channel_port\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequests_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# Only try to update_engine_server if rslex Environment has been initialized already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/_aml_helper.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mengine_api_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_environment_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchanged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msend_message_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/api.py\u001b[0m in \u001b[0;36msync_host_secret\u001b[0;34m(self, message_args, cancellation_token)\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mupdate_aml_env_vars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_engine_api\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msync_host_secret\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mCancellationToken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_message_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Engine.SyncHostSecret'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/dataprep/api/engineapi/engine.py\u001b[0m in \u001b[0;36msend_message\u001b[0;34m(self, op_code, message, cancellation_token)\u001b[0m\n\u001b[1;32m    269\u001b[0m         }, cls=CustomEncoder))\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_messages_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pending_messages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 30,
      "metadata": {
        "id": "r00b5L-H-ZdO",
        "gather": {
          "logged": 1617818647969
        },
        "outputId": "270594f0-c91e-4845-fd29-1c5c35f72e6a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n4  19728         0.0    2011-07-13   Action In A           0       Artisan   \n\n   longitude   latitude              wpt_name  num_private  ... payment_type  \\\n0  34.938093  -9.856322                  none            0  ...     annually   \n1  34.698766  -2.147466              Zahanati            0  ...    never pay   \n2  37.460664  -3.821329           Kwa Mahundi            0  ...   per bucket   \n3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0  ...    never pay   \n4  31.130847  -1.825359               Shuleni            0  ...    never pay   \n\n  water_quality quality_group      quantity  quantity_group  \\\n0          soft          good        enough          enough   \n1          soft          good  insufficient    insufficient   \n2          soft          good        enough          enough   \n3          soft          good           dry             dry   \n4          soft          good      seasonal        seasonal   \n\n                 source           source_type  source_class  \\\n0                spring                spring   groundwater   \n1  rainwater harvesting  rainwater harvesting       surface   \n2                   dam                   dam       surface   \n3           machine dbh              borehole   groundwater   \n4  rainwater harvesting  rainwater harvesting       surface   \n\n               waterpoint_type waterpoint_type_group  \n0           communal standpipe    communal standpipe  \n1           communal standpipe    communal standpipe  \n2  communal standpipe multiple    communal standpipe  \n3  communal standpipe multiple    communal standpipe  \n4           communal standpipe    communal standpipe  \n\n[5 rows x 40 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>amount_tsh</th>\n      <th>date_recorded</th>\n      <th>funder</th>\n      <th>gps_height</th>\n      <th>installer</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>wpt_name</th>\n      <th>num_private</th>\n      <th>...</th>\n      <th>payment_type</th>\n      <th>water_quality</th>\n      <th>quality_group</th>\n      <th>quantity</th>\n      <th>quantity_group</th>\n      <th>source</th>\n      <th>source_type</th>\n      <th>source_class</th>\n      <th>waterpoint_type</th>\n      <th>waterpoint_type_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>69572</td>\n      <td>6000.0</td>\n      <td>2011-03-14</td>\n      <td>Roman</td>\n      <td>1390</td>\n      <td>Roman</td>\n      <td>34.938093</td>\n      <td>-9.856322</td>\n      <td>none</td>\n      <td>0</td>\n      <td>...</td>\n      <td>annually</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>spring</td>\n      <td>spring</td>\n      <td>groundwater</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8776</td>\n      <td>0.0</td>\n      <td>2013-03-06</td>\n      <td>Grumeti</td>\n      <td>1399</td>\n      <td>GRUMETI</td>\n      <td>34.698766</td>\n      <td>-2.147466</td>\n      <td>Zahanati</td>\n      <td>0</td>\n      <td>...</td>\n      <td>never pay</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34310</td>\n      <td>25.0</td>\n      <td>2013-02-25</td>\n      <td>Lottery Club</td>\n      <td>686</td>\n      <td>World vision</td>\n      <td>37.460664</td>\n      <td>-3.821329</td>\n      <td>Kwa Mahundi</td>\n      <td>0</td>\n      <td>...</td>\n      <td>per bucket</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>dam</td>\n      <td>dam</td>\n      <td>surface</td>\n      <td>communal standpipe multiple</td>\n      <td>communal standpipe</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>67743</td>\n      <td>0.0</td>\n      <td>2013-01-28</td>\n      <td>Unicef</td>\n      <td>263</td>\n      <td>UNICEF</td>\n      <td>38.486161</td>\n      <td>-11.155298</td>\n      <td>Zahanati Ya Nanyumbu</td>\n      <td>0</td>\n      <td>...</td>\n      <td>never pay</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>dry</td>\n      <td>dry</td>\n      <td>machine dbh</td>\n      <td>borehole</td>\n      <td>groundwater</td>\n      <td>communal standpipe multiple</td>\n      <td>communal standpipe</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19728</td>\n      <td>0.0</td>\n      <td>2011-07-13</td>\n      <td>Action In A</td>\n      <td>0</td>\n      <td>Artisan</td>\n      <td>31.130847</td>\n      <td>-1.825359</td>\n      <td>Shuleni</td>\n      <td>0</td>\n      <td>...</td>\n      <td>never pay</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>seasonal</td>\n      <td>seasonal</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617820630823
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns[df.dtypes==object]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 26,
          "data": {
            "text/plain": "Index(['funder', 'installer', 'basin', 'lga', 'ward', 'public_meeting',\n       'scheme_management', 'permit', 'extraction_type',\n       'extraction_type_class', 'management', 'management_group',\n       'payment_type', 'water_quality', 'quantity_group', 'source',\n       'source_class', 'waterpoint_type'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617823451742
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "Index(['date_recorded', 'funder', 'gps_height', 'installer', 'longitude',\n       'latitude', 'basin', 'region_code', 'district_code', 'lga', 'ward',\n       'population', 'public_meeting', 'scheme_management', 'permit',\n       'construction_year', 'extraction_type', 'extraction_type_class',\n       'management', 'management_group', 'payment_type', 'water_quality',\n       'quantity_group', 'source', 'source_class', 'waterpoint_type'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617823422693
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_remove = ['id','amount_tsh',  'num_private', 'region', \r\n",
        "          'quantity', 'quality_group', 'source_type', 'payment', \r\n",
        "          'waterpoint_type_group',\r\n",
        "         'extraction_type_group']\r\n",
        "df = df.drop('id', axis=1)\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['id'] not found in axis\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-62957c623559>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0;34m'waterpoint_type_group'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m          'extraction_type_group']\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4115\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4116\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4117\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4118\u001b[0m         )\n\u001b[1;32m   4119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3912\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3913\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3914\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3945\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3946\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5340\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['id'] not found in axis\""
          ]
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up our Compute Target"
      ],
      "metadata": {
        "id": "1aci-_n67fg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Creating a compute cluster if there isn't one that is already created.\n",
        "\n",
        "cpu_cluster_name = 'hypr-auto-clustr'\n",
        "\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new computer target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_v2',\n",
        "                                                          max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "    \n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing compute target.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1617818652094
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "kS4ek0mP4LH-",
        "outputId": "04fee564-830c-4bab-a4fa-92f6cfd65d27"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using get_status() to get a detailed status for the current compute cluster.\n",
        "print(cpu_cluster.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'currentNodeCount': 3, 'targetNodeCount': 0, 'nodeStateCounts': {'preparingNodeCount': 0, 'runningNodeCount': 0, 'idleNodeCount': 0, 'unusableNodeCount': 0, 'leavingNodeCount': 3, 'preemptedNodeCount': 0}, 'allocationState': 'Resizing', 'allocationStateTransitionTime': '2021-04-07T18:02:48.072000+00:00', 'errors': None, 'creationTime': '2021-04-07T16:46:46.252734+00:00', 'modifiedTime': '2021-04-07T16:47:01.701608+00:00', 'provisioningState': 'Succeeded', 'provisioningStateTransitionTime': None, 'scaleSettings': {'minNodeCount': 0, 'maxNodeCount': 4, 'nodeIdleTimeBeforeScaleDown': 'PT120S'}, 'vmPriority': 'Dedicated', 'vmSize': 'STANDARD_D2_V2'}\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "id": "29YRrdjv4LH_",
        "gather": {
          "logged": 1617818652855
        },
        "outputId": "591db018-9782-4a0d-92b5-1d36df3cca35"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compute_targets = ws.compute_targets\n",
        "for name, ct in compute_targets.items():\n",
        "    print(name, ct.type, ct.provisioning_state)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "notebook142186 ComputeInstance Succeeded\n",
            "hypr-auto-clustr AmlCompute Succeeded\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "id": "blX8K_h_4LIA",
        "gather": {
          "logged": 1617818655229
        },
        "outputId": "2ef3efcb-0426-4024-c990-24fd383bbd54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cpu_cluster"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "AmlCompute(workspace=Workspace.create(name='quick-starts-ws-142186', subscription_id='f5091c60-1c3c-430f-8d81-d802f6bf2414', resource_group='aml-quickstarts-142186'), name=hypr-auto-clustr, id=/subscriptions/f5091c60-1c3c-430f-8d81-d802f6bf2414/resourceGroups/aml-quickstarts-142186/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-142186/computes/hypr-auto-clustr, type=AmlCompute, provisioning_state=Succeeded, location=southcentralus, tags=None)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 10,
      "metadata": {
        "id": "7K7tV1ag4LIB",
        "gather": {
          "logged": 1617818655398
        },
        "outputId": "6a342129-d443-4bfb-8f76-716501740f9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperdrive Configuration\n",
        "\n",
        "We are using Random Forest to train our model. We will use Hyperdrive to do a hyperparameter search to optimize our model.\n",
        "\n",
        "We will be using Random Sampling since it is more efficient than grid search for finding an optima.\n",
        "\n"
      ],
      "metadata": {
        "id": "Gk-kpMb97tHe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "from azureml.core import ScriptRunConfig\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "from azureml.train.hyperdrive.policy import BanditPolicy\n",
        "from azureml.train.hyperdrive.sampling import BayesianParameterSampling\n",
        "from azureml.train.hyperdrive.runconfig import HyperDriveConfig\n",
        "from azureml.train.hyperdrive.parameter_expressions import quniform\n",
        "from azureml.train.hyperdrive.parameter_expressions import choice\n",
        "import os\n",
        "\n",
        "# Specifying parameter sampler.\n",
        "# - Here we use Bayesian Hyperparameter Sampling to search the hyperparameter space for the best model.\n",
        "# - Essentially, Bayesian Sampling builds a probability model of the objective function we are trying \n",
        "#   to minimize and uses it to select the most promising hyperparameters to evaluate in the true objective function.\n",
        "# - For best results with Bayesian Sampling we recommend using a maximum number of runs greater than or \n",
        "#   equal to 20 times the number of hyperparameters being tuned. Recommendend value:60.\n",
        "#   We will be optimizing 3 hyperparameters for this project, therefore we choose 60 max_total_runs.\n",
        "# - We also use quniform to search the hyperparameter space since quniform(low, high, q) creates uniform distriution \n",
        "#   between low and high values, separated by spacing q.\n",
        "\n",
        "ps = BayesianParameterSampling(\n",
        "    {\n",
        "    'max_depth': quniform(3, 15, 1), # Maximum depth of the trees\n",
        "    'min_samples_split': choice(2, 4, 6), # Minimum number of samples required to split\n",
        "    'n_estimators' : quniform(500, 1000, 50) # Number of trees\n",
        "    }\n",
        ")\n",
        "\n",
        "if \"training\" not in os.listdir():\n",
        "    os.mkdir(\"./training\")\n",
        "\n",
        "# Creating a SKLearn estimator for use with train.py\n",
        "src = ScriptRunConfig(source_directory=os.path.join('./'),\n",
        "                      script='train.py',\n",
        "                      compute_target=cpu_cluster,\n",
        "                      environment=sklearn_env)\n",
        "\n",
        "# Creating a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.\n",
        "hyperdrive_config = HyperDriveConfig(run_config=src,\n",
        "                                    hyperparameter_sampling=ps,\n",
        "                                    primary_metric_name='norm_macro_recall',\n",
        "                                    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
        "                                    max_total_runs=60,\n",
        "                                    max_concurrent_runs=4)"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "gather": {
          "logged": 1617818659947
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "bkWve4Zp4LIC",
        "outputId": "48ddaf4a-1b4c-47c6-9645-1e45b740f8af"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submit Experiment and Run Details"
      ],
      "metadata": {
        "id": "2G52h417ACCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Submitting a HyperDrive run to the experiment and show run details with the widget.\n",
        "\n",
        "hyperdrive_run = exp.submit(config=hyperdrive_config)\n",
        "\n",
        "RunDetails(hyperdrive_run).show()\n",
        "hyperdrive_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_HyperDriveWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO'…",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36890856a2a54e1b8c916d9a1e563c8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Canceled\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/Pump-it-Up-Data-Mining-the-Water-Table/runs/HD_2e33f43b-0592-4de2-aaf6-92407a66352b?wsid=/subscriptions/f5091c60-1c3c-430f-8d81-d802f6bf2414/resourcegroups/aml-quickstarts-142186/workspaces/quick-starts-ws-142186\", \"run_id\": \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b\", \"run_properties\": {\"run_id\": \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b\", \"created_utc\": \"2021-04-07T18:04:24.388096Z\", \"properties\": {\"primary_metric_config\": \"{\\\"name\\\": \\\"norm_macro_recall\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"resume_from\": \"null\", \"runTemplate\": \"HyperDrive\", \"azureml.runsource\": \"hyperdrive\", \"platform\": \"AML\", \"ContentSnapshotId\": \"e2358bdf-6abd-464f-893f-f48397840dda\"}, \"tags\": {\"_aml_system_max_concurrent_jobs\": \"4\", \"max_concurrent_jobs\": \"4\", \"_aml_system_max_total_jobs\": \"60\", \"max_total_jobs\": \"60\", \"_aml_system_max_duration_minutes\": \"10080\", \"max_duration_minutes\": \"10080\", \"_aml_system_policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"policy_config\": \"{\\\"name\\\": \\\"DEFAULT\\\"}\", \"_aml_system_generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"max_depth\\\": [\\\"quniform\\\", [3, 15, 1]], \\\"min_samples_split\\\": [\\\"choice\\\", [[2, 4, 6]]], \\\"n_estimators\\\": [\\\"quniform\\\", [500, 1000, 50]]}}\", \"generator_config\": \"{\\\"name\\\": \\\"BAYESIANOPTIMIZATION\\\", \\\"parameter_space\\\": {\\\"max_depth\\\": [\\\"quniform\\\", [3, 15, 1]], \\\"min_samples_split\\\": [\\\"choice\\\", [[2, 4, 6]]], \\\"n_estimators\\\": [\\\"quniform\\\", [500, 1000, 50]]}}\", \"_aml_system_primary_metric_config\": \"{\\\"name\\\": \\\"norm_macro_recall\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"primary_metric_config\": \"{\\\"name\\\": \\\"norm_macro_recall\\\", \\\"goal\\\": \\\"maximize\\\"}\", \"_aml_system_platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/f5091c60-1c3c-430f-8d81-d802f6bf2414/resourceGroups/aml-quickstarts-142186/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-142186/experiments/Pump-it-Up-Data-Mining-the-Water-Table\\\", \\\"SubscriptionId\\\": \\\"f5091c60-1c3c-430f-8d81-d802f6bf2414\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-142186\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-142186\\\", \\\"ExperimentName\\\": \\\"Pump-it-Up-Data-Mining-the-Water-Table\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"hypr-auto-clustr\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"sklearn_env\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"dependencies\\\": [\\\"python=3.6.2\\\", \\\"pip=20.2.4\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"scikit-learn\\\"]}]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210220.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"e2358bdf-6abd-464f-893f-f48397840dda\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"39b799c5-2985-4c4a-9547-e1fdad7bb5ee\\\", \\\"amlClientSessionId\\\": \\\"4842a291-5450-446e-b0fd-2f33ba463610\\\", \\\"subscriptionId\\\": \\\"f5091c60-1c3c-430f-8d81-d802f6bf2414\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 60, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"platform_config\": \"{\\\"ServiceAddress\\\": \\\"https://southcentralus.experiments.azureml.net\\\", \\\"ServiceArmScope\\\": \\\"subscriptions/f5091c60-1c3c-430f-8d81-d802f6bf2414/resourceGroups/aml-quickstarts-142186/providers/Microsoft.MachineLearningServices/workspaces/quick-starts-ws-142186/experiments/Pump-it-Up-Data-Mining-the-Water-Table\\\", \\\"SubscriptionId\\\": \\\"f5091c60-1c3c-430f-8d81-d802f6bf2414\\\", \\\"ResourceGroupName\\\": \\\"aml-quickstarts-142186\\\", \\\"WorkspaceName\\\": \\\"quick-starts-ws-142186\\\", \\\"ExperimentName\\\": \\\"Pump-it-Up-Data-Mining-the-Water-Table\\\", \\\"Definition\\\": {\\\"Overrides\\\": {\\\"script\\\": \\\"train.py\\\", \\\"arguments\\\": [], \\\"target\\\": \\\"hypr-auto-clustr\\\", \\\"framework\\\": \\\"Python\\\", \\\"communicator\\\": \\\"None\\\", \\\"maxRunDurationSeconds\\\": 2592000, \\\"nodeCount\\\": 1, \\\"priority\\\": null, \\\"environment\\\": {\\\"name\\\": \\\"sklearn_env\\\", \\\"version\\\": null, \\\"environmentVariables\\\": {\\\"EXAMPLE_ENV_VAR\\\": \\\"EXAMPLE_VALUE\\\"}, \\\"python\\\": {\\\"userManagedDependencies\\\": false, \\\"interpreterPath\\\": \\\"python\\\", \\\"condaDependenciesFile\\\": null, \\\"baseCondaEnvironment\\\": null, \\\"condaDependencies\\\": {\\\"dependencies\\\": [\\\"python=3.6.2\\\", \\\"pip=20.2.4\\\", {\\\"pip\\\": [\\\"azureml-defaults\\\", \\\"scikit-learn\\\"]}]}}, \\\"docker\\\": {\\\"enabled\\\": false, \\\"baseImage\\\": \\\"mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210220.v1\\\", \\\"baseDockerfile\\\": null, \\\"sharedVolumes\\\": true, \\\"shmSize\\\": \\\"2g\\\", \\\"arguments\\\": [], \\\"baseImageRegistry\\\": {\\\"address\\\": null, \\\"username\\\": null, \\\"password\\\": null, \\\"registryIdentity\\\": null}, \\\"platform\\\": {\\\"os\\\": \\\"Linux\\\", \\\"architecture\\\": \\\"amd64\\\"}}, \\\"spark\\\": {\\\"repositories\\\": [], \\\"packages\\\": [], \\\"precachePackages\\\": true}, \\\"databricks\\\": {\\\"mavenLibraries\\\": [], \\\"pypiLibraries\\\": [], \\\"rcranLibraries\\\": [], \\\"jarLibraries\\\": [], \\\"eggLibraries\\\": []}, \\\"r\\\": null, \\\"inferencingStackVersion\\\": null}, \\\"history\\\": {\\\"outputCollection\\\": true, \\\"snapshotProject\\\": true, \\\"directoriesToWatch\\\": [\\\"logs\\\"]}, \\\"spark\\\": {\\\"configuration\\\": {\\\"spark.app.name\\\": \\\"Azure ML Experiment\\\", \\\"spark.yarn.maxAppAttempts\\\": 1}}, \\\"hdi\\\": {\\\"yarnDeployMode\\\": \\\"cluster\\\"}, \\\"tensorflow\\\": {\\\"workerCount\\\": 1, \\\"parameterServerCount\\\": 1}, \\\"mpi\\\": {\\\"processCountPerNode\\\": 1, \\\"nodeCount\\\": 1}, \\\"pytorch\\\": {\\\"communicationBackend\\\": \\\"nccl\\\", \\\"processCount\\\": null, \\\"nodeCount\\\": 1}, \\\"paralleltask\\\": {\\\"maxRetriesPerWorker\\\": 0, \\\"workerCountPerNode\\\": 1, \\\"terminalExitCodes\\\": null}, \\\"dataReferences\\\": {}, \\\"data\\\": {}, \\\"outputData\\\": {}, \\\"sourceDirectoryDataStore\\\": null, \\\"amlcompute\\\": {\\\"vmSize\\\": null, \\\"vmPriority\\\": null, \\\"retainCluster\\\": false, \\\"name\\\": null, \\\"clusterMaxNodeCount\\\": null}, \\\"command\\\": \\\"\\\"}, \\\"TargetDetails\\\": null, \\\"SnapshotId\\\": \\\"e2358bdf-6abd-464f-893f-f48397840dda\\\", \\\"TelemetryValues\\\": {\\\"amlClientType\\\": \\\"azureml-sdk-train\\\", \\\"amlClientModule\\\": \\\"[Scrubbed]\\\", \\\"amlClientFunction\\\": \\\"[Scrubbed]\\\", \\\"tenantId\\\": \\\"660b3398-b80e-49d2-bc5b-ac1dc93b5254\\\", \\\"amlClientRequestId\\\": \\\"39b799c5-2985-4c4a-9547-e1fdad7bb5ee\\\", \\\"amlClientSessionId\\\": \\\"4842a291-5450-446e-b0fd-2f33ba463610\\\", \\\"subscriptionId\\\": \\\"f5091c60-1c3c-430f-8d81-d802f6bf2414\\\", \\\"estimator\\\": \\\"NoneType\\\", \\\"samplingMethod\\\": \\\"BayesianOptimization\\\", \\\"terminationPolicy\\\": \\\"Default\\\", \\\"primaryMetricGoal\\\": \\\"maximize\\\", \\\"maxTotalRuns\\\": 60, \\\"maxConcurrentRuns\\\": 4, \\\"maxDurationMinutes\\\": 10080, \\\"vmSize\\\": null}}}\", \"_aml_system_resume_child_runs\": \"null\", \"resume_child_runs\": \"null\", \"_aml_system_all_jobs_generated\": \"true\", \"all_jobs_generated\": \"true\", \"_aml_system_cancellation_requested\": \"true\", \"cancellation_requested\": \"true\", \"_aml_system_progress_metadata_evaluation_timestamp\": \"\\\"2021-04-07T18:04:25.668185\\\"\", \"progress_metadata_evaluation_timestamp\": \"\\\"2021-04-07T18:04:25.668185\\\"\", \"_aml_system_progress_metadata_digest\": \"\\\"7334a3ecd7ce1294cf6709b938334e66bedf598c4a84e1eaa0fad4074410c807\\\"\", \"progress_metadata_digest\": \"\\\"7334a3ecd7ce1294cf6709b938334e66bedf598c4a84e1eaa0fad4074410c807\\\"\", \"_aml_system_progress_metadata_active_timestamp\": \"\\\"2021-04-07T18:04:25.668185\\\"\", \"progress_metadata_active_timestamp\": \"\\\"2021-04-07T18:04:25.668185\\\"\", \"_aml_system_HD_2e33f43b-0592-4de2-aaf6-92407a66352b_0\": \"{\\\"max_depth\\\": 5, \\\"min_samples_split\\\": 2, \\\"n_estimators\\\": 600}\", \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_0\": \"{\\\"max_depth\\\": 5, \\\"min_samples_split\\\": 2, \\\"n_estimators\\\": 600}\", \"_aml_system_HD_2e33f43b-0592-4de2-aaf6-92407a66352b_1\": \"{\\\"max_depth\\\": 6, \\\"min_samples_split\\\": 4, \\\"n_estimators\\\": 500}\", \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_1\": \"{\\\"max_depth\\\": 6, \\\"min_samples_split\\\": 4, \\\"n_estimators\\\": 500}\", \"_aml_system_HD_2e33f43b-0592-4de2-aaf6-92407a66352b_2\": \"{\\\"max_depth\\\": 9, \\\"min_samples_split\\\": 2, \\\"n_estimators\\\": 950}\", \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_2\": \"{\\\"max_depth\\\": 9, \\\"min_samples_split\\\": 2, \\\"n_estimators\\\": 950}\", \"_aml_system_HD_2e33f43b-0592-4de2-aaf6-92407a66352b_3\": \"{\\\"max_depth\\\": 11, \\\"min_samples_split\\\": 6, \\\"n_estimators\\\": 750}\", \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_3\": \"{\\\"max_depth\\\": 11, \\\"min_samples_split\\\": 6, \\\"n_estimators\\\": 750}\", \"_aml_system_environment_preparation_status\": \"PREPARED\", \"environment_preparation_status\": \"PREPARED\", \"_aml_system_prepare_run_id\": \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_preparation\", \"prepare_run_id\": \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_preparation\", \"_aml_system_HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4\": \"{\\\"max_depth\\\": 7, \\\"min_samples_split\\\": 2, \\\"n_estimators\\\": 750}\", \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4\": \"{\\\"max_depth\\\": 7, \\\"min_samples_split\\\": 2, \\\"n_estimators\\\": 750}\", \"_aml_system_HD_2e33f43b-0592-4de2-aaf6-92407a66352b_5\": \"{\\\"max_depth\\\": 8, \\\"min_samples_split\\\": 2, \\\"n_estimators\\\": 650}\", \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_5\": \"{\\\"max_depth\\\": 8, \\\"min_samples_split\\\": 2, \\\"n_estimators\\\": 650}\", \"_aml_system_HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4_cancelled\": \"true\", \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4_cancelled\": \"true\", \"_aml_system_HD_2e33f43b-0592-4de2-aaf6-92407a66352b_5_cancelled\": \"true\", \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_5_cancelled\": \"true\", \"_aml_system_final_best_metric_update_retry_count\": \"1\", \"final_best_metric_update_retry_count\": \"1\"}, \"end_time_utc\": \"2021-04-07T18:29:38.667094Z\", \"status\": \"Canceled\", \"log_files\": {\"azureml-logs/hyperdrive.txt\": \"https://mlstrg142186.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_2e33f43b-0592-4de2-aaf6-92407a66352b/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=RPkcv%2Bz%2Fa5rhFtXr0SgT%2FHOff6V94Pm0J2VYw23WMRM%3D&st=2021-04-07T18%3A19%3A47Z&se=2021-04-08T02%3A29%3A47Z&sp=r\"}, \"log_groups\": [[\"azureml-logs/hyperdrive.txt\"]], \"run_duration\": \"0:25:14\", \"run_number\": \"21\", \"run_queued_details\": {\"status\": \"Canceled\", \"details\": null}, \"hyper_parameters\": {\"max_depth\": [\"quniform\", [3, 15, 1]], \"min_samples_split\": [\"choice\", [[2, 4, 6]]], \"n_estimators\": [\"quniform\", [500, 1000, 50]]}}, \"child_runs\": [{\"run_id\": \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_2\", \"run_number\": 23, \"metric\": null, \"status\": \"Failed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-04-07T18:11:12.289702Z\", \"end_time\": \"2021-04-07T18:28:25.620182Z\", \"created_time\": \"2021-04-07T18:04:57.933985Z\", \"created_time_dt\": \"2021-04-07T18:04:57.933985Z\", \"duration\": \"0:23:27\", \"hyperdrive_id\": \"2e33f43b-0592-4de2-aaf6-92407a66352b\", \"arguments\": null, \"param_max_depth\": 9, \"param_min_samples_split\": 2, \"param_n_estimators\": 950}, {\"run_id\": \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_0\", \"run_number\": 24, \"metric\": null, \"status\": \"Failed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-04-07T18:11:13.864392Z\", \"end_time\": \"2021-04-07T18:28:28.472279Z\", \"created_time\": \"2021-04-07T18:04:58.102391Z\", \"created_time_dt\": \"2021-04-07T18:04:58.102391Z\", \"duration\": \"0:23:30\", \"hyperdrive_id\": \"2e33f43b-0592-4de2-aaf6-92407a66352b\", \"arguments\": null, \"param_max_depth\": 5, \"param_min_samples_split\": 2, \"param_n_estimators\": 600}, {\"run_id\": \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_1\", \"run_number\": 26, \"metric\": null, \"status\": \"Failed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-04-07T18:11:22.471184Z\", \"end_time\": \"2021-04-07T18:22:00.762222Z\", \"created_time\": \"2021-04-07T18:04:58.548125Z\", \"created_time_dt\": \"2021-04-07T18:04:58.548125Z\", \"duration\": \"0:17:02\", \"hyperdrive_id\": \"2e33f43b-0592-4de2-aaf6-92407a66352b\", \"arguments\": null, \"param_max_depth\": 6, \"param_min_samples_split\": 4, \"param_n_estimators\": 500}, {\"run_id\": \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_3\", \"run_number\": 25, \"metric\": null, \"status\": \"Failed\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-04-07T18:11:19.628522Z\", \"end_time\": \"2021-04-07T18:28:25.486399Z\", \"created_time\": \"2021-04-07T18:04:58.318822Z\", \"created_time_dt\": \"2021-04-07T18:04:58.318822Z\", \"duration\": \"0:23:27\", \"hyperdrive_id\": \"2e33f43b-0592-4de2-aaf6-92407a66352b\", \"arguments\": null, \"param_max_depth\": 11, \"param_min_samples_split\": 6, \"param_n_estimators\": 750}, {\"run_id\": \"HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4\", \"run_number\": 27, \"metric\": null, \"status\": \"Canceled\", \"run_type\": \"azureml.scriptrun\", \"training_percent\": null, \"start_time\": \"2021-04-07T18:22:57.641722Z\", \"end_time\": \"2021-04-07T18:28:58.268582Z\", \"created_time\": \"2021-04-07T18:22:43.126414Z\", \"created_time_dt\": \"2021-04-07T18:22:43.126414Z\", \"duration\": \"0:06:15\", \"hyperdrive_id\": \"2e33f43b-0592-4de2-aaf6-92407a66352b\", \"arguments\": null, \"param_max_depth\": 7, \"param_min_samples_split\": 2, \"param_n_estimators\": 750}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-04-07T18:04:25.745615][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space\\r\\n[2021-04-07T18:04:25.899457][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.\\r\\n[2021-04-07T18:04:26.2532056Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.\\r\\n[2021-04-07T18:04:25.176901][API][INFO]Experiment created\\r\\n[2021-04-07T18:04:57.2346019Z][SCHEDULER][INFO]Scheduling job, id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_1'\\r\\n[2021-04-07T18:04:57.2271422Z][SCHEDULER][INFO]Scheduling job, id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_0'\\r\\n[2021-04-07T18:04:57.2387255Z][SCHEDULER][INFO]Scheduling job, id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_3'\\r\\n[2021-04-07T18:04:57.2413431Z][SCHEDULER][INFO]Scheduling job, id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_2'\\r\\n[2021-04-07T18:04:57.2262859Z][SCHEDULER][INFO]The execution environment was successfully prepared.\\r\\n[2021-04-07T18:04:58.0914161Z][SCHEDULER][INFO]Successfully patched a child run. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_2'\\r\\n[2021-04-07T18:04:58.0239218Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_2'\\r\\n[2021-04-07T18:04:58.2023136Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_0'\\r\\n[2021-04-07T18:04:58.2879283Z][SCHEDULER][INFO]Successfully patched a child run. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_0'\\r\\n[2021-04-07T18:04:58.5668715Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_3'\\r\\n[2021-04-07T18:04:58.6445796Z][SCHEDULER][INFO]Successfully patched a child run. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_3'\\r\\n[2021-04-07T18:04:58.7991005Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_1'\\r\\n[2021-04-07T18:04:59.0520918Z][SCHEDULER][INFO]Successfully patched a child run. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_1'\\r\\n[2021-04-07T18:22:25.594011][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-04-07T18:22:25.849556][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-04-07T18:22:41.4845536Z][SCHEDULER][INFO]Scheduling job, id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4'\\r\\n[2021-04-07T18:22:43.5282532Z][SCHEDULER][INFO]Successfully scheduled a job. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4'\\r\\n[2021-04-07T18:22:43.6363254Z][SCHEDULER][INFO]Successfully patched a child run. Id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4'\\r\\n[2021-04-07T18:28:25.875523][GENERATOR][INFO]Trying to sample '1' jobs from the hyperparameter space\\r\\n[2021-04-07T18:28:26.576731][GENERATOR][INFO]Successfully sampled '1' jobs, they will soon be submitted to the execution target.\\r\\n[2021-04-07T18:28:36.928483][CONTROLLER][INFO]Experiment has been marked for cancellation.\\r\\n[2021-04-07T18:28:36.928564][CONTROLLER][WARNING]The first 3 jobs have failed. The system is canceling the experiment. Please resolve the issues before resubmitting the experiment.\\r\\n[2021-04-07T18:28:48.5894991Z][SCHEDULER][INFO]Cancelling job, id='HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4'\\r\\n[2021-04-07T18:28:49.1623989Z][SCHEDULER][INFO]Updating job statuses to cancelled: [(job id = 'HD_2e33f43b-0592-4de2-aaf6-92407a66352b_4', previous status = 'RUNNING'), (job id = 'HD_2e33f43b-0592-4de2-aaf6-92407a66352b_5', previous status = 'QUEUED')]\\r\\n[2021-04-07T18:29:06.584437][CONTROLLER][WARNING]User errors were found in at least one of the child runs.\\r\\n[2021-04-07T18:29:38.138540][CONTROLLER][WARNING]User errors were found in at least one of the child runs.\\r\\n[2021-04-07T18:29:39.129945][CONTROLLER][INFO]Experiment was 'ExperimentStatus.RUNNING', is 'ExperimentStatus.CANCELLED'.\\n\\nError occurred: User errors were found in at least one of the child runs.\\n\", \"graph\": {}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.24.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RunId: HD_2e33f43b-0592-4de2-aaf6-92407a66352b\n",
            "Web View: https://ml.azure.com/experiments/Pump-it-Up-Data-Mining-the-Water-Table/runs/HD_2e33f43b-0592-4de2-aaf6-92407a66352b?wsid=/subscriptions/f5091c60-1c3c-430f-8d81-d802f6bf2414/resourcegroups/aml-quickstarts-142186/workspaces/quick-starts-ws-142186\n",
            "\n",
            "Streaming azureml-logs/hyperdrive.txt\n",
            "=====================================\n",
            "\n",
            "\"<START>[2021-04-07T18:04:25.745615][GENERATOR][INFO]Trying to sample '4' jobs from the hyperparameter space<END>\\n\"\"<START>[2021-04-07T18:04:25.899457][GENERATOR][INFO]Successfully sampled '4' jobs, they will soon be submitted to the execution target.<END>\\n\"<START>[2021-04-07T18:04:26.2532056Z][SCHEDULER][INFO]The execution environment is being prepared. Please be patient as it can take a few minutes.<END>\"<START>[2021-04-07T18:04:25.176901][API][INFO]Experiment created<END>\\n\"\n",
            "\n",
            "Execution Summary\n",
            "=================\n",
            "RunId: HD_2e33f43b-0592-4de2-aaf6-92407a66352b\n",
            "Web View: https://ml.azure.com/experiments/Pump-it-Up-Data-Mining-the-Water-Table/runs/HD_2e33f43b-0592-4de2-aaf6-92407a66352b?wsid=/subscriptions/f5091c60-1c3c-430f-8d81-d802f6bf2414/resourcegroups/aml-quickstarts-142186/workspaces/quick-starts-ws-142186\n",
            "\n",
            "Warnings:\n",
            "{\n",
            "  \"error\": {\n",
            "    \"code\": \"UserError\",\n",
            "    \"severity\": null,\n",
            "    \"message\": \"User errors were found in at least one of the child runs.\",\n",
            "    \"messageFormat\": null,\n",
            "    \"messageParameters\": {},\n",
            "    \"referenceCode\": null,\n",
            "    \"detailsUri\": null,\n",
            "    \"target\": null,\n",
            "    \"details\": [],\n",
            "    \"innerError\": null,\n",
            "    \"debugInfo\": null\n",
            "  },\n",
            "  \"correlation\": null,\n",
            "  \"environment\": null,\n",
            "  \"location\": null,\n",
            "  \"time\": \"0001-01-01T00:00:00+00:00\",\n",
            "  \"componentName\": null\n",
            "}\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "{'runId': 'HD_2e33f43b-0592-4de2-aaf6-92407a66352b',\n 'target': 'hypr-auto-clustr',\n 'status': 'Canceled',\n 'startTimeUtc': '2021-04-07T18:04:24.446612Z',\n 'endTimeUtc': '2021-04-07T18:29:38.667094Z',\n 'error': {'error': {'code': 'UserError',\n   'message': 'User errors were found in at least one of the child runs.',\n   'messageParameters': {},\n   'details': []},\n  'time': '0001-01-01T00:00:00.000Z'},\n 'warnings': [{'source': 'SecondaryError',\n   'message': '{\\n  \"error\": {\\n    \"code\": \"UserError\",\\n    \"severity\": null,\\n    \"message\": \"User errors were found in at least one of the child runs.\",\\n    \"messageFormat\": null,\\n    \"messageParameters\": {},\\n    \"referenceCode\": null,\\n    \"detailsUri\": null,\\n    \"target\": null,\\n    \"details\": [],\\n    \"innerError\": null,\\n    \"debugInfo\": null\\n  },\\n  \"correlation\": null,\\n  \"environment\": null,\\n  \"location\": null,\\n  \"time\": \"0001-01-01T00:00:00+00:00\",\\n  \"componentName\": null\\n}'}],\n 'properties': {'primary_metric_config': '{\"name\": \"norm_macro_recall\", \"goal\": \"maximize\"}',\n  'resume_from': 'null',\n  'runTemplate': 'HyperDrive',\n  'azureml.runsource': 'hyperdrive',\n  'platform': 'AML',\n  'ContentSnapshotId': 'e2358bdf-6abd-464f-893f-f48397840dda'},\n 'inputDatasets': [],\n 'outputDatasets': [],\n 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://mlstrg142186.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_2e33f43b-0592-4de2-aaf6-92407a66352b/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=RPkcv%2Bz%2Fa5rhFtXr0SgT%2FHOff6V94Pm0J2VYw23WMRM%3D&st=2021-04-07T18%3A19%3A47Z&se=2021-04-08T02%3A29%3A47Z&sp=r'},\n 'submittedBy': 'ODL_User 142186'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "scrolled": false,
        "colab": {
          "referenced_widgets": [
            "759f448677db434fa8ef18faa40b577d",
            "9d306f2f47724b8ca87dac84b16c8d60"
          ]
        },
        "id": "u6z3VizC4LIC",
        "gather": {
          "logged": 1617820202472
        },
        "outputId": "073ae2be-0769-4172-846e-9cce80a13302"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving our Best Random Forest / Hyperdrive Model"
      ],
      "metadata": {
        "id": "jiYZr4ucAJfu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "# Get your best run and save the model from that run.\n",
        "\n",
        "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
        "best_run_metrics = best_run.get_metrics()\n",
        "\n",
        "print('Best Run:', best_run)\n",
        "print('Metrics:', best_run_metrics['recall_score_micro'])\n",
        "\n",
        "hyperdrive_model = best_run.register_model(model_name=\"rf_hyperdrive_model\", model_path=\"./outputs/model.pkl\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1598276310862
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "scrolled": false,
        "id": "DxrY9iQX4LID"
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "name": "hyperparameter_tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}