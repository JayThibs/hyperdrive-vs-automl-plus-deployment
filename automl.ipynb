{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/hyperdrive-vs-automl-plus-deployment/blob/main/automl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "Note: For data exploration, go to hyperparameter_tuning.ipynb"
      ],
      "metadata": {
        "id": "wjy4Pc9vWXWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Dependencies"
      ],
      "metadata": {
        "id": "JCE-mKVP6sCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.26.0\n"
          ]
        }
      ],
      "execution_count": 1,
      "metadata": {
        "id": "nZbdttQy4Un6",
        "gather": {
          "logged": 1618515532342
        },
        "outputId": "87150e8e-2739-4475-d886-73120d9f086c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %%writefile feature_preprocessing.py\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def bools(df):\n",
        "    \"\"\"\n",
        "    public_meeting: we will fill the nulls as 'False'\n",
        "    permit: we will fill the nulls as 'False\n",
        "    \"\"\"\n",
        "    z = ['public_meeting', 'permit']\n",
        "    for i in z:\n",
        "        df[i].fillna(False, inplace = True)\n",
        "        df[i] = df[i].apply(lambda x: float(x))\n",
        "    return df\n",
        "\n",
        "def locs(df, trans = ['longitude', 'latitude', 'gps_height', 'population']):\n",
        "    \"\"\"\n",
        "    fill in the nulls for ['longitude', 'latitude', 'gps_height', 'population'] by using medians from \n",
        "    ['subvillage', 'district_code', 'basin'], and lastly the overall median\n",
        "    \"\"\"\n",
        "    df.loc[df.longitude == 0, 'latitude'] = 0\n",
        "    for z in trans:\n",
        "        df[z].replace(0., np.NaN, inplace = True)\n",
        "        df[z].replace(1., np.NaN, inplace = True)\n",
        "        \n",
        "        for j in ['district_code', 'basin']:\n",
        "        \n",
        "            df['median'] = df.groupby([j])[z].transform('median')\n",
        "            df[z] = df[z].fillna(df['median'])\n",
        "        \n",
        "        df[z] = df[z].fillna(df[z].median())\n",
        "        del df['median']\n",
        "    return df\n",
        "\n",
        "def construction(df):\n",
        "    \"\"\"\n",
        "    A lot of null values for construction year. Of course, this is a missing value (a placeholder).\n",
        "    For modeling purposes, this is actually fine, but we'll have trouble with visualizations if we\n",
        "    compare the results for different years, so we'll set the value to something closer to\n",
        "    the other values that aren't placeholders. Let's look at the unique years and set the null\n",
        "    values to 50 years sooner.\n",
        "    Let's set it to 1910 since the lowest \"good\" value is 1960.\n",
        "    \"\"\"\n",
        "    df.loc[df['construction_year'] < 1950, 'construction_year'] = 1910\n",
        "    return df\n",
        "\n",
        "# Alright, now let's drop a few columns\n",
        "# Needed to drop quite a few categorical columns so that the data would fit in memory in Azure\n",
        "# Tested the model before and after (from 6388 columns to 278) in Colab and only had a ~0.03% reduction in performance\n",
        "\n",
        "def removal(df):\n",
        "  # id: we drop the id column because it is not a useful predictor.\n",
        "  # amount_tsh: is mostly blank - delete\n",
        "  # wpt_name: not useful, delete (too many values)\n",
        "  # subvillage: too many values, delete\n",
        "  # scheme_name: this is almost 50% nulls, so we will delete this column\n",
        "  # num_private: we will delete this column because ~99% of the values are zeros.\n",
        "  features_to_drop = ['id','amount_tsh',  'num_private', \n",
        "          'quantity', 'quality_group', 'source_type', 'payment', \n",
        "          'waterpoint_type_group', 'extraction_type_group', 'wpt_name', \n",
        "          'subvillage', 'scheme_name', 'funder', 'installer', 'recorded_by',\n",
        "          'ward']\n",
        "  df = df.drop(features_to_drop, axis=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "def dummy(df):\n",
        "    dummy_cols = ['basin', 'lga', 'public_meeting',\n",
        "       'scheme_management', 'permit', 'extraction_type',\n",
        "       'extraction_type_class', 'management', 'management_group',\n",
        "       'payment_type', 'water_quality', 'quantity_group', 'source',\n",
        "       'source_class', 'waterpoint_type', 'region']\n",
        "\n",
        "    df = pd.get_dummies(df, columns=dummy_cols)\n",
        "\n",
        "    return df\n",
        "\n",
        "def dates(df):\n",
        "    \"\"\"\n",
        "    date_recorded: this might be a useful variable for this analysis, although the year itself would be useless in a practical scenario moving into the future. We will convert this column into a datetime, and we will also create 'year_recorded' and 'month_recorded' columns just in case those levels prove to be useful. A visual inspection of both casts significant doubt on that possibility, but we'll proceed for now. We will delete date_recorded itself, since random forest cannot accept datetime\n",
        "    \"\"\"\n",
        "    df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
        "    df['year_recorded'] = df['date_recorded'].apply(lambda x: x.year)\n",
        "    df['month_recorded'] = df['date_recorded'].apply(lambda x: x.month)\n",
        "    df['date_recorded'] = (pd.to_datetime(df['date_recorded'])).apply(lambda x: x.toordinal())\n",
        "    return df\n",
        "\n",
        "def dates2(df):\n",
        "    \"\"\"\n",
        "    Turn year_recorded and month_recorded into dummy variables\n",
        "    \"\"\"\n",
        "    for z in ['month_recorded', 'year_recorded']:\n",
        "        df[z] = df[z].apply(lambda x: str(x))\n",
        "        good_cols = [z+'_'+i for i in df[z].unique()]\n",
        "        df = pd.concat((df, pd.get_dummies(df[z], prefix = z)[good_cols]), axis = 1)\n",
        "        del df[z]\n",
        "    return df\n",
        "\n",
        "def small_n(df):\n",
        "    \"Collapsing small categorical value counts into 'other'\"\n",
        "    cols = [i for i in df.columns if type(df[i].iloc[0]) == str]\n",
        "    df[cols] = df[cols].where(df[cols].apply(lambda x: x.map(x.value_counts())) > 100, \"other\")\n",
        "    return df"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "id": "tVGom3TYuwx_",
        "gather": {
          "logged": 1618515532564
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "\n",
        "We'll be using the Pump it Up dataset from the DrivenData competition.\n",
        "\n",
        "The description of the problem: \n",
        "\n",
        "> Using data from Taarifa and the Tanzanian Ministry of Water, can you predict which pumps are functional, which need some repairs, and which don't work at all? This is an intermediate-level practice competition. Predict one of these three classes based on a number of variables about what kind of pump is operating, when it was installed, and how it is managed. A smart understanding of which waterpoints will fail can improve maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
        "\n",
        "In other words, our goal is to predict which water pumps are non-functioning or functioning, but in need of repair.\n",
        "\n",
        "In this project, we will train a model using AutoML to train multiple multiple and choose the best performing model for deployment."
      ],
      "metadata": {
        "id": "NpdvmaVVWXWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We loaded the dataset into Azure and we are grabbing it here.\n",
        "\n",
        "from azureml.core import Workspace, Experiment, Dataset\n",
        "# from feature_preprocessing import *\n",
        "\n",
        "# download config file in azure and put it in the current Notebooks folder\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"Pump-it-Up-Data-Mining-the-Water-Table\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()\n",
        "\n",
        "# download config file in azure and put it in the current Notebooks folder\n",
        "ws = run.experiment.workspace\n",
        "\n",
        "dataset = Dataset.get_by_name(ws, name='Pump-it-Up-dataset')\n",
        "X = dataset.to_pandas_dataframe()\n",
        "y = X[['status_group']]\n",
        "del X['status_group']\n",
        "\n",
        "# Cleaning up the features of our dataset\n",
        "X = bools(X)\n",
        "X = locs(X)\n",
        "X = construction(X)\n",
        "X = removal(X)\n",
        "X = dummy(X)\n",
        "X = dates(X)\n",
        "x = dates2(X)\n",
        "X = small_n(X)\n",
        "\n",
        "# Removing \">\", \"[\" and \"]\" from the headers to make the data compatible with different algorithms (namely, xgboost)\n",
        "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
        "X.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X.columns.values]\n",
        "\n",
        "# Converting the population values to log\n",
        "X['population'] = np.log(X['population'])\n",
        "\n",
        "# Splitting the dataset into a training and test set\n",
        "# Test set will be used later\n",
        "# The same random seed (42) for the Hyperdrive model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Concatenating the features and labels together to feed to our AutoML model\n",
        "clean_train_df = pd.concat([X_train, y_train], axis=1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Workspace name: quick-starts-ws-142798\n",
            "Azure region: southcentralus\n",
            "Subscription id: 3e42d11f-d64d-4173-af9b-12ecaa1030b3\n",
            "Resource group: aml-quickstarts-142798\n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "id": "uuj67ZSm4LIE",
        "gather": {
          "logged": 1618515551889
        },
        "outputId": "3a2d67df-0635-4c33-d978-eea734c66aec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Get the default datastore to be entered as a parameter in tabular dataset creation\n",
        "datastore = ws.get_default_datastore()\n",
        "\n",
        "# Change pandas dataframe into a tabular dataset to be used in automl\n",
        "testing_data = TabularDatasetFactory.register_pandas_dataframe(X_test, datastore, 'automl_data_test')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Method register_pandas_dataframe: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/56c4ca64-b495-42f8-9b68-82ff83e46833/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618515559015
        },
        "id": "iADh-as2aHBt",
        "outputId": "6873e0bb-9023-4654-9838-3fb21efceaee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Get the default datastore to be entered as a parameter in tabular dataset creation\n",
        "datastore = ws.get_default_datastore()\n",
        "\n",
        "# Change pandas dataframe into a tabular dataset to be used in automl\n",
        "training_data = TabularDatasetFactory.register_pandas_dataframe(clean_train_df, datastore, 'automl_data')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Method register_pandas_dataframe: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/b04c79fa-a825-4845-9cfb-6e9970f2c260/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "id": "law5FINf4LIE",
        "gather": {
          "logged": 1618515576407
        },
        "outputId": "4c0ef9f4-987c-4d8e-9286-228dc61a8b1a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.take(3).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "   date_recorded  gps_height  longitude  latitude  region_code  district_code  \\\n0         734926      2092.0  35.426020 -4.227446           21              1   \n1         734213       550.0  35.510074 -5.724555            1              6   \n2         734328       550.0  32.499866 -9.081222           12              6   \n\n   population  construction_year  basin_Internal  basin_Lake Nyasa  ...  \\\n0    5.075174               1998               1                 0  ...   \n1    5.298317               1910               1                 0  ...   \n2    5.298317               1910               0                 0  ...   \n\n   region_Pwani  region_Rukwa  region_Ruvuma  region_Shinyanga  \\\n0             0             0              0                 0   \n1             0             0              0                 0   \n2             0             0              0                 0   \n\n   region_Singida  region_Tabora  region_Tanga  year_recorded  month_recorded  \\\n0               0              0             0           2013               2   \n1               0              0             0           2011               3   \n2               0              0             0           2011               7   \n\n     status_group  \n0      functional  \n1      functional  \n2  non functional  \n\n[3 rows x 264 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date_recorded</th>\n      <th>gps_height</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>region_code</th>\n      <th>district_code</th>\n      <th>population</th>\n      <th>construction_year</th>\n      <th>basin_Internal</th>\n      <th>basin_Lake Nyasa</th>\n      <th>...</th>\n      <th>region_Pwani</th>\n      <th>region_Rukwa</th>\n      <th>region_Ruvuma</th>\n      <th>region_Shinyanga</th>\n      <th>region_Singida</th>\n      <th>region_Tabora</th>\n      <th>region_Tanga</th>\n      <th>year_recorded</th>\n      <th>month_recorded</th>\n      <th>status_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>734926</td>\n      <td>2092.0</td>\n      <td>35.426020</td>\n      <td>-4.227446</td>\n      <td>21</td>\n      <td>1</td>\n      <td>5.075174</td>\n      <td>1998</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2013</td>\n      <td>2</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>734213</td>\n      <td>550.0</td>\n      <td>35.510074</td>\n      <td>-5.724555</td>\n      <td>1</td>\n      <td>6</td>\n      <td>5.298317</td>\n      <td>1910</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2011</td>\n      <td>3</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>734328</td>\n      <td>550.0</td>\n      <td>32.499866</td>\n      <td>-9.081222</td>\n      <td>12</td>\n      <td>6</td>\n      <td>5.298317</td>\n      <td>1910</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2011</td>\n      <td>7</td>\n      <td>non functional</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 264 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "id": "WChG_Wzp8oXg",
        "gather": {
          "logged": 1618515577077
        },
        "outputId": "7aa7553a-2e2d-4f0b-dfea-a170a3b7d4ab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Experiment\n",
        "\n",
        "We'll create a new experiment for our deployment of an AutoML model and create a project folder to hold the training scripts."
      ],
      "metadata": {
        "id": "lUqJbckB5HD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = 'automl-pump-it-up-operationalize'\n",
        "project_folder = './automl-pipeline-project'\n",
        "\n",
        "automl_experiment = Experiment(ws, experiment_name)\n",
        "automl_experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "Experiment(Name: automl-pump-it-up-operationalize,\nWorkspace: quick-starts-ws-142798)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automl-pump-it-up-operationalize</td><td>quick-starts-ws-142798</td><td><a href=\"https://ml.azure.com/experiments/id/0c534afe-6722-4a07-a491-95523b15de85?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-142798/workspaces/quick-starts-ws-142798&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "id": "ZlKWTS0g5GBg",
        "gather": {
          "logged": 1618515579190
        },
        "outputId": "1247f68e-8a85-48bf-8ac5-0c7108bbb430"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Creating a compute cluster if there isn't one that is already created.\n",
        "\n",
        "cpu_cluster_name = 'hypr-auto-clustr'\n",
        "\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new computer target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_v2',\n",
        "                                                          max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "    \n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating a new computer target...\n",
            "Creating....\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618515605723
        },
        "id": "X75NT0jXNVw7",
        "outputId": "156b378d-7a1d-42fc-ca21-92a527385c23"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoML Configuration\n",
        "\n",
        "We'll create a new experiment for our deployment of an AutoML model and create a project folder to hold the training scripts.\n",
        "\n",
        "Here we create the general AutoML settings object.\n",
        "\n",
        "\n",
        "Calculate recall to test how well we do on True Positives. We can imagine a real scenario where we want to build a model that does not miss the non-functioning water pumps, and we care much less functioning water pumps that are incorrectly predicted as non-functional. Recall is useful to make sure we miss less True Positives."
      ],
      "metadata": {
        "id": "ng9WKfEN9FVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Note: We are using `norm_macro_recall` for the primary metric here, but that is not the metric we actually want\n",
        "# our model to perform the best on. As described in the readme, we want `recall_score_micro`. However,\n",
        "# we cannot use `recall_score_micro` as our primary metric because AutoML currently only allows a few primary metrics.\n",
        "# We decided to use `norm_macro_recall` because it was the closest metric to the one we actually wanted to evaluate.\n",
        "\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 120, # to set a limit on the amount of time AutoML will be running\n",
        "    \"max_concurrent_iterations\": 5, # applies to the compute target we are using\n",
        "    \"primary_metric\" : 'norm_macro_recall' # recall for our primary metric\n",
        "}\n",
        "\n",
        "# Setting AutoML config for model training.\n",
        "\n",
        "automl_config = AutoMLConfig(compute_target=cpu_cluster,\n",
        "                             task = \"classification\", # classifying if water pumps are functional\n",
        "                             training_data=training_data, \n",
        "                             label_column_name=\"status_group\", # our target variable for water pump function  \n",
        "                             path = project_folder,\n",
        "                             enable_early_stopping= True, # prevents automl from spending too much time on models that stopped improving, saves time and compute costs\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1618515607310
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "dYjR1WTR4LIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Pipeline and AutoMLStep\n",
        "\n",
        "Defining the outputs for the AutoMLStep using TrainingOutput."
      ],
      "metadata": {
        "id": "D6udoRSe9NW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
        "\n",
        "ds = ws.get_default_datastore()\n",
        "metrics_output_name = 'metrics_output'\n",
        "best_model_output_name = 'best_model_output'\n",
        "\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=metrics_output_name,\n",
        "                           training_output=TrainingOutput(type='Metrics'))\n",
        "model_data = PipelineData(name='model_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=best_model_output_name,\n",
        "                           training_output=TrainingOutput(type='Model'))"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "id": "9-xCEtpOZOVS",
        "gather": {
          "logged": 1618515608019
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the AutoMLStep"
      ],
      "metadata": {
        "id": "u-DVjxDp9dFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an AutoMLStep\n",
        "\n",
        "automl_step = AutoMLStep(\n",
        "    name='automl_module',\n",
        "    automl_config=automl_config,\n",
        "    outputs=[metrics_data, model_data],\n",
        "    allow_reuse=True\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "id": "8yDcosARZa7K",
        "gather": {
          "logged": 1618515609806
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Pipeline\n",
        "\n",
        "from azureml.pipeline.core import Pipeline\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    description=\"pipeline_with_automlstep\",\n",
        "    workspace=ws,    \n",
        "    steps=[automl_step])"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "id": "D8uIv-9iZjo3",
        "gather": {
          "logged": 1618515610785
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Submitting AutoML experiment...')\n",
        "\n",
        "pipeline_run = automl_experiment.submit(pipeline)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting AutoML experiment...\n",
            "Created step automl_module [b97f12be][34f1ff41-ccb7-4ded-bd3b-2f9d3554ae6b], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun bdabd576-1a42-4007-915e-adcbb6769e28\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/bdabd576-1a42-4007-915e-adcbb6769e28?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-142798/workspaces/quick-starts-ws-142798&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "id": "Pg-NU8vuZp6Z",
        "gather": {
          "logged": 1618515616701
        },
        "outputId": "1be08aff-48cc-4c7d-d6d5-98475b7ddb3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Details\n",
        "\n",
        "Using the RunDetails widget to show the different experiments."
      ],
      "metadata": {
        "id": "xrTPvoOJb4Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(pipeline_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "87c66796097c460a9e899a4c440dd512"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/bdabd576-1a42-4007-915e-adcbb6769e28?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-142798/workspaces/quick-starts-ws-142798&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"bdabd576-1a42-4007-915e-adcbb6769e28\", \"run_properties\": {\"run_id\": \"bdabd576-1a42-4007-915e-adcbb6769e28\", \"created_utc\": \"2021-04-15T19:40:14.742649Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-04-15T20:39:08.282894Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlstrg142798.blob.core.windows.net/azureml/ExperimentRun/dcid.bdabd576-1a42-4007-915e-adcbb6769e28/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=kR2KhIRIAYMxMKU6UCNE0GttknlmWb%2FOHzZ1u3o3%2FaM%3D&st=2021-04-15T23%3A32%3A34Z&se=2021-04-16T07%3A42%3A34Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlstrg142798.blob.core.windows.net/azureml/ExperimentRun/dcid.bdabd576-1a42-4007-915e-adcbb6769e28/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=yYeEHAliOB%2Bazl7sWiP42HGQxArx%2FZWSIaY6Lf8iQL8%3D&st=2021-04-15T23%3A32%3A34Z&se=2021-04-16T07%3A42%3A34Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlstrg142798.blob.core.windows.net/azureml/ExperimentRun/dcid.bdabd576-1a42-4007-915e-adcbb6769e28/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=ZNX%2FY%2FEkJfEu5FNuc%2FQPfgsD3fBkTrNcF5nNbQZ8JIA%3D&st=2021-04-15T23%3A32%3A34Z&se=2021-04-16T07%3A42%3A34Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:58:53\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da\", \"name\": \"automl_module\", \"status\": \"Finished\", \"start_time\": \"2021-04-15T19:40:50.860317Z\", \"created_time\": \"2021-04-15T19:40:24.389431Z\", \"end_time\": \"2021-04-15T20:36:24.410379Z\", \"duration\": \"0:56:00\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-04-15T19:40:24.389431Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-04-15 19:40:24Z] Submitting 1 runs, first five are: b97f12be:7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da\\n[2021-04-15 20:39:07Z] Completing processing run id 7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"3f7fb40f\": {\"node_id\": \"3f7fb40f\", \"name\": \"automl_data\"}}, \"module_nodes\": {\"b97f12be\": {\"node_id\": \"b97f12be\", \"name\": \"automl_module\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da\"}}, \"edges\": [{\"source_node_id\": \"3f7fb40f\", \"source_node_name\": \"automl_data\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"b97f12be\", \"dst_node_name\": \"automl_module\"}], \"child_runs\": [{\"run_id\": \"7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da\", \"name\": \"automl_module\", \"status\": \"Finished\", \"start_time\": \"2021-04-15T19:40:50.860317Z\", \"created_time\": \"2021-04-15T19:40:24.389431Z\", \"end_time\": \"2021-04-15T20:36:24.410379Z\", \"duration\": \"0:56:00\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-04-15T19:40:24.389431Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.26.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "id": "4wYnNdUEZ_7G",
        "gather": {
          "logged": 1618515617953
        },
        "colab": {
          "referenced_widgets": [
            "288bde079a694ec896843c326d2bfca8",
            "fa8c5ee0ca814d36937cae7b0c98427f"
          ]
        },
        "outputId": "b6155b2b-2abf-4c64-9a75-9b41cc3b1c2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: bdabd576-1a42-4007-915e-adcbb6769e28\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/bdabd576-1a42-4007-915e-adcbb6769e28?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-142798/workspaces/quick-starts-ws-142798&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
            "PipelineRun Status: NotStarted\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da?wsid=/subscriptions/3e42d11f-d64d-4173-af9b-12ecaa1030b3/resourcegroups/aml-quickstarts-142798/workspaces/quick-starts-ws-142798&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
            "StepRun( automl_module ) Status: NotStarted\n",
            "StepRun( automl_module ) Status: Running\n",
            "\n",
            "StepRun(automl_module) Execution Summary\n",
            "=========================================\n",
            "StepRun( automl_module ) Status: Finished\n",
            "{'runId': '7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da', 'target': 'hypr-auto-clustr', 'status': 'Completed', 'startTimeUtc': '2021-04-15T19:40:50.860317Z', 'endTimeUtc': '2021-04-15T20:36:24.410379Z', 'properties': {'ContentSnapshotId': '44518cb1-eb7b-45fa-bbb2-558f8a36076a', 'StepType': 'AutoMLStep', 'azureml.moduleid': '34f1ff41-ccb7-4ded-bd3b-2f9d3554ae6b', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'b97f12be', 'azureml.pipelinerunid': 'bdabd576-1a42-4007-915e-adcbb6769e28', 'num_iterations': '1000', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'norm_macro_recall', 'train_split': '0', 'MaxTimeSeconds': None, 'acquisition_parameter': '0', 'num_cross_validation': None, 'target': 'hypr-auto-clustr', 'RawAMLSettingsString': None, 'AMLSettingsJsonString': '{\"path\": null, \"name\": \"placeholder\", \"subscription_id\": \"3e42d11f-d64d-4173-af9b-12ecaa1030b3\", \"resource_group\": \"aml-quickstarts-142798\", \"workspace_name\": \"quick-starts-ws-142798\", \"region\": \"southcentralus\", \"compute_target\": \"hypr-auto-clustr\", \"spark_service\": null, \"azure_service\": null, \"many_models\": false, \"pipeline_fetch_max_batch_size\": 1, \"enable_batch_run\": false, \"enable_run_restructure\": false, \"iterations\": 1000, \"primary_metric\": \"norm_macro_recall\", \"task_type\": \"classification\", \"data_script\": null, \"test_size\": 0.0, \"validation_size\": 0.0, \"n_cross_validations\": null, \"y_min\": null, \"y_max\": null, \"num_classes\": null, \"featurization\": \"auto\", \"_ignore_package_version_incompatibilities\": false, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 5, \"iteration_timeout_minutes\": null, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": 120, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": null, \"supported_models\": [\"TensorFlowLinearClassifier\", \"LightGBM\", \"DecisionTree\", \"AveragedPerceptronClassifier\", \"BernoulliNaiveBayes\", \"RandomForest\", \"KNN\", \"ExtremeRandomTrees\", \"LogisticRegression\", \"GradientBoosting\", \"MultinomialNaiveBayes\", \"SGD\", \"XGBoostClassifier\", \"LinearSVM\", \"SVM\", \"TensorFlowDNN\"], \"private_models\": [], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"_debug_log\": \"automl_errors.log\", \"show_warnings\": false, \"model_explainability\": true, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": \"STANDARD_D2_V2\", \"telemetry_verbosity\": 20, \"send_telemetry\": true, \"enable_dnn\": false, \"scenario\": \"SDK-1.13.0\", \"environment_label\": null, \"save_mlflow\": false, \"force_text_dnn\": false, \"enable_feature_sweeping\": true, \"enable_early_stopping\": true, \"early_stopping_n_iters\": 10, \"metrics\": null, \"enable_metric_confidence\": false, \"enable_ensembling\": true, \"enable_stack_ensembling\": true, \"ensemble_iterations\": 15, \"enable_tf\": false, \"enable_subsampling\": null, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"force_streaming\": false, \"track_child_runs\": true, \"allowed_private_models\": [], \"label_column_name\": \"status_group\", \"weight_column_name\": null, \"cv_split_column_names\": null, \"enable_local_managed\": false, \"_local_managed_run_id\": null, \"cost_mode\": 1, \"lag_length\": 0, \"metric_operation\": \"maximize\", \"preprocess\": true}', 'DataPrepJsonString': '{\\\\\"training_data\\\\\": {\\\\\"datasetId\\\\\": \\\\\"3fd300af-2168-46f7-a3bb-e31b0b42fec1\\\\\"}, \\\\\"datasets\\\\\": 0}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'Orchestrator': 'automl', 'ClientType': 'Others', '_aml_system_scenario_identification': 'Remote.Parent', 'root_attribution': 'azureml.StepRun', 'snapshotId': '44518cb1-eb7b-45fa-bbb2-558f8a36076a', 'SetupRunId': '7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_setup', 'SetupRunContainerId': 'dcid.7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_setup', 'ClientSdkVersion': '1.26.0', 'FeaturizationRunJsonPath': 'featurizer_container.json', 'FeaturizationRunId': '7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_featurize', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"dataset_classes\": 3, \"dataset_features\": 322, \"dataset_samples\": 42768, \"single_frequency_class_detected\": false}', 'ModelExplainRunId': '7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_ModelExplain'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlstrg142798.blob.core.windows.net/azureml/ExperimentRun/dcid.7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=iJr1GLn9dx4XSmDIFaHZR8f8XavQTN12mkP9UUHNH%2B0%3D&st=2021-04-15T19%3A30%3A30Z&se=2021-04-16T03%3A40%3A30Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlstrg142798.blob.core.windows.net/azureml/ExperimentRun/dcid.7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=%2F3oHRJCLsuyiyaKYCQ0NQomWaYqjEBrr6o4oW7T2JKU%3D&st=2021-04-15T19%3A30%3A30Z&se=2021-04-16T03%3A40%3A30Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlstrg142798.blob.core.windows.net/azureml/ExperimentRun/dcid.7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=uJbiIOYqKRxDz74wvHNYf52SsUWJLiGE1Ub8MaCWfU8%3D&st=2021-04-15T19%3A30%3A30Z&se=2021-04-16T03%3A40%3A30Z&sp=r'}, 'submittedBy': 'ODL_User 142798'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': 'bdabd576-1a42-4007-915e-adcbb6769e28', 'status': 'Completed', 'startTimeUtc': '2021-04-15T19:40:18.926321Z', 'endTimeUtc': '2021-04-15T20:39:08.282894Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlstrg142798.blob.core.windows.net/azureml/ExperimentRun/dcid.bdabd576-1a42-4007-915e-adcbb6769e28/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=mBDyS1ke00Lr%2FafnsY8f4glu3RvMLtq%2BY6aCUQINyVo%3D&st=2021-04-15T19%3A30%3A39Z&se=2021-04-16T03%3A40%3A39Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlstrg142798.blob.core.windows.net/azureml/ExperimentRun/dcid.bdabd576-1a42-4007-915e-adcbb6769e28/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=sKK3VafS5f8mXuGg3%2FZ3Pbt8%2BSpeSefx3YBCUfaI848%3D&st=2021-04-15T19%3A30%3A39Z&se=2021-04-16T03%3A40%3A39Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlstrg142798.blob.core.windows.net/azureml/ExperimentRun/dcid.bdabd576-1a42-4007-915e-adcbb6769e28/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=d%2FwKVE6kcqxmPmew6smV%2FCAjs5tuM%2B%2FbFA4iaQITtfA%3D&st=2021-04-15T19%3A30%3A39Z&se=2021-04-16T03%3A40%3A39Z&sp=r'}, 'submittedBy': 'ODL_User 142798'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "id": "Mbk5-oAiaCvS",
        "gather": {
          "logged": 1618519149559
        },
        "outputId": "a6476728-6636-4b81-c129-9a430164c847"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examine Results\n",
        "\n",
        "# Retrive the metrics of all child runs"
      ],
      "metadata": {
        "id": "l6onN6m69zUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
        "num_file_downloaded = metrics_output.download('.', show_progress=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading azureml/7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da/metrics_data\n",
            "Downloaded azureml/7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da/metrics_data, 1 files out of an estimated total of 1\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {
        "id": "vnfQf6xGabw7",
        "gather": {
          "logged": 1618519159769
        },
        "outputId": "55175c35-16b8-4fcd-daa7-2d718e1a6823"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(metrics_output._path_on_datastore) as f:\n",
        "    metrics_output_result = f.read()\n",
        "    \n",
        "deserialized_metrics_output = json.loads(metrics_output_result)\n",
        "df = pd.DataFrame(deserialized_metrics_output)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "df_t = df.T\n",
        "df_t['recall_score_micro'].sort_values()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_12    [0.5315656565656566]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_30    [0.5429292929292929]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_25    [0.5429292929292929]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_9     [0.5761784511784511]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_18    [0.5940656565656566]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_14    [0.5949074074074074]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_11    [0.5991161616161617]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_4     [0.6005892255892256]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_10     [0.601010101010101]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_15    [0.6062710437710438]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_2     [0.6111111111111112]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_29    [0.6279461279461279]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_19    [0.6289983164983165]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_24    [0.6561447811447811]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_5     [0.6641414141414141]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_17    [0.6778198653198653]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_22    [0.6900252525252525]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_6       [0.69760101010101]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_7     [0.7028619528619529]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_3     [0.7037037037037037]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_33    [0.7055976430976431]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_31    [0.7062289562289562]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_13    [0.7106481481481481]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_38    [0.7140151515151515]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_28    [0.7140151515151515]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_8     [0.7184343434343434]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_43    [0.7232744107744108]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_32    [0.7276936026936027]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_20    [0.7293771043771043]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_16    [0.7306397306397306]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_37    [0.7359006734006734]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_42    [0.7403198653198653]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_34    [0.7407407407407407]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_44    [0.7453703703703703]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_49                  [0.75]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_41    [0.7542087542087542]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_23    [0.7550505050505051]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_1     [0.7563131313131313]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_40    [0.7607323232323232]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_21    [0.7613636363636364]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_35    [0.7634680134680135]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_36     [0.764520202020202]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_50    [0.7689393939393939]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_39    [0.7693602693602694]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_26    [0.7815656565656566]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_0     [0.7868265993265994]\n7a7d7a63-3bb8-42de-b1a1-2d9e0e94c8da_27    [0.8106060606060606]\nName: recall_score_micro, dtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "id": "j3D5X1aEaeT8",
        "gather": {
          "logged": 1618519160035
        },
        "outputId": "a774e36a-6b86-4fcb-f00f-2534bc7d2ff2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Model"
      ],
      "metadata": {
        "id": "4C37uiNk-IHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl.run import AutoMLRun\n",
        "best_recall_run_id = df_t['recall_score_micro'].str.get(0).idxmax() # get string for best recall_score_micro run\n",
        "automl_run = AutoMLRun(automl_experiment, run_id=best_recall_run_id)\n",
        "automl_run.download_files()"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618519160719
        },
        "id": "jYckr8AAaHB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('outputs/model.pkl', \"rb\" ) as f:\n",
        "    best_model = pickle.load(f)\n",
        "best_model"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "PipelineWithYTransformations(Pipeline={'memory': None,\n                                       'steps': [('datatransformer',\n                                                  DataTransformer(enable_dnn=None,\n                                                                  enable_feature_sweeping=None,\n                                                                  feature_sweeping_config=None,\n                                                                  feature_sweeping_timeout=None,\n                                                                  featurization_config=None,\n                                                                  force_text_dnn=None,\n                                                                  is_cross_validation=None,\n                                                                  is_onnx_compatible=None,\n                                                                  logger=None,\n                                                                  observer=None,\n                                                                  task=None,\n                                                                  working_dir=None))...\n                                                                    max_depth=5,\n                                                                    max_leaves=0,\n                                                                    min_child_weight=1,\n                                                                    missing=nan,\n                                                                    n_estimators=800,\n                                                                    n_jobs=1,\n                                                                    nthread=None,\n                                                                    objective='multi:softprob',\n                                                                    random_state=0,\n                                                                    reg_alpha=0.8333333333333334,\n                                                                    reg_lambda=0.625,\n                                                                    scale_pos_weight=1,\n                                                                    seed=None,\n                                                                    silent=None,\n                                                                    subsample=0.7,\n                                                                    tree_method='auto',\n                                                                    verbose=-10,\n                                                                    verbosity=0))],\n                                       'verbose': False},\n                             y_transformer={},\n                             y_transformer_name='LabelEncoder')"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "id": "Yo4EdSyOae-b",
        "gather": {
          "logged": 1618519173336
        },
        "outputId": "9c79fac2-93fa-4e8b-f933-154498c41235"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# As we can see, MaxAbsScaler LightGBMClassifier performed the best on recall_score_micro\r\n",
        "best_model.steps"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "[('datatransformer',\n  DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n                  feature_sweeping_config=None, feature_sweeping_timeout=None,\n                  featurization_config=None, force_text_dnn=None,\n                  is_cross_validation=None, is_onnx_compatible=None, logger=None,\n                  observer=None, task=None, working_dir=None)),\n ('StandardScalerWrapper',\n  <azureml.automl.runtime.shared.model_wrappers.StandardScalerWrapper at 0x7f8ed23ec198>),\n ('XGBoostClassifier',\n  XGBoostClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n                    colsample_bynode=1, colsample_bytree=1, eta=0.3, gamma=0,\n                    learning_rate=0.1, max_delta_step=0, max_depth=5,\n                    max_leaves=0, min_child_weight=1, missing=nan,\n                    n_estimators=800, n_jobs=1, nthread=None,\n                    objective='multi:softprob', random_state=0,\n                    reg_alpha=0.8333333333333334, reg_lambda=0.625,\n                    scale_pos_weight=1, seed=None, silent=None, subsample=0.7,\n                    tree_method='auto', verbose=-10, verbosity=0))]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 20,
      "metadata": {
        "id": "9RMLJGX_afA2",
        "gather": {
          "logged": 1618519173599
        },
        "outputId": "05df2679-044e-419c-900c-fef989b0b9de"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model on the Test Set"
      ],
      "metadata": {
        "id": "q0hjMqcq-Z1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# important because registering data with TabularDatasetFactory might change column names (it did in this case)\r\n",
        "# If column names change and you only registered X_train, there will be a mismatch unless you do the same with X_test\r\n",
        "X_testing = testing_data.to_pandas_dataframe() "
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618519173875
        },
        "id": "sIFeLIraaHB8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Predict on the Test Set\n",
        "ypred = best_model.predict(X_testing)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, ypred, average='micro')\n",
        "print('Recall Micro: %.3f' % recall)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall Micro: 0.803\n"
          ]
        }
      ],
      "execution_count": 22,
      "metadata": {
        "id": "Bkh8yPVAafGG",
        "gather": {
          "logged": 1618519179676
        },
        "outputId": "2f82438d-fdaa-44b0-9aa4-3e4184ee8686"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, the score on `recall_score_micro` is higher with the LightGBMClassifer than it was with the Random Forest HyperDrive model (which was 0.765).\r\n",
        "\r\n",
        "Therefore, we will be deploying the best model we got with AutoML."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Deployment\n",
        "\n",
        "Registering the model, creating an inference config and deploy the model as a web service.\n",
        "\n",
        "In other words, we are publishing the pipeline to enable a REST endpoint to rerun the pipeline from any HTTP library on any platform."
      ],
      "metadata": {
        "id": "TxROfMr3BC-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "# Register model (with the best recall_score_micro performance)\n",
        "model = Model.register(model_path='outputs/model.pkl', \n",
        "                          model_name='automl_LightGBMClassifier',\n",
        "                          tags={'Training context':'Auto ML'},\n",
        "                          properties={'Recall_Micro': recall},\n",
        "                          workspace=ws)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Registering model automl_LightGBMClassifier\n"
          ]
        }
      ],
      "execution_count": 23,
      "metadata": {
        "id": "-Hjn8heOhsIn",
        "gather": {
          "logged": 1618519181885
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Move the model.pkl file from ./outputs to the base folder (./)."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing if prediction works in notebook before sending request to endpoint\r\n",
        "import json\r\n",
        "import joblib\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "model_path = Model.get_model_path('model.pkl')\r\n",
        "model_test = joblib.load(model_path)\r\n",
        "\r\n",
        "data = json.dumps(x_new)\r\n",
        "\r\n",
        "data_test = pd.DataFrame(json.loads(data)['data'])\r\n",
        "predictions_test = model_test.predict(data_test)\r\n",
        "\r\n",
        "# It works!\r\n",
        "predictions_test.tolist()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 64,
          "data": {
            "text/plain": "['non functional']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 64,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618525216699
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile score.py\n",
        "\n",
        "import json\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    global model\n",
        "    # Get the path to the registered model file and load it\n",
        "    model_path = Model.get_model_path('automl_LightGBMClassifier')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "# Called when a request is received\n",
        "def run(data):\n",
        "    # Get the input data as a numpy array\n",
        "    data = pd.DataFrame(json.loads(data)['data'])\n",
        "    # Get a prediction from the model\n",
        "    predictions = model.predict(data)\n",
        "    # Return the predictions as any JSON serializable format\n",
        "    return predictions.tolist()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting score.py\n"
          ]
        }
      ],
      "execution_count": 65,
      "metadata": {
        "id": "5XMcHSsRlLrK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# Add the dependencies for your model\n",
        "# We need to include all of these packages for deployment of the automl model\n",
        "# Otherwise the deployment will not work\n",
        "myenv = CondaDependencies()\n",
        "myenv.add_conda_package(\"scikit-learn==0.22.1\")\n",
        "myenv.add_conda_package(\"pandas==0.25.1\")\n",
        "myenv.add_conda_package(\"numpy>=1.16.0,<1.19.0\")\n",
        "myenv.add_conda_package(\"py-xgboost<=0.90\")\n",
        "myenv.add_conda_package(\"fbprophet==0.5\")\n",
        "myenv.add_conda_package(\"holidays==0.9.11\")\n",
        "myenv.add_conda_package(\"psutil>=5.2.2,<6.0.0\")\n",
        "myenv.add_pip_package(\"azureml-interpret==1.20.0\")\n",
        "myenv.add_pip_package(\"azureml-train-automl-runtime==1.20.0\")\n",
        "myenv.add_pip_package(\"inference-schema\")\n",
        "\n",
        "# Save the environment config as a .yml file\n",
        "env_file = './env.yml'\n",
        "with open(env_file,\"w\") as f:\n",
        "    f.write(myenv.serialize_to_string())\n",
        "print(\"Saved dependency info in\", env_file)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved dependency info in ./env.yml\n"
          ]
        }
      ],
      "execution_count": 76,
      "metadata": {
        "id": "JKk9sOBvleuA",
        "gather": {
          "logged": 1618527365250
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create inference_config\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "classifier_inference_config = InferenceConfig(runtime=\"python\",\n",
        "                                              source_directory = '.',\n",
        "                                              entry_script=\"score.py\",\n",
        "                                              conda_file=\"env.yml\")\n"
      ],
      "outputs": [],
      "execution_count": 77,
      "metadata": {
        "id": "E_mlymGRikMG",
        "gather": {
          "logged": 1618527369847
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "classifier_deploy_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
        "                                                              memory_gb = 1,\n",
        "                                                              enable_app_insights=True)"
      ],
      "outputs": [],
      "execution_count": 78,
      "metadata": {
        "id": "d4iRvCgNoZ7m",
        "gather": {
          "logged": 1618527370767
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "model = ws.models['automl_LightGBMClassifier']\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name = 'pump-it-up-deployed-service-3',\n",
        "                       models = [model],\n",
        "                       inference_config = classifier_inference_config,\n",
        "                       deployment_config = classifier_deploy_config)\n",
        "\n",
        "service.wait_for_deployment(show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-04-15 22:56:34+00:00 Creating Container Registry if not exists.\n",
            "2021-04-15 22:56:35+00:00 Registering the environment.\n",
            "2021-04-15 22:56:36+00:00 Building image..\n",
            "2021-04-15 23:09:54+00:00 Generating deployment configuration.\n",
            "2021-04-15 23:09:57+00:00 Submitting deployment to compute..\n",
            "2021-04-15 23:10:00+00:00 Checking the status of deployment pump-it-up-deployed-service-3..\n",
            "2021-04-15 23:14:35+00:00 Checking the status of inference endpoint pump-it-up-deployed-service-3.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ]
        }
      ],
      "execution_count": 79,
      "metadata": {
        "id": "MuTYOuTko8EJ",
        "gather": {
          "logged": 1618528486951
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(service.get_logs())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-04-15T23:14:30,650447000+00:00 - gunicorn/run \n",
            "2021-04-15T23:14:30,664591600+00:00 - iot-server/run \n",
            "2021-04-15T23:14:30,682268900+00:00 - nginx/run \n",
            "2021-04-15T23:14:30,683229500+00:00 - rsyslog/run \n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "rsyslogd: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2021-04-15T23:14:31,006424900+00:00 - iot-server/finish 1 0\n",
            "2021-04-15T23:14:31,040275100+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "Starting gunicorn 19.9.0\n",
            "Listening at: http://127.0.0.1:31311 (72)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 100\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Generating new fontManager, this may take some time...\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-dataset-runtime 1.26.0 (/azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/python3.6/site-packages), Requirement.parse('azureml-dataset-runtime~=1.20.0'), {'azureml-automl-core'}).\n",
            "Initializing logger\n",
            "2021-04-15 23:14:35,167 | root | INFO | Starting up app insights client\n",
            "2021-04-15 23:14:35,168 | root | INFO | Starting up request id generator\n",
            "2021-04-15 23:14:35,168 | root | INFO | Starting up app insight hooks\n",
            "2021-04-15 23:14:35,168 | root | INFO | Invoking user's init function\n",
            "2021-04-15 23:14:38,930 | root | INFO | Users's init has completed successfully\n",
            "2021-04-15 23:14:38,933 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-04-15 23:14:38,933 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-04-15 23:14:38,938 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-04-15 23:14:42,173 | root | INFO | Swagger file not present\n",
            "2021-04-15 23:14:42,173 | root | INFO | 404\n",
            "127.0.0.1 - - [15/Apr/2021:23:14:42 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "2021-04-15 23:14:46,472 | root | INFO | Swagger file not present\n",
            "2021-04-15 23:14:46,473 | root | INFO | 404\n",
            "127.0.0.1 - - [15/Apr/2021:23:14:46 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "\n"
          ]
        }
      ],
      "execution_count": 80,
      "metadata": {
        "id": "kx1q8WHbpzvv",
        "gather": {
          "logged": 1618528506898
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the Deployed Model\n",
        "\n",
        "Here we will send a request to the deployed model to test it.\n",
        "\n"
      ],
      "metadata": {
        "id": "DF7As6zVBew1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "endpoint = service.scoring_uri\n",
        "\n",
        "print(f'\\nservice state: {service.state}\\n')\n",
        "print(f'scoring URI: \\n{endpoint}\\n')\n",
        "print(f'swagger URI: \\n{service.swagger_uri}\\n')\n",
        "\n",
        "print(endpoint)\n",
        "print(service.swagger_uri)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "service state: Healthy\n",
            "\n",
            "scoring URI: \n",
            "http://de2b48a0-32b4-4e5a-baff-1f04641f3faf.southcentralus.azurecontainer.io/score\n",
            "\n",
            "swagger URI: \n",
            "http://de2b48a0-32b4-4e5a-baff-1f04641f3faf.southcentralus.azurecontainer.io/swagger.json\n",
            "\n",
            "http://de2b48a0-32b4-4e5a-baff-1f04641f3faf.southcentralus.azurecontainer.io/score\n",
            "http://de2b48a0-32b4-4e5a-baff-1f04641f3faf.southcentralus.azurecontainer.io/swagger.json\n"
          ]
        }
      ],
      "execution_count": 81,
      "metadata": {
        "id": "heGk6iM4ar9f",
        "gather": {
          "logged": 1618528512893
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_testing.loc[10]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 82,
          "data": {
            "text/plain": "date_recorded    734244.00\ngps_height         1181.00\nlongitude            36.11\nlatitude             -4.91\nregion_code           1.00\n                    ...   \nregion_Singida        0.00\nregion_Tabora         0.00\nregion_Tanga          0.00\nyear_recorded      2011.00\nmonth_recorded        4.00\nName: 10, Length: 263, dtype: float64"
          },
          "metadata": {}
        }
      ],
      "execution_count": 82,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618528514947
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_new = pd.DataFrame(X_testing.loc[10]).T # grabbing a random example for testing the webservice\r\n",
        "# x_new.columns = x_new.columns.str.replace(r\"[^a-zA-Z\\d_]+\", \"\")\r\n",
        "x_new = x_new.T.rename(columns={10: \"data\"})\r\n",
        "x_new = x_new.to_dict()\r\n",
        "x_new = {\"data\": [x_new['data']]}\r\n",
        "x_new"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 83,
          "data": {
            "text/plain": "{'data': [{'date_recorded': 734244.0,\n   'gps_height': 1181.0,\n   'longitude': 36.11237521,\n   'latitude': -4.91391433,\n   'region_code': 1.0,\n   'district_code': 1.0,\n   'population': 5.521460917862246,\n   'construction_year': 1910.0,\n   'basin_Internal': 1.0,\n   'basin_Lake Nyasa': 0.0,\n   'basin_Lake Rukwa': 0.0,\n   'basin_Lake Tanganyika': 0.0,\n   'basin_Lake Victoria': 0.0,\n   'basin_Pangani': 0.0,\n   'basin_Rufiji': 0.0,\n   'basin_Ruvuma / Southern Coast': 0.0,\n   'basin_Wami / Ruvu': 0.0,\n   'lga_Arusha Rural': 0.0,\n   'lga_Arusha Urban': 0.0,\n   'lga_Babati': 0.0,\n   'lga_Bagamoyo': 0.0,\n   'lga_Bahi': 0.0,\n   'lga_Bariadi': 0.0,\n   'lga_Biharamulo': 0.0,\n   'lga_Bukoba Rural': 0.0,\n   'lga_Bukoba Urban': 0.0,\n   'lga_Bukombe': 0.0,\n   'lga_Bunda': 0.0,\n   'lga_Chamwino': 0.0,\n   'lga_Chato': 0.0,\n   'lga_Chunya': 0.0,\n   'lga_Dodoma Urban': 0.0,\n   'lga_Geita': 0.0,\n   'lga_Hai': 0.0,\n   'lga_Hanang': 0.0,\n   'lga_Handeni': 0.0,\n   'lga_Igunga': 0.0,\n   'lga_Ilala': 0.0,\n   'lga_Ileje': 0.0,\n   'lga_Ilemela': 0.0,\n   'lga_Iramba': 0.0,\n   'lga_Iringa Rural': 0.0,\n   'lga_Kahama': 0.0,\n   'lga_Karagwe': 0.0,\n   'lga_Karatu': 0.0,\n   'lga_Kasulu': 0.0,\n   'lga_Kibaha': 0.0,\n   'lga_Kibondo': 0.0,\n   'lga_Kigoma Rural': 0.0,\n   'lga_Kigoma Urban': 0.0,\n   'lga_Kilindi': 0.0,\n   'lga_Kilolo': 0.0,\n   'lga_Kilombero': 0.0,\n   'lga_Kilosa': 0.0,\n   'lga_Kilwa': 0.0,\n   'lga_Kinondoni': 0.0,\n   'lga_Kisarawe': 0.0,\n   'lga_Kishapu': 0.0,\n   'lga_Kiteto': 0.0,\n   'lga_Kondoa': 1.0,\n   'lga_Kongwa': 0.0,\n   'lga_Korogwe': 0.0,\n   'lga_Kwimba': 0.0,\n   'lga_Kyela': 0.0,\n   'lga_Lindi Rural': 0.0,\n   'lga_Lindi Urban': 0.0,\n   'lga_Liwale': 0.0,\n   'lga_Longido': 0.0,\n   'lga_Ludewa': 0.0,\n   'lga_Lushoto': 0.0,\n   'lga_Mafia': 0.0,\n   'lga_Magu': 0.0,\n   'lga_Makete': 0.0,\n   'lga_Manyoni': 0.0,\n   'lga_Masasi': 0.0,\n   'lga_Maswa': 0.0,\n   'lga_Mbarali': 0.0,\n   'lga_Mbeya Rural': 0.0,\n   'lga_Mbinga': 0.0,\n   'lga_Mbozi': 0.0,\n   'lga_Mbulu': 0.0,\n   'lga_Meatu': 0.0,\n   'lga_Meru': 0.0,\n   'lga_Misenyi': 0.0,\n   'lga_Missungwi': 0.0,\n   'lga_Mkinga': 0.0,\n   'lga_Mkuranga': 0.0,\n   'lga_Monduli': 0.0,\n   'lga_Morogoro Rural': 0.0,\n   'lga_Morogoro Urban': 0.0,\n   'lga_Moshi Rural': 0.0,\n   'lga_Moshi Urban': 0.0,\n   'lga_Mpanda': 0.0,\n   'lga_Mpwapwa': 0.0,\n   'lga_Mtwara Rural': 0.0,\n   'lga_Mtwara Urban': 0.0,\n   'lga_Mufindi': 0.0,\n   'lga_Muheza': 0.0,\n   'lga_Muleba': 0.0,\n   'lga_Musoma Rural': 0.0,\n   'lga_Mvomero': 0.0,\n   'lga_Mwanga': 0.0,\n   'lga_Nachingwea': 0.0,\n   'lga_Namtumbo': 0.0,\n   'lga_Nanyumbu': 0.0,\n   'lga_Newala': 0.0,\n   'lga_Ngara': 0.0,\n   'lga_Ngorongoro': 0.0,\n   'lga_Njombe': 0.0,\n   'lga_Nkasi': 0.0,\n   'lga_Nyamagana': 0.0,\n   'lga_Nzega': 0.0,\n   'lga_Pangani': 0.0,\n   'lga_Rombo': 0.0,\n   'lga_Rorya': 0.0,\n   'lga_Ruangwa': 0.0,\n   'lga_Rufiji': 0.0,\n   'lga_Rungwe': 0.0,\n   'lga_Same': 0.0,\n   'lga_Sengerema': 0.0,\n   'lga_Serengeti': 0.0,\n   'lga_Shinyanga Rural': 0.0,\n   'lga_Shinyanga Urban': 0.0,\n   'lga_Siha': 0.0,\n   'lga_Sikonge': 0.0,\n   'lga_Simanjiro': 0.0,\n   'lga_Singida Rural': 0.0,\n   'lga_Singida Urban': 0.0,\n   'lga_Songea Rural': 0.0,\n   'lga_Songea Urban': 0.0,\n   'lga_Sumbawanga Rural': 0.0,\n   'lga_Sumbawanga Urban': 0.0,\n   'lga_Tabora Urban': 0.0,\n   'lga_Tandahimba': 0.0,\n   'lga_Tanga': 0.0,\n   'lga_Tarime': 0.0,\n   'lga_Temeke': 0.0,\n   'lga_Tunduru': 0.0,\n   'lga_Ukerewe': 0.0,\n   'lga_Ulanga': 0.0,\n   'lga_Urambo': 0.0,\n   'lga_Uyui': 0.0,\n   'public_meeting_0_0': 0.0,\n   'public_meeting_1_0': 1.0,\n   'scheme_management_Company': 0.0,\n   'scheme_management_None': 0.0,\n   'scheme_management_Other': 0.0,\n   'scheme_management_Parastatal': 0.0,\n   'scheme_management_Private operator': 0.0,\n   'scheme_management_SWC': 0.0,\n   'scheme_management_Trust': 0.0,\n   'scheme_management_VWC': 1.0,\n   'scheme_management_WUA': 0.0,\n   'scheme_management_WUG': 0.0,\n   'scheme_management_Water Board': 0.0,\n   'scheme_management_Water authority': 0.0,\n   'permit_0_0': 1.0,\n   'permit_1_0': 0.0,\n   'extraction_type_afridev': 0.0,\n   'extraction_type_cemo': 0.0,\n   'extraction_type_climax': 0.0,\n   'extraction_type_gravity': 1.0,\n   'extraction_type_india mark ii': 0.0,\n   'extraction_type_india mark iii': 0.0,\n   'extraction_type_ksb': 0.0,\n   'extraction_type_mono': 0.0,\n   'extraction_type_nira/tanira': 0.0,\n   'extraction_type_other': 0.0,\n   'extraction_type_other - mkulima/shinyanga': 0.0,\n   'extraction_type_other - play pump': 0.0,\n   'extraction_type_other - rope pump': 0.0,\n   'extraction_type_other - swn 81': 0.0,\n   'extraction_type_submersible': 0.0,\n   'extraction_type_swn 80': 0.0,\n   'extraction_type_walimi': 0.0,\n   'extraction_type_windmill': 0.0,\n   'extraction_type_class_gravity': 1.0,\n   'extraction_type_class_handpump': 0.0,\n   'extraction_type_class_motorpump': 0.0,\n   'extraction_type_class_other': 0.0,\n   'extraction_type_class_rope pump': 0.0,\n   'extraction_type_class_submersible': 0.0,\n   'extraction_type_class_wind-powered': 0.0,\n   'management_company': 0.0,\n   'management_other': 0.0,\n   'management_other - school': 0.0,\n   'management_parastatal': 0.0,\n   'management_private operator': 0.0,\n   'management_trust': 0.0,\n   'management_unknown': 0.0,\n   'management_vwc': 1.0,\n   'management_water authority': 0.0,\n   'management_water board': 0.0,\n   'management_wua': 0.0,\n   'management_wug': 0.0,\n   'management_group_commercial': 0.0,\n   'management_group_other': 0.0,\n   'management_group_parastatal': 0.0,\n   'management_group_unknown': 0.0,\n   'management_group_user-group': 1.0,\n   'payment_type_annually': 0.0,\n   'payment_type_monthly': 0.0,\n   'payment_type_never pay': 1.0,\n   'payment_type_on failure': 0.0,\n   'payment_type_other': 0.0,\n   'payment_type_per bucket': 0.0,\n   'payment_type_unknown': 0.0,\n   'water_quality_coloured': 0.0,\n   'water_quality_fluoride': 0.0,\n   'water_quality_fluoride abandoned': 0.0,\n   'water_quality_milky': 0.0,\n   'water_quality_salty': 0.0,\n   'water_quality_salty abandoned': 0.0,\n   'water_quality_soft': 1.0,\n   'water_quality_unknown': 0.0,\n   'quantity_group_dry': 0.0,\n   'quantity_group_enough': 1.0,\n   'quantity_group_insufficient': 0.0,\n   'quantity_group_seasonal': 0.0,\n   'quantity_group_unknown': 0.0,\n   'source_dam': 0.0,\n   'source_hand dtw': 0.0,\n   'source_lake': 0.0,\n   'source_machine dbh': 0.0,\n   'source_other': 0.0,\n   'source_rainwater harvesting': 0.0,\n   'source_river': 0.0,\n   'source_shallow well': 0.0,\n   'source_spring': 1.0,\n   'source_unknown': 0.0,\n   'source_class_groundwater': 1.0,\n   'source_class_surface': 0.0,\n   'source_class_unknown': 0.0,\n   'waterpoint_type_cattle trough': 0.0,\n   'waterpoint_type_communal standpipe': 1.0,\n   'waterpoint_type_communal standpipe multiple': 0.0,\n   'waterpoint_type_dam': 0.0,\n   'waterpoint_type_hand pump': 0.0,\n   'waterpoint_type_improved spring': 0.0,\n   'waterpoint_type_other': 0.0,\n   'region_Arusha': 0.0,\n   'region_Dar es Salaam': 0.0,\n   'region_Dodoma': 1.0,\n   'region_Iringa': 0.0,\n   'region_Kagera': 0.0,\n   'region_Kigoma': 0.0,\n   'region_Kilimanjaro': 0.0,\n   'region_Lindi': 0.0,\n   'region_Manyara': 0.0,\n   'region_Mara': 0.0,\n   'region_Mbeya': 0.0,\n   'region_Morogoro': 0.0,\n   'region_Mtwara': 0.0,\n   'region_Mwanza': 0.0,\n   'region_Pwani': 0.0,\n   'region_Rukwa': 0.0,\n   'region_Ruvuma': 0.0,\n   'region_Shinyanga': 0.0,\n   'region_Singida': 0.0,\n   'region_Tabora': 0.0,\n   'region_Tanga': 0.0,\n   'year_recorded': 2011.0,\n   'month_recorded': 4.0}]}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 83,
      "metadata": {
        "id": "VMpqODAztLkb",
        "gather": {
          "logged": 1618528529565
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\r\n",
        "import json\r\n",
        "\r\n",
        "# Convert the array to a serializable list in a JSON document\r\n",
        "input_data = json.dumps(x_new)\r\n",
        "\r\n",
        "with open('data.json', 'w') as file:\r\n",
        "    file.write(input_data)\r\n",
        "\r\n",
        "# Set the content type in the request headers\r\n",
        "request_headers = { \"Content-Type\":\"application/json\"}\r\n",
        "\r\n",
        "# Call the service\r\n",
        "response = requests.post(url = endpoint,\r\n",
        "                         data = input_data,\r\n",
        "                         headers = request_headers)\r\n",
        "\r\n",
        "print(response)\r\n",
        "print(\"Prediction Results:\", response.json())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Response [200]>\n",
            "Prediction Results: ['non functional']\n"
          ]
        }
      ],
      "execution_count": 88,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618530156367
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works!"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response.status_code"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 85,
          "data": {
            "text/plain": "200"
          },
          "metadata": {}
        }
      ],
      "execution_count": 85,
      "metadata": {
        "id": "xpGC1i6LasBZ",
        "gather": {
          "logged": 1618528995951
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing the logs and Deleting the Service"
      ],
      "metadata": {
        "id": "dAIMxK1RB9iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete computer target in order to avoid incurring additional charges.\n",
        "\n",
        "AmlCompute.delete(cpu_cluster)\n",
        "service.delete()\n",
        "model.delete()\n",
        "run.delete()\n",
        "automl_run.delete()\n",
        "automl_experiment.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "FrhiISos4LIG"
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "name": "automl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}