{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/hyperdrive-vs-automl-plus-deployment/blob/main/automl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ],
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML"
      ],
      "metadata": {
        "id": "wjy4Pc9vWXWa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment and Import Dependencies\n",
        "\n",
        "Here we specify the conda dependencies."
      ],
      "metadata": {
        "id": "JCE-mKVP6sCc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile conda_dependencies.yml\n",
        "\n",
        "dependencies:\n",
        "- python=3.6.2\n",
        "- pip=20.2.4\n",
        "- pip:\n",
        "    - azureml-defaults\n",
        "    - scikit-learn"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting conda_dependencies.yml\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "id": "7gDTnHm54LH8",
        "outputId": "f9437794-6fb5-4531-b890-32f59817b342"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "\n",
        "# Creating a conda environment for model training. It needs to be included in ScriptRunConfig.\n",
        "\n",
        "sklearn_env = Environment.from_conda_specification(name='sklearn_env', file_path='./conda_dependencies.yml')"
      ],
      "outputs": [],
      "execution_count": 12,
      "metadata": {
        "id": "npQZM5w74LH9",
        "gather": {
          "logged": 1617333735057
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import logging\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from sklearn import datasets\n",
        "import pkg_resources\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SDK version: 1.24.0\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "id": "nZbdttQy4Un6",
        "gather": {
          "logged": 1617333737480
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import datetime\n",
        "\n",
        "# Data Exploration was done in a notebook beforehand\n",
        "\n",
        "\n",
        "def dates(X):\n",
        "    \"\"\"\n",
        "    date_recorded: this might be a useful variable for this analysis, although the year itself would be \n",
        "    useless in a practical scenario moving into the future. We will convert this column into a datetime, \n",
        "    and we will also create 'year_recorded' and 'month_recorded' columns just in case those levels prove \n",
        "    to be useful. A visual inspection of both casts significant doubt on that possibility, but we'll proceed \n",
        "    for now. We will delete date_recorded itself, since random forest cannot accept datetime\n",
        "    \"\"\"\n",
        "    for i in [X]:\n",
        "        i['date_recorded'] = pd.to_datetime(i['date_recorded'])\n",
        "        i['year_recorded'] = i['date_recorded'].apply(lambda x: x.year)\n",
        "        i['month_recorded'] = i['date_recorded'].apply(lambda x: x.month)\n",
        "        i['date_recorded'] = (pd.to_datetime(i['date_recorded'])).apply(lambda x: x.toordinal())\n",
        "    return X\n",
        "\n",
        "\n",
        "def date_parser(df):\n",
        "    date_recorder = list(map(lambda x: datetime.datetime.strptime(str(x), '%Y-%m-%d'),\n",
        "                             df['date_recorded'].values))\n",
        "    df['year_recorder'] = list(map(lambda x: int(x.strftime('%Y')), date_recorder))\n",
        "    df['weekday_recorder'] = list(map(lambda x: int(x.strftime('%w')), date_recorder))\n",
        "    df['yearly_week_recorder'] = list(map(lambda x: int(x.strftime('%W')), date_recorder))\n",
        "    df['month_recorder'] = list(map(lambda x: int(x.strftime('%m')), date_recorder))\n",
        "    df['age'] = df['year_recorder'].values - df['construction_year'].values\n",
        "    del df['date_recorded']\n",
        "    return df\n",
        "\n",
        "\n",
        "def bools(X):\n",
        "    \"\"\"\n",
        "    public_meeting: we will fill the nulls as 'False'\n",
        "    permit: we will fill the nulls as 'False'\n",
        "    \"\"\"\n",
        "    z = ['public_meeting', 'permit']\n",
        "    for i in z:\n",
        "        X[i].fillna(False, inplace = True)\n",
        "        X[i] = X[i].apply(lambda x: float(x))\n",
        "    return X\n",
        "\n",
        "\n",
        "def small_n(X):\n",
        "    \"Collapsing small categorical value counts into 'other'\"\n",
        "    cols = [i for i in X.columns if type(X[i].iloc[0]) == str]\n",
        "    X[cols] = X[cols].where(X[cols].apply(lambda x: x.map(x.value_counts())) > 100, \"other\")\n",
        "    return X\n"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVGom3TYuwx_",
        "outputId": "e9fe9718-0729-471e-a2c9-af748ae1f62c",
        "gather": {
          "logged": 1617333737721
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "\n",
        "We'll be using the Pump it Up dataset from the DrivenData competition.\n",
        "\n",
        "The description of the problem: \n",
        "\n",
        "> Using data from Taarifa and the Tanzanian Ministry of Water, can you predict which pumps are functional, which need some repairs, and which don't work at all? This is an intermediate-level practice competition. Predict one of these three classes based on a number of variables about what kind of pump is operating, when it was installed, and how it is managed. A smart understanding of which waterpoints will fail can improve maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
        "\n",
        "In other words, our goal is to predict which water pumps are non-functioning or functioning, but in need of repair.\n",
        "\n",
        "In this project, we will train a model using AutoML to train multiple multiple and choose the best performing model for deployment."
      ],
      "metadata": {
        "id": "NpdvmaVVWXWg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We loaded the dataset into Azure and we are grabbing it here.\n",
        "\n",
        "# azureml-core of version 1.0.72 or higher is required\n",
        "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
        "from azureml.core import Workspace, Dataset\n",
        "\n",
        "subscription_id = '9b72f9e6-56c5-4c16-991b-19c652994860'\n",
        "resource_group = 'aml-quickstarts-141771'\n",
        "workspace_name = 'quick-starts-ws-141771'\n",
        "\n",
        "workspace = Workspace(subscription_id, resource_group, workspace_name)\n",
        "\n",
        "dataset = Dataset.get_by_name(workspace, name='Pump-it-Up-datatset')\n",
        "df = dataset.to_pandas_dataframe()\n",
        "y = df['status_group']\n",
        "del df['status_group']\n",
        "X = df\n",
        "del df"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "id": "uuj67ZSm4LIE",
        "gather": {
          "logged": 1617333738277
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "      id  amount_tsh date_recorded        funder  gps_height     installer  \\\n0  69572      6000.0    2011-03-14         Roman        1390         Roman   \n1   8776         0.0    2013-03-06       Grumeti        1399       GRUMETI   \n2  34310        25.0    2013-02-25  Lottery Club         686  World vision   \n3  67743         0.0    2013-01-28        Unicef         263        UNICEF   \n4  19728         0.0    2011-07-13   Action In A           0       Artisan   \n\n   longitude   latitude              wpt_name  num_private  ... payment_type  \\\n0  34.938093  -9.856322                  none            0  ...     annually   \n1  34.698766  -2.147466              Zahanati            0  ...    never pay   \n2  37.460664  -3.821329           Kwa Mahundi            0  ...   per bucket   \n3  38.486161 -11.155298  Zahanati Ya Nanyumbu            0  ...    never pay   \n4  31.130847  -1.825359               Shuleni            0  ...    never pay   \n\n  water_quality quality_group      quantity  quantity_group  \\\n0          soft          good        enough          enough   \n1          soft          good  insufficient    insufficient   \n2          soft          good        enough          enough   \n3          soft          good           dry             dry   \n4          soft          good      seasonal        seasonal   \n\n                 source           source_type  source_class  \\\n0                spring                spring   groundwater   \n1  rainwater harvesting  rainwater harvesting       surface   \n2                   dam                   dam       surface   \n3           machine dbh              borehole   groundwater   \n4  rainwater harvesting  rainwater harvesting       surface   \n\n               waterpoint_type waterpoint_type_group  \n0           communal standpipe    communal standpipe  \n1           communal standpipe    communal standpipe  \n2  communal standpipe multiple    communal standpipe  \n3  communal standpipe multiple    communal standpipe  \n4           communal standpipe    communal standpipe  \n\n[5 rows x 40 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>amount_tsh</th>\n      <th>date_recorded</th>\n      <th>funder</th>\n      <th>gps_height</th>\n      <th>installer</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>wpt_name</th>\n      <th>num_private</th>\n      <th>...</th>\n      <th>payment_type</th>\n      <th>water_quality</th>\n      <th>quality_group</th>\n      <th>quantity</th>\n      <th>quantity_group</th>\n      <th>source</th>\n      <th>source_type</th>\n      <th>source_class</th>\n      <th>waterpoint_type</th>\n      <th>waterpoint_type_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>69572</td>\n      <td>6000.0</td>\n      <td>2011-03-14</td>\n      <td>Roman</td>\n      <td>1390</td>\n      <td>Roman</td>\n      <td>34.938093</td>\n      <td>-9.856322</td>\n      <td>none</td>\n      <td>0</td>\n      <td>...</td>\n      <td>annually</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>spring</td>\n      <td>spring</td>\n      <td>groundwater</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8776</td>\n      <td>0.0</td>\n      <td>2013-03-06</td>\n      <td>Grumeti</td>\n      <td>1399</td>\n      <td>GRUMETI</td>\n      <td>34.698766</td>\n      <td>-2.147466</td>\n      <td>Zahanati</td>\n      <td>0</td>\n      <td>...</td>\n      <td>never pay</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>34310</td>\n      <td>25.0</td>\n      <td>2013-02-25</td>\n      <td>Lottery Club</td>\n      <td>686</td>\n      <td>World vision</td>\n      <td>37.460664</td>\n      <td>-3.821329</td>\n      <td>Kwa Mahundi</td>\n      <td>0</td>\n      <td>...</td>\n      <td>per bucket</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>dam</td>\n      <td>dam</td>\n      <td>surface</td>\n      <td>communal standpipe multiple</td>\n      <td>communal standpipe</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>67743</td>\n      <td>0.0</td>\n      <td>2013-01-28</td>\n      <td>Unicef</td>\n      <td>263</td>\n      <td>UNICEF</td>\n      <td>38.486161</td>\n      <td>-11.155298</td>\n      <td>Zahanati Ya Nanyumbu</td>\n      <td>0</td>\n      <td>...</td>\n      <td>never pay</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>dry</td>\n      <td>dry</td>\n      <td>machine dbh</td>\n      <td>borehole</td>\n      <td>groundwater</td>\n      <td>communal standpipe multiple</td>\n      <td>communal standpipe</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19728</td>\n      <td>0.0</td>\n      <td>2011-07-13</td>\n      <td>Action In A</td>\n      <td>0</td>\n      <td>Artisan</td>\n      <td>31.130847</td>\n      <td>-1.825359</td>\n      <td>Shuleni</td>\n      <td>0</td>\n      <td>...</td>\n      <td>never pay</td>\n      <td>soft</td>\n      <td>good</td>\n      <td>seasonal</td>\n      <td>seasonal</td>\n      <td>rainwater harvesting</td>\n      <td>rainwater harvesting</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 40 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617333738539
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A lot of null values for construction year. Of course, this is a missing value (a placeholder).\n",
        "# For modeling purposes, this is actually fine, but we'll have trouble with visualizations if we\n",
        "# compare the results for different years, so we'll set the value to something closer to\n",
        "# the other values that aren't placeholders. Let's look at the unique years and set the null\n",
        "# values to 50 years sooner.\n",
        "# Alright, let's set it to 1910\n",
        "X.loc[X['construction_year'] < 1950, 'construction_year'] = 1910\n",
        "X['population'] = np.log(X['population'])\n",
        "\n",
        "# Cleaning up the features of our dataset\n",
        "# X = dates(X)\n",
        "x = date_parser(X)\n",
        "X = bools(X)\n",
        "X['population'] = np.log(X['population'])\n",
        "X = small_n(X)\n",
        "\n",
        "# Splitting the dataset into a training and test set\n",
        "# Test set will be used later\n",
        "# The same random seed (42) for the Hyperdrive model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Concatenating the features and labels together to feed to our AutoML model\n",
        "clean_df = pd.concat([X_train, y_train], axis=1)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/site-packages/pandas/core/series.py:856: RuntimeWarning: divide by zero encountered in log\n",
            "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {
        "gather": {
          "logged": 1617333738763
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "s1EeoYUR4LIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Get the default datastore to be entered as a parameter in tabular dataset creation\n",
        "datastore = workspace.get_default_datastore()\n",
        "\n",
        "# Change pandas dataframe into a tabular dataset to be used in automl\n",
        "training_data = TabularDatasetFactory.register_pandas_dataframe(clean_df, datastore, 'automl_data')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Method register_pandas_dataframe: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/26d0450c-37c1-4f84-bce0-be89b7cb4bac/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ]
        }
      ],
      "execution_count": 18,
      "metadata": {
        "id": "law5FINf4LIE",
        "outputId": "138b50d8-93cd-43d3-8ccb-0bec92c74507",
        "gather": {
          "logged": 1617333740668
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.take(5).to_pandas_dataframe()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 19,
          "data": {
            "text/plain": "      id  amount_tsh  date_recorded funder  gps_height installer  longitude  \\\n0    454        50.0         734926   Dmdd        2092     other  35.426020   \n1    510         0.0         734213  other           0      Gove  35.510074   \n2  14146         0.0         734328   Kkkt           0      KKKT  32.499866   \n3  47410         0.0         734239  other           0     other  34.060484   \n4   1288       300.0         734232     Ki        1023     other  37.032690   \n\n   latitude wpt_name  num_private  ...      quantity quantity_group  \\\n0 -4.227446    other            0  ...  insufficient   insufficient   \n1 -5.724555    other            0  ...        enough         enough   \n2 -9.081222    other            0  ...        enough         enough   \n3 -8.830208    other            0  ...  insufficient   insufficient   \n4 -6.040787    other            0  ...        enough         enough   \n\n         source   source_type  source_class     waterpoint_type  \\\n0        spring        spring   groundwater  communal standpipe   \n1  shallow well  shallow well   groundwater           hand pump   \n2  shallow well  shallow well   groundwater               other   \n3         river    river/lake       surface  communal standpipe   \n4  shallow well  shallow well   groundwater               other   \n\n  waterpoint_type_group  year_recorded  month_recorded    status_group  \n0    communal standpipe           2013               2      functional  \n1             hand pump           2011               3      functional  \n2                 other           2011               7  non functional  \n3    communal standpipe           2011               4  non functional  \n4                 other           2011               4  non functional  \n\n[5 rows x 43 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>amount_tsh</th>\n      <th>date_recorded</th>\n      <th>funder</th>\n      <th>gps_height</th>\n      <th>installer</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>wpt_name</th>\n      <th>num_private</th>\n      <th>...</th>\n      <th>quantity</th>\n      <th>quantity_group</th>\n      <th>source</th>\n      <th>source_type</th>\n      <th>source_class</th>\n      <th>waterpoint_type</th>\n      <th>waterpoint_type_group</th>\n      <th>year_recorded</th>\n      <th>month_recorded</th>\n      <th>status_group</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>454</td>\n      <td>50.0</td>\n      <td>734926</td>\n      <td>Dmdd</td>\n      <td>2092</td>\n      <td>other</td>\n      <td>35.426020</td>\n      <td>-4.227446</td>\n      <td>other</td>\n      <td>0</td>\n      <td>...</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>spring</td>\n      <td>spring</td>\n      <td>groundwater</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>2013</td>\n      <td>2</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>510</td>\n      <td>0.0</td>\n      <td>734213</td>\n      <td>other</td>\n      <td>0</td>\n      <td>Gove</td>\n      <td>35.510074</td>\n      <td>-5.724555</td>\n      <td>other</td>\n      <td>0</td>\n      <td>...</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>shallow well</td>\n      <td>shallow well</td>\n      <td>groundwater</td>\n      <td>hand pump</td>\n      <td>hand pump</td>\n      <td>2011</td>\n      <td>3</td>\n      <td>functional</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>14146</td>\n      <td>0.0</td>\n      <td>734328</td>\n      <td>Kkkt</td>\n      <td>0</td>\n      <td>KKKT</td>\n      <td>32.499866</td>\n      <td>-9.081222</td>\n      <td>other</td>\n      <td>0</td>\n      <td>...</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>shallow well</td>\n      <td>shallow well</td>\n      <td>groundwater</td>\n      <td>other</td>\n      <td>other</td>\n      <td>2011</td>\n      <td>7</td>\n      <td>non functional</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>47410</td>\n      <td>0.0</td>\n      <td>734239</td>\n      <td>other</td>\n      <td>0</td>\n      <td>other</td>\n      <td>34.060484</td>\n      <td>-8.830208</td>\n      <td>other</td>\n      <td>0</td>\n      <td>...</td>\n      <td>insufficient</td>\n      <td>insufficient</td>\n      <td>river</td>\n      <td>river/lake</td>\n      <td>surface</td>\n      <td>communal standpipe</td>\n      <td>communal standpipe</td>\n      <td>2011</td>\n      <td>4</td>\n      <td>non functional</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1288</td>\n      <td>300.0</td>\n      <td>734232</td>\n      <td>Ki</td>\n      <td>1023</td>\n      <td>other</td>\n      <td>37.032690</td>\n      <td>-6.040787</td>\n      <td>other</td>\n      <td>0</td>\n      <td>...</td>\n      <td>enough</td>\n      <td>enough</td>\n      <td>shallow well</td>\n      <td>shallow well</td>\n      <td>groundwater</td>\n      <td>other</td>\n      <td>other</td>\n      <td>2011</td>\n      <td>4</td>\n      <td>non functional</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 43 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 19,
      "metadata": {
        "id": "WChG_Wzp8oXg",
        "gather": {
          "logged": 1617333740981
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Experiment\n",
        "\n",
        "We'll create a new experiment for our deployment of an AutoML model and create a project folder to hold the training scripts."
      ],
      "metadata": {
        "id": "lUqJbckB5HD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "experiment_name = 'automl-pump-it-up-operationalize'\n",
        "project_folder = './automl-pipeline-project'\n",
        "\n",
        "automl_experiment = Experiment(workspace, experiment_name)\n",
        "automl_experiment"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "Experiment(Name: automl-pump-it-up-operationalize,\nWorkspace: quick-starts-ws-141771)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automl-pump-it-up-operationalize</td><td>quick-starts-ws-141771</td><td><a href=\"https://ml.azure.com/experiments/automl-pump-it-up-operationalize?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-141771/workspaces/quick-starts-ws-141771\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {
        "id": "ZlKWTS0g5GBg",
        "gather": {
          "logged": 1617333761108
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "\r\n",
        "# Creating a compute cluster if there isn't one that is already created.\r\n",
        "\r\n",
        "cpu_cluster_name = 'hypr-auto-clustr'\r\n",
        "\r\n",
        "try:\r\n",
        "    cpu_cluster = ComputeTarget(workspace=workspace, name=cpu_cluster_name)\r\n",
        "    print('Found existing compute target.')\r\n",
        "except ComputeTargetException:\r\n",
        "    print('Creating a new computer target...')\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_v2',\r\n",
        "                                                          max_nodes=4)\r\n",
        "    cpu_cluster = ComputeTarget.create(workspace, cpu_cluster_name, compute_config)\r\n",
        "    \r\n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing compute target.\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1617333924178
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoML Configuration\n",
        "\n",
        "We'll create a new experiment for our deployment of an AutoML model and create a project folder to hold the training scripts.\n",
        "\n",
        "Here we create the general AutoML settings object.\n",
        "\n",
        "\n",
        "Calculate recall to test how well we do on True Positives. We can imagine a real scenario where we want to build a model that does not miss the non-functioning water pumps, and we care much less functioning water pumps that are incorrectly predicted as non-functional. Recall is useful to make sure we miss less True Positives."
      ],
      "metadata": {
        "id": "ng9WKfEN9FVP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 20, # to set a limit on the amount of time AutoML will be running\n",
        "    \"max_concurrent_iterations\": 5, # applies to the compute target we are using\n",
        "    \"primary_metric\" : 'norm_macro_recall' # recall for our performance metric\n",
        "}\n",
        "\n",
        "# Setting AutoML config for model training.\n",
        "\n",
        "automl_config = AutoMLConfig(compute_target=cpu_cluster,\n",
        "                             task = \"classification\", # classifying if water pumps are functional\n",
        "                             training_data=training_data, \n",
        "                             label_column_name=\"status_group\", # our target variable for water pump function  \n",
        "                             path = project_folder,\n",
        "                             enable_early_stopping= True, # prevents automl from spending too much time on models that stopped improving, saves time and compute costs\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "gather": {
          "logged": 1617334052607
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "dYjR1WTR4LIF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Pipeline and AutoMLStep\n",
        "\n",
        "Defining the outputs for the AutoMLStep using TrainingOutput."
      ],
      "metadata": {
        "id": "D6udoRSe9NW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
        "\n",
        "ds = workspace.get_default_datastore()\n",
        "metrics_output_name = 'metrics_output'\n",
        "best_model_output_name = 'best_model_output'\n",
        "\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=metrics_output_name,\n",
        "                           training_output=TrainingOutput(type='Metrics'))\n",
        "model_data = PipelineData(name='model_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=best_model_output_name,\n",
        "                           training_output=TrainingOutput(type='Model'))"
      ],
      "outputs": [],
      "execution_count": 32,
      "metadata": {
        "id": "9-xCEtpOZOVS",
        "gather": {
          "logged": 1617334059710
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the AutoMLStep"
      ],
      "metadata": {
        "id": "u-DVjxDp9dFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating an AutoMLStep\n",
        "\n",
        "automl_step = AutoMLStep(\n",
        "    name='automl_module',\n",
        "    automl_config=automl_config,\n",
        "    outputs=[metrics_data, model_data],\n",
        "    allow_reuse=True\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": 33,
      "metadata": {
        "id": "8yDcosARZa7K",
        "gather": {
          "logged": 1617334060087
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Pipeline\n",
        "\n",
        "from azureml.pipeline.core import Pipeline\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    description=\"pipeline_with_automlstep\",\n",
        "    workspace=workspace,    \n",
        "    steps=[automl_step])"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "id": "D8uIv-9iZjo3",
        "gather": {
          "logged": 1617334065457
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Submitting AutoML experiment...')\n",
        "\n",
        "pipeline_run = automl_experiment.submit(pipeline)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitting AutoML experiment...\n",
            "Created step automl_module [8107933d][117ebb2e-c744-4523-82b8-1a0f07b09536], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 4995889a-e571-4d09-a1ba-eadf1d10ecff\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/automl-pump-it-up-operationalize/runs/4995889a-e571-4d09-a1ba-eadf1d10ecff?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-141771/workspaces/quick-starts-ws-141771\n"
          ]
        }
      ],
      "execution_count": 36,
      "metadata": {
        "id": "Pg-NU8vuZp6Z",
        "gather": {
          "logged": 1617334106966
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run Details\n",
        "\n",
        "Using the RunDeatils widget to show the different experiments."
      ],
      "metadata": {
        "id": "xrTPvoOJb4Uq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(pipeline_run).show()"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "288bde079a694ec896843c326d2bfca8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Running\", \"workbench_run_details_uri\": \"https://ml.azure.com/experiments/automl-pump-it-up-operationalize/runs/4995889a-e571-4d09-a1ba-eadf1d10ecff?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-141771/workspaces/quick-starts-ws-141771\", \"run_id\": \"4995889a-e571-4d09-a1ba-eadf1d10ecff\", \"run_properties\": {\"run_id\": \"4995889a-e571-4d09-a1ba-eadf1d10ecff\", \"created_utc\": \"2021-04-02T03:28:26.087264Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": null, \"status\": \"Running\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlstrg141771.blob.core.windows.net/azureml/ExperimentRun/dcid.4995889a-e571-4d09-a1ba-eadf1d10ecff/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=OBHHMJOhuTh55%2BhI1Pj%2BcVQ7LHj7vWRn3FEPkyFIBJY%3D&st=2021-04-02T03%3A18%3A40Z&se=2021-04-02T11%3A28%3A40Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlstrg141771.blob.core.windows.net/azureml/ExperimentRun/dcid.4995889a-e571-4d09-a1ba-eadf1d10ecff/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=fgWDpSu2b6hUIvbA740M77siBv0vHp6hDbxM4hXF%2Fds%3D&st=2021-04-02T03%3A18%3A40Z&se=2021-04-02T11%3A28%3A40Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlstrg141771.blob.core.windows.net/azureml/ExperimentRun/dcid.4995889a-e571-4d09-a1ba-eadf1d10ecff/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=qpgG1mD7%2B%2FPbmEQ664%2BoqZQJCELwJmJ35TARBk%2BxQiM%3D&st=2021-04-02T03%3A18%3A40Z&se=2021-04-02T11%3A28%3A40Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:26:17\", \"run_number\": \"1\", \"run_queued_details\": {\"status\": \"Running\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"9ed5efb8-a168-4a84-8dba-f6e5521adf43\", \"name\": \"automl_module\", \"status\": \"Running\", \"start_time\": \"2021-04-02T03:28:47.95855Z\", \"created_time\": \"2021-04-02T03:28:30.086694Z\", \"end_time\": \"\", \"duration\": \"0:26:14\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-04-02T03:28:30.086694Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-04-02 03:28:30Z] Submitting 1 runs, first five are: 8107933d:9ed5efb8-a168-4a84-8dba-f6e5521adf43\\n\", \"graph\": {\"datasource_nodes\": {\"7064339e\": {\"node_id\": \"7064339e\", \"name\": \"automl_data\"}}, \"module_nodes\": {\"8107933d\": {\"node_id\": \"8107933d\", \"name\": \"automl_module\", \"status\": \"Running\", \"_is_reused\": false, \"run_id\": \"9ed5efb8-a168-4a84-8dba-f6e5521adf43\"}}, \"edges\": [{\"source_node_id\": \"7064339e\", \"source_node_name\": \"automl_data\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"8107933d\", \"dst_node_name\": \"automl_module\"}], \"child_runs\": [{\"run_id\": \"9ed5efb8-a168-4a84-8dba-f6e5521adf43\", \"name\": \"automl_module\", \"status\": \"Running\", \"start_time\": \"2021-04-02T03:28:47.95855Z\", \"created_time\": \"2021-04-02T03:28:30.086694Z\", \"end_time\": \"\", \"duration\": \"0:26:14\", \"run_number\": 2, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-04-02T03:28:30.086694Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.24.0\"}, \"loading\": false}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "id": "4wYnNdUEZ_7G",
        "gather": {
          "logged": 1617334149274
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_run.wait_for_completion()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRunId: 4995889a-e571-4d09-a1ba-eadf1d10ecff\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/automl-pump-it-up-operationalize/runs/4995889a-e571-4d09-a1ba-eadf1d10ecff?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-141771/workspaces/quick-starts-ws-141771\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 9ed5efb8-a168-4a84-8dba-f6e5521adf43\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/automl-pump-it-up-operationalize/runs/9ed5efb8-a168-4a84-8dba-f6e5521adf43?wsid=/subscriptions/9b72f9e6-56c5-4c16-991b-19c652994860/resourcegroups/aml-quickstarts-141771/workspaces/quick-starts-ws-141771\n",
            "StepRun( automl_module ) Status: Running\n"
          ]
        }
      ],
      "execution_count": 38,
      "metadata": {
        "id": "Mbk5-oAiaCvS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examine Results\n",
        "\n",
        "# Retrive the metrics of all child runs"
      ],
      "metadata": {
        "id": "l6onN6m69zUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
        "num_file_downloaded = metrics_output.download('.', show_progress=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "vnfQf6xGabw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open(metrics_output._path_on_datastore) as f:\n",
        "    metrics_output_result = f.read()\n",
        "    \n",
        "deserialized_metrics_output = json.loads(metrics_output_result)\n",
        "df = pd.DataFrame(deserialized_metrics_output)\n",
        "df"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'metrics_output' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-9aede8ce2ffa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path_on_datastore\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmetrics_output_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdeserialized_metrics_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_output_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'metrics_output' is not defined"
          ]
        }
      ],
      "execution_count": 73,
      "metadata": {
        "id": "j3D5X1aEaeT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Best Model"
      ],
      "metadata": {
        "id": "4C37uiNk-IHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve best model from Pipeline Run\n",
        "best_model_output = pipeline_run.get_pipeline_output(best_model_output_name)\n",
        "num_file_downloaded = best_model_output.download('.', show_progress=True)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pipeline_run' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-c368596b3d58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Retrieve best model from Pipeline Run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_model_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pipeline_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model_output_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnum_file_downloaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_progress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline_run' is not defined"
          ]
        }
      ],
      "execution_count": 74,
      "metadata": {
        "id": "bU9OgmfFae7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(best_model_output._path_on_datastore, \"rb\" ) as f:\n",
        "    best_model = pickle.load(f)\n",
        "best_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "Yo4EdSyOae-b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.steps"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-50c9d37eaba3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ],
      "execution_count": 76,
      "metadata": {
        "id": "9RMLJGX_afA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the model on the Test Set"
      ],
      "metadata": {
        "id": "q0hjMqcq-Z1Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the Test Set\n",
        "ypred = best_model.predict(X_test)\n",
        "\n",
        "# calculate recall\n",
        "recall = recall_score(y_test, ypred, average='micro')\n",
        "print('Recall: %.3f' % recall)"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-1872bd423e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Predict on the Test Set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mypred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# calculate recall\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mypred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ],
      "execution_count": 77,
      "metadata": {
        "id": "Bkh8yPVAafGG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Deployment\n",
        "\n",
        "Registering the model, creating an inference config and deploy the model as a web service.\n",
        "\n",
        "In other words, we are publishing the pipeline to enable a REST endpoint to rerun the pipeline from any HTTP library on any platform."
      ],
      "metadata": {
        "id": "TxROfMr3BC-M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "published_pipeline = pipeline_run.publish_pipeline(\n",
        "    name=\"Pump it Up Train\", description=\"Training Pump it Up pipeline\", version=\"1.0\")\n",
        "\n",
        "published_pipeline"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pipeline_run' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-dbb995baef24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m published_pipeline = pipeline_run.publish_pipeline(\n\u001b[0m\u001b[1;32m      2\u001b[0m     name=\"Pump it Up Train\", description=\"Training Pump it Up pipeline\", version=\"1.0\")\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpublished_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline_run' is not defined"
          ]
        }
      ],
      "execution_count": 78,
      "metadata": {
        "id": "_-M5J1dqar2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we authenticate to retrieve the auth_header so that the endpoint can be used."
      ],
      "metadata": {
        "id": "sO9_TzOVMkCC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.authentication import InteractiveLoginAuthentication\n",
        "\n",
        "interactive_auth = InteractiveLoginAuthentication()\n",
        "auth_header = interactive_auth.get_authentication_header()"
      ],
      "outputs": [],
      "execution_count": 79,
      "metadata": {
        "id": "KONZ0u1sar6F",
        "gather": {
          "logged": 1617329765988
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the Deployed Model\n",
        "\n",
        "Here we will send a request to the deployed model to test it.\n",
        "\n"
      ],
      "metadata": {
        "id": "DF7As6zVBew1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Geting the REST url from the endpoint property of the published pipeline\n",
        "rest_endpoint = published_pipeline.endpoint\n",
        "\n",
        "# Building an HTTP POST request to the endpoint\n",
        "# We also add a JSON payload object with the experiment name\n",
        "response = requests.post(rest_endpoint, \n",
        "                         headers=auth_header, \n",
        "                         json={\"ExperimentName\": \"pipeline-rest-endpoint\"}\n",
        "                        )\n",
        "\n",
        "print(response.status_code)\n",
        "print(response.elapsed)\n",
        "print(response.json())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "heGk6iM4ar9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers = {'Content-Type':'application/json'}\n",
        "data = {\"text\": ['the food was horrible', \n",
        "                 'wow, this movie was truely great, I totally enjoyed it!',\n",
        "                 'why the heck was my package not delivered in time?']}\n",
        "\n",
        "resp = requests.post(aci_service.scoring_uri, json=data, headers=headers)\n",
        "print(\"Prediction Results:\", resp.json())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "dnV3Si0PeSPs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are making it so that a request will trigger the run. We are also going to access the Id key from the response dict to get the value of the run id."
      ],
      "metadata": {
        "id": "VOx0aAUfRO26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    response.raise_for_status()\n",
        "except Exception:    \n",
        "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
        "                    \"Response Code: {}\\n\"\n",
        "                    \"Headers: {}\\n\"\n",
        "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
        "\n",
        "run_id = response.json().get('Id')\n",
        "print('Submitted pipeline run: ', run_id)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "xpGC1i6LasBZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing the logs of the web service\n",
        "\n",
        "We can now use the run id to monitor the status of the new run. "
      ],
      "metadata": {
        "id": "fddhsrfIRlYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core.run import PipelineRun\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "published_pipeline_run = PipelineRun(ws.experiments[\"pipeline-rest-endpoint\"], run_id)\n",
        "RunDetails(published_pipeline_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "OhI6b04ldRed"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Printing the logs and Deleting the Service"
      ],
      "metadata": {
        "id": "dAIMxK1RB9iC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Delete computer target in order to avoid incurring additional charges.\n",
        "\n",
        "AmlCompute.delete(cpu_cluster)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "FrhiISos4LIG"
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "name": "automl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}