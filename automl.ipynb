{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "colab": {
      "name": "automl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayThibs/hyperdrive-vs-automl-plus-deployment/blob/main/automl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wjy4Pc9vWXWa"
      },
      "source": [
        "# Automated ML\n",
        "\n",
        "Note: For data exploration, go to hyperparameter_tuning.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCE-mKVP6sCc"
      },
      "source": [
        "# Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZbdttQy4Un6",
        "gather": {
          "logged": 1618614616949
        },
        "outputId": "87150e8e-2739-4475-d886-73120d9f086c"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import azureml.core\n",
        "from azureml.core.experiment import Experiment\n",
        "from azureml.core.workspace import Workspace\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.dataset import Dataset\n",
        "\n",
        "from azureml.pipeline.steps import AutoMLStep\n",
        "\n",
        "# Check core SDK version number\n",
        "print(\"SDK version:\", azureml.core.VERSION)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SDK version: 1.26.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVGom3TYuwx_",
        "gather": {
          "logged": 1618614617188
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def bools(df):\n",
        "    \"\"\"\n",
        "    public_meeting: we will fill the nulls as 'False'\n",
        "    permit: we will fill the nulls as 'False\n",
        "    \"\"\"\n",
        "    z = ['public_meeting', 'permit']\n",
        "    for i in z:\n",
        "        df[i].fillna(False, inplace = True)\n",
        "        df[i] = df[i].apply(lambda x: float(x))\n",
        "    return df\n",
        "\n",
        "def locs(df, trans = ['longitude', 'latitude', 'gps_height', 'population']):\n",
        "    \"\"\"\n",
        "    fill in the nulls for ['longitude', 'latitude', 'gps_height', 'population'] by using medians from \n",
        "    ['subvillage', 'district_code', 'basin'], and lastly the overall median\n",
        "    \"\"\"\n",
        "    df.loc[df.longitude == 0, 'latitude'] = 0\n",
        "    for z in trans:\n",
        "        df[z].replace(0., np.NaN, inplace = True)\n",
        "        df[z].replace(1., np.NaN, inplace = True)\n",
        "        \n",
        "        for j in ['district_code', 'basin']:\n",
        "        \n",
        "            df['median'] = df.groupby([j])[z].transform('median')\n",
        "            df[z] = df[z].fillna(df['median'])\n",
        "        \n",
        "        df[z] = df[z].fillna(df[z].median())\n",
        "        del df['median']\n",
        "    return df\n",
        "\n",
        "def construction(df):\n",
        "    \"\"\"\n",
        "    A lot of null values for construction year. Of course, this is a missing value (a placeholder).\n",
        "    For modeling purposes, this is actually fine, but we'll have trouble with visualizations if we\n",
        "    compare the results for different years, so we'll set the value to something closer to\n",
        "    the other values that aren't placeholders. Let's look at the unique years and set the null\n",
        "    values to 50 years sooner.\n",
        "    Let's set it to 1910 since the lowest \"good\" value is 1960.\n",
        "    \"\"\"\n",
        "    df.loc[df['construction_year'] < 1950, 'construction_year'] = 1910\n",
        "    return df\n",
        "\n",
        "# Alright, now let's drop a few columns\n",
        "# Needed to drop quite a few categorical columns so that the data would fit in memory in Azure\n",
        "# Tested the model before and after (from 6388 columns to 278) in Colab and only had a ~0.03% reduction in performance\n",
        "\n",
        "def removal(df):\n",
        "  # id: we drop the id column because it is not a useful predictor.\n",
        "  # amount_tsh: is mostly blank - delete\n",
        "  # wpt_name: not useful, delete (too many values)\n",
        "  # subvillage: too many values, delete\n",
        "  # scheme_name: this is almost 50% nulls, so we will delete this column\n",
        "  # num_private: we will delete this column because ~99% of the values are zeros.\n",
        "  features_to_drop = ['id','amount_tsh',  'num_private', \n",
        "          'quantity', 'quality_group', 'source_type', 'payment', \n",
        "          'waterpoint_type_group', 'extraction_type_group', 'wpt_name', \n",
        "          'subvillage', 'scheme_name', 'funder', 'installer', 'recorded_by',\n",
        "          'ward']\n",
        "  df = df.drop(features_to_drop, axis=1)\n",
        "\n",
        "  return df\n",
        "\n",
        "def dummy(df):\n",
        "    dummy_cols = ['basin', 'lga', 'public_meeting',\n",
        "       'scheme_management', 'permit', 'extraction_type',\n",
        "       'extraction_type_class', 'management', 'management_group',\n",
        "       'payment_type', 'water_quality', 'quantity_group', 'source',\n",
        "       'source_class', 'waterpoint_type', 'region']\n",
        "\n",
        "    df = pd.get_dummies(df, columns=dummy_cols)\n",
        "\n",
        "    return df\n",
        "\n",
        "def dates(df):\n",
        "    \"\"\"\n",
        "    date_recorded: this might be a useful variable for this analysis, although the year itself would be useless in a practical scenario moving into the future. We will convert this column into a datetime, and we will also create 'year_recorded' and 'month_recorded' columns just in case those levels prove to be useful. A visual inspection of both casts significant doubt on that possibility, but we'll proceed for now. We will delete date_recorded itself, since random forest cannot accept datetime\n",
        "    \"\"\"\n",
        "    df['date_recorded'] = pd.to_datetime(df['date_recorded'])\n",
        "    df['year_recorded'] = df['date_recorded'].apply(lambda x: x.year)\n",
        "    df['month_recorded'] = df['date_recorded'].apply(lambda x: x.month)\n",
        "    df['date_recorded'] = (pd.to_datetime(df['date_recorded'])).apply(lambda x: x.toordinal())\n",
        "    return df\n",
        "\n",
        "def dates2(df):\n",
        "    \"\"\"\n",
        "    Turn year_recorded and month_recorded into dummy variables\n",
        "    \"\"\"\n",
        "    for z in ['month_recorded', 'year_recorded']:\n",
        "        df[z] = df[z].apply(lambda x: str(x))\n",
        "        good_cols = [z+'_'+i for i in df[z].unique()]\n",
        "        df = pd.concat((df, pd.get_dummies(df[z], prefix = z)[good_cols]), axis = 1)\n",
        "        del df[z]\n",
        "    return df\n",
        "\n",
        "def small_n(df):\n",
        "    \"Collapsing small categorical value counts into 'other'\"\n",
        "    cols = [i for i in df.columns if type(df[i].iloc[0]) == str]\n",
        "    df[cols] = df[cols].where(df[cols].apply(lambda x: x.map(x.value_counts())) > 100, \"other\")\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpdvmaVVWXWg"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "\n",
        "We'll be using the Pump it Up dataset from the DrivenData competition.\n",
        "\n",
        "The description of the problem: \n",
        "\n",
        "> Using data from Taarifa and the Tanzanian Ministry of Water, can you predict which pumps are functional, which need some repairs, and which don't work at all? This is an intermediate-level practice competition. Predict one of these three classes based on a number of variables about what kind of pump is operating, when it was installed, and how it is managed. A smart understanding of which waterpoints will fail can improve maintenance operations and ensure that clean, potable water is available to communities across Tanzania.\n",
        "\n",
        "In other words, our goal is to predict which water pumps are non-functioning or functioning, but in need of repair.\n",
        "\n",
        "In this project, we will train a model using AutoML to train multiple multiple and choose the best performing model for deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuj67ZSm4LIE",
        "gather": {
          "logged": 1618618751607
        },
        "outputId": "3a2d67df-0635-4c33-d978-eea734c66aec"
      },
      "source": [
        "# We loaded the dataset into Azure and we are grabbing it here.\n",
        "\n",
        "from azureml.core import Workspace, Experiment, Dataset\n",
        "# from feature_preprocessing import *\n",
        "\n",
        "# download config file in azure and put it in the current Notebooks folder\n",
        "ws = Workspace.from_config()\n",
        "exp = Experiment(workspace=ws, name=\"Pump-it-Up-Data-Mining-the-Water-Table\")\n",
        "\n",
        "print('Workspace name: ' + ws.name, \n",
        "      'Azure region: ' + ws.location, \n",
        "      'Subscription id: ' + ws.subscription_id, \n",
        "      'Resource group: ' + ws.resource_group, sep = '\\n')\n",
        "\n",
        "run = exp.start_logging()\n",
        "\n",
        "# download config file in azure and put it in the current Notebooks folder\n",
        "ws = run.experiment.workspace\n",
        "\n",
        "key = 'Pump-it-Up-dataset'\n",
        "\n",
        "if key in ws.datasets.keys():\n",
        "      dataset = ws.datasets[key]\n",
        "      print('dataset found!')\n",
        "\n",
        "else:\n",
        "      url = 'https://raw.githubusercontent.com/JayThibs/hyperdrive-vs-automl-plus-deployment/main/Pump-it-Up-dataset.csv'\n",
        "      dataset = Dataset.Tabular.from_delimited_files(url)\n",
        "      datatset = dataset.register(ws, key)\n",
        "\n",
        "dataset.to_pandas_dataframe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Workspace name: quick-starts-ws-142888\n",
            "Azure region: southcentralus\n",
            "Subscription id: 1b944a9b-fdae-4f97-aeb1-b7eea0beac53\n",
            "Resource group: aml-quickstarts-142888\n",
            "dataset found!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id  amount_tsh date_recorded           funder  gps_height  \\\n",
              "0      69572     6000.00    2011-03-14            Roman        1390   \n",
              "1       8776        0.00    2013-03-06          Grumeti        1399   \n",
              "2      34310       25.00    2013-02-25     Lottery Club         686   \n",
              "3      67743        0.00    2013-01-28           Unicef         263   \n",
              "4      19728        0.00    2011-07-13      Action In A           0   \n",
              "...      ...         ...           ...              ...         ...   \n",
              "59395  60739       10.00    2013-05-03  Germany Republi        1210   \n",
              "59396  27263     4700.00    2011-05-07      Cefa-njombe        1212   \n",
              "59397  37057        0.00    2011-04-11             None           0   \n",
              "59398  31282        0.00    2011-03-08            Malec           0   \n",
              "59399  26348        0.00    2011-03-23       World Bank         191   \n",
              "\n",
              "          installer  longitude  latitude              wpt_name  num_private  \\\n",
              "0             Roman      34.94     -9.86                  none            0   \n",
              "1           GRUMETI      34.70     -2.15              Zahanati            0   \n",
              "2      World vision      37.46     -3.82           Kwa Mahundi            0   \n",
              "3            UNICEF      38.49    -11.16  Zahanati Ya Nanyumbu            0   \n",
              "4           Artisan      31.13     -1.83               Shuleni            0   \n",
              "...             ...        ...       ...                   ...          ...   \n",
              "59395           CES      37.17     -3.25   Area Three Namba 27            0   \n",
              "59396          Cefa      35.25     -9.07     Kwa Yahona Kuvala            0   \n",
              "59397          None      34.02     -8.75               Mashine            0   \n",
              "59398          Musa      35.86     -6.38                Mshoro            0   \n",
              "59399         World      38.10     -6.75       Kwa Mzee Lugawa            0   \n",
              "\n",
              "       ... water_quality quality_group      quantity  quantity_group  \\\n",
              "0      ...          soft          good        enough          enough   \n",
              "1      ...          soft          good  insufficient    insufficient   \n",
              "2      ...          soft          good        enough          enough   \n",
              "3      ...          soft          good           dry             dry   \n",
              "4      ...          soft          good      seasonal        seasonal   \n",
              "...    ...           ...           ...           ...             ...   \n",
              "59395  ...          soft          good        enough          enough   \n",
              "59396  ...          soft          good        enough          enough   \n",
              "59397  ...      fluoride      fluoride        enough          enough   \n",
              "59398  ...          soft          good  insufficient    insufficient   \n",
              "59399  ...         salty         salty        enough          enough   \n",
              "\n",
              "                     source           source_type source_class  \\\n",
              "0                    spring                spring  groundwater   \n",
              "1      rainwater harvesting  rainwater harvesting      surface   \n",
              "2                       dam                   dam      surface   \n",
              "3               machine dbh              borehole  groundwater   \n",
              "4      rainwater harvesting  rainwater harvesting      surface   \n",
              "...                     ...                   ...          ...   \n",
              "59395                spring                spring  groundwater   \n",
              "59396                 river            river/lake      surface   \n",
              "59397           machine dbh              borehole  groundwater   \n",
              "59398          shallow well          shallow well  groundwater   \n",
              "59399          shallow well          shallow well  groundwater   \n",
              "\n",
              "                   waterpoint_type waterpoint_type_group    status_group  \n",
              "0               communal standpipe    communal standpipe      functional  \n",
              "1               communal standpipe    communal standpipe      functional  \n",
              "2      communal standpipe multiple    communal standpipe      functional  \n",
              "3      communal standpipe multiple    communal standpipe  non functional  \n",
              "4               communal standpipe    communal standpipe      functional  \n",
              "...                            ...                   ...             ...  \n",
              "59395           communal standpipe    communal standpipe      functional  \n",
              "59396           communal standpipe    communal standpipe      functional  \n",
              "59397                    hand pump             hand pump      functional  \n",
              "59398                    hand pump             hand pump      functional  \n",
              "59399                    hand pump             hand pump      functional  \n",
              "\n",
              "[59400 rows x 41 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>amount_tsh</th>\n",
              "      <th>date_recorded</th>\n",
              "      <th>funder</th>\n",
              "      <th>gps_height</th>\n",
              "      <th>installer</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>wpt_name</th>\n",
              "      <th>num_private</th>\n",
              "      <th>...</th>\n",
              "      <th>water_quality</th>\n",
              "      <th>quality_group</th>\n",
              "      <th>quantity</th>\n",
              "      <th>quantity_group</th>\n",
              "      <th>source</th>\n",
              "      <th>source_type</th>\n",
              "      <th>source_class</th>\n",
              "      <th>waterpoint_type</th>\n",
              "      <th>waterpoint_type_group</th>\n",
              "      <th>status_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69572</td>\n",
              "      <td>6000.00</td>\n",
              "      <td>2011-03-14</td>\n",
              "      <td>Roman</td>\n",
              "      <td>1390</td>\n",
              "      <td>Roman</td>\n",
              "      <td>34.94</td>\n",
              "      <td>-9.86</td>\n",
              "      <td>none</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>spring</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8776</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2013-03-06</td>\n",
              "      <td>Grumeti</td>\n",
              "      <td>1399</td>\n",
              "      <td>GRUMETI</td>\n",
              "      <td>34.70</td>\n",
              "      <td>-2.15</td>\n",
              "      <td>Zahanati</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34310</td>\n",
              "      <td>25.00</td>\n",
              "      <td>2013-02-25</td>\n",
              "      <td>Lottery Club</td>\n",
              "      <td>686</td>\n",
              "      <td>World vision</td>\n",
              "      <td>37.46</td>\n",
              "      <td>-3.82</td>\n",
              "      <td>Kwa Mahundi</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>dam</td>\n",
              "      <td>dam</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>67743</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2013-01-28</td>\n",
              "      <td>Unicef</td>\n",
              "      <td>263</td>\n",
              "      <td>UNICEF</td>\n",
              "      <td>38.49</td>\n",
              "      <td>-11.16</td>\n",
              "      <td>Zahanati Ya Nanyumbu</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>dry</td>\n",
              "      <td>dry</td>\n",
              "      <td>machine dbh</td>\n",
              "      <td>borehole</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe multiple</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>19728</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2011-07-13</td>\n",
              "      <td>Action In A</td>\n",
              "      <td>0</td>\n",
              "      <td>Artisan</td>\n",
              "      <td>31.13</td>\n",
              "      <td>-1.83</td>\n",
              "      <td>Shuleni</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>seasonal</td>\n",
              "      <td>seasonal</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>rainwater harvesting</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59395</th>\n",
              "      <td>60739</td>\n",
              "      <td>10.00</td>\n",
              "      <td>2013-05-03</td>\n",
              "      <td>Germany Republi</td>\n",
              "      <td>1210</td>\n",
              "      <td>CES</td>\n",
              "      <td>37.17</td>\n",
              "      <td>-3.25</td>\n",
              "      <td>Area Three Namba 27</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>spring</td>\n",
              "      <td>spring</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59396</th>\n",
              "      <td>27263</td>\n",
              "      <td>4700.00</td>\n",
              "      <td>2011-05-07</td>\n",
              "      <td>Cefa-njombe</td>\n",
              "      <td>1212</td>\n",
              "      <td>Cefa</td>\n",
              "      <td>35.25</td>\n",
              "      <td>-9.07</td>\n",
              "      <td>Kwa Yahona Kuvala</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>river</td>\n",
              "      <td>river/lake</td>\n",
              "      <td>surface</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>communal standpipe</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59397</th>\n",
              "      <td>37057</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2011-04-11</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>None</td>\n",
              "      <td>34.02</td>\n",
              "      <td>-8.75</td>\n",
              "      <td>Mashine</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>fluoride</td>\n",
              "      <td>fluoride</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>machine dbh</td>\n",
              "      <td>borehole</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59398</th>\n",
              "      <td>31282</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2011-03-08</td>\n",
              "      <td>Malec</td>\n",
              "      <td>0</td>\n",
              "      <td>Musa</td>\n",
              "      <td>35.86</td>\n",
              "      <td>-6.38</td>\n",
              "      <td>Mshoro</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>soft</td>\n",
              "      <td>good</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>insufficient</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59399</th>\n",
              "      <td>26348</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2011-03-23</td>\n",
              "      <td>World Bank</td>\n",
              "      <td>191</td>\n",
              "      <td>World</td>\n",
              "      <td>38.10</td>\n",
              "      <td>-6.75</td>\n",
              "      <td>Kwa Mzee Lugawa</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>salty</td>\n",
              "      <td>salty</td>\n",
              "      <td>enough</td>\n",
              "      <td>enough</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>shallow well</td>\n",
              "      <td>groundwater</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>hand pump</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59400 rows × 41 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618618753753
        },
        "id": "Qf3vNSvwDEgf"
      },
      "source": [
        "X = dataset.to_pandas_dataframe()\n",
        "y = X[['status_group']]\n",
        "del X['status_group']\n",
        "\n",
        "# Cleaning up the features of our dataset\n",
        "X = bools(X)\n",
        "X = locs(X)\n",
        "X = construction(X)\n",
        "X = removal(X)\n",
        "X = dummy(X)\n",
        "X = dates(X)\n",
        "x = dates2(X)\n",
        "X = small_n(X)\n",
        "\n",
        "# Removing \">\", \"[\" and \"]\" from the headers to make the data compatible with different algorithms (namely, xgboost)\n",
        "regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
        "X.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in X.columns.values]\n",
        "\n",
        "# Converting the population values to log\n",
        "X['population'] = np.log(X['population'])\n",
        "\n",
        "# Splitting the dataset into a training and test set\n",
        "# Test set will be used later\n",
        "# The same random seed (42) for the Hyperdrive model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Concatenating the features and labels together to feed to our AutoML model\n",
        "clean_train_df = pd.concat([X_train, y_train], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618618757303
        },
        "id": "iADh-as2aHBt",
        "outputId": "6873e0bb-9023-4654-9838-3fb21efceaee"
      },
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Registering the test dataset for future inference\n",
        "\n",
        "# Get the default datastore to be entered as a parameter in tabular dataset creation\n",
        "datastore = ws.get_default_datastore()\n",
        "\n",
        "# Change pandas dataframe into a tabular dataset to be used in automl\n",
        "testing_data = TabularDatasetFactory.register_pandas_dataframe(X_test, datastore, 'automl_data_test')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:azureml._base_sdk_common._docstring_wrapper:Method register_pandas_dataframe: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/087771d3-f31b-4380-ac1e-40ed469d1f46/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "law5FINf4LIE",
        "gather": {
          "logged": 1618618763384
        },
        "outputId": "4c0ef9f4-987c-4d8e-9286-228dc61a8b1a"
      },
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\n",
        "\n",
        "# Get the default datastore to be entered as a parameter in tabular dataset creation\n",
        "datastore = ws.get_default_datastore()\n",
        "\n",
        "# Change pandas dataframe into a tabular dataset to be used in automl\n",
        "training_data = TabularDatasetFactory.register_pandas_dataframe(clean_train_df, datastore, 'automl_data')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:azureml._base_sdk_common._docstring_wrapper:Method register_pandas_dataframe: This is an experimental method, and may change at any time.<br/>For more information, see https://aka.ms/azuremlexperimental.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Validating arguments.\n",
            "Arguments validated.\n",
            "Successfully obtained datastore reference and path.\n",
            "Uploading file to managed-dataset/82272953-2a23-48c9-994d-a339fa077de8/\n",
            "Successfully uploaded file to datastore.\n",
            "Creating and registering a new dataset.\n",
            "Successfully created and registered a new dataset.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WChG_Wzp8oXg",
        "gather": {
          "logged": 1618618763636
        },
        "outputId": "7aa7553a-2e2d-4f0b-dfea-a170a3b7d4ab"
      },
      "source": [
        "training_data.take(3).to_pandas_dataframe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   date_recorded  gps_height  longitude  latitude  region_code  district_code  \\\n",
              "0         734926     2092.00      35.43     -4.23           21              1   \n",
              "1         734213      550.00      35.51     -5.72            1              6   \n",
              "2         734328      550.00      32.50     -9.08           12              6   \n",
              "\n",
              "   population  construction_year  basin_Internal  basin_Lake Nyasa  ...  \\\n",
              "0        5.08               1998               1                 0  ...   \n",
              "1        5.30               1910               1                 0  ...   \n",
              "2        5.30               1910               0                 0  ...   \n",
              "\n",
              "   region_Pwani  region_Rukwa  region_Ruvuma  region_Shinyanga  \\\n",
              "0             0             0              0                 0   \n",
              "1             0             0              0                 0   \n",
              "2             0             0              0                 0   \n",
              "\n",
              "   region_Singida  region_Tabora  region_Tanga  year_recorded  month_recorded  \\\n",
              "0               0              0             0           2013               2   \n",
              "1               0              0             0           2011               3   \n",
              "2               0              0             0           2011               7   \n",
              "\n",
              "     status_group  \n",
              "0      functional  \n",
              "1      functional  \n",
              "2  non functional  \n",
              "\n",
              "[3 rows x 264 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date_recorded</th>\n",
              "      <th>gps_height</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>region_code</th>\n",
              "      <th>district_code</th>\n",
              "      <th>population</th>\n",
              "      <th>construction_year</th>\n",
              "      <th>basin_Internal</th>\n",
              "      <th>basin_Lake Nyasa</th>\n",
              "      <th>...</th>\n",
              "      <th>region_Pwani</th>\n",
              "      <th>region_Rukwa</th>\n",
              "      <th>region_Ruvuma</th>\n",
              "      <th>region_Shinyanga</th>\n",
              "      <th>region_Singida</th>\n",
              "      <th>region_Tabora</th>\n",
              "      <th>region_Tanga</th>\n",
              "      <th>year_recorded</th>\n",
              "      <th>month_recorded</th>\n",
              "      <th>status_group</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>734926</td>\n",
              "      <td>2092.00</td>\n",
              "      <td>35.43</td>\n",
              "      <td>-4.23</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>5.08</td>\n",
              "      <td>1998</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2013</td>\n",
              "      <td>2</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>734213</td>\n",
              "      <td>550.00</td>\n",
              "      <td>35.51</td>\n",
              "      <td>-5.72</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>5.30</td>\n",
              "      <td>1910</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2011</td>\n",
              "      <td>3</td>\n",
              "      <td>functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>734328</td>\n",
              "      <td>550.00</td>\n",
              "      <td>32.50</td>\n",
              "      <td>-9.08</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>5.30</td>\n",
              "      <td>1910</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2011</td>\n",
              "      <td>7</td>\n",
              "      <td>non functional</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 264 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUqJbckB5HD4"
      },
      "source": [
        "# Setting up Experiment\n",
        "\n",
        "We'll create a new experiment for our deployment of an AutoML model and create a project folder to hold the training scripts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlKWTS0g5GBg",
        "gather": {
          "logged": 1618618763759
        },
        "outputId": "1247f68e-8a85-48bf-8ac5-0c7108bbb430"
      },
      "source": [
        "experiment_name = 'automl-pump-it-up-operationalize'\n",
        "project_folder = './automl-pipeline-project'\n",
        "\n",
        "automl_experiment = Experiment(ws, experiment_name)\n",
        "automl_experiment"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Experiment(Name: automl-pump-it-up-operationalize,\n",
              "Workspace: quick-starts-ws-142888)"
            ],
            "text/html": [
              "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>automl-pump-it-up-operationalize</td><td>quick-starts-ws-142888</td><td><a href=\"https://ml.azure.com/experiments/id/1fb29d4b-e969-45ba-844e-b3b5017a4776?wsid=/subscriptions/1b944a9b-fdae-4f97-aeb1-b7eea0beac53/resourcegroups/aml-quickstarts-142888/workspaces/quick-starts-ws-142888&amp;tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618625616683
        },
        "id": "X75NT0jXNVw7",
        "outputId": "156b378d-7a1d-42fc-ca21-92a527385c23"
      },
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "# Creating a compute cluster if there isn't one that is already created.\n",
        "\n",
        "cpu_cluster_name = 'hypr-auto-clustr'\n",
        "\n",
        "try:\n",
        "    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)\n",
        "    print('Found existing compute target.')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new computer target...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_v2',\n",
        "                                                          max_nodes=4)\n",
        "    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)\n",
        "    \n",
        "cpu_cluster.wait_for_completion(show_output=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating a new computer target...\n",
            "Creating....\n",
            "SucceededProvisioning operation finished, operation \"Succeeded\"\n",
            "Succeeded\n",
            "AmlCompute wait for completion finished\n",
            "\n",
            "Minimum number of nodes requested have been provisioned\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng9WKfEN9FVP"
      },
      "source": [
        "# AutoML Configuration\n",
        "\n",
        "We'll create a new experiment for our deployment of an AutoML model and create a project folder to hold the training scripts.\n",
        "\n",
        "Here we create the general AutoML settings object.\n",
        "\n",
        "\n",
        "Calculate recall to test how well we do on True Positives. We can imagine a real scenario where we want to build a model that does not miss the non-functioning water pumps, and we care much less functioning water pumps that are incorrectly predicted as non-functional. Recall is useful to make sure we miss less True Positives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "gather": {
          "logged": 1618618767704
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "dYjR1WTR4LIF"
      },
      "source": [
        "from azureml.train.automl import AutoMLConfig\n",
        "\n",
        "# Note: We are using `norm_macro_recall` for the primary metric here, but that is not the metric we actually want\n",
        "# our model to perform the best on. As described in the readme, we want `recall_score_micro`. However,\n",
        "# we cannot use `recall_score_micro` as our primary metric because AutoML currently only allows a few primary metrics.\n",
        "# We decided to use `norm_macro_recall` because it was the closest metric to the one we actually wanted to evaluate.\n",
        "\n",
        "automl_settings = {\n",
        "    \"experiment_timeout_minutes\": 120, # to set a limit on the amount of time AutoML will be running\n",
        "    \"max_concurrent_iterations\": 5, # applies to the compute target we are using\n",
        "    \"primary_metric\" : 'norm_macro_recall' # recall for our primary metric\n",
        "}\n",
        "\n",
        "# Setting AutoML config for model training.\n",
        "\n",
        "automl_config = AutoMLConfig(compute_target=cpu_cluster,\n",
        "                             task = \"classification\", # classifying if water pumps are functional\n",
        "                             training_data=training_data, \n",
        "                             label_column_name=\"status_group\", # our target variable for water pump function  \n",
        "                             path = project_folder,\n",
        "                             enable_early_stopping= True, # prevents automl from spending too much time on models that stopped improving, saves time and compute costs\n",
        "                             featurization= 'auto',\n",
        "                             debug_log = \"automl_errors.log\",\n",
        "                             **automl_settings\n",
        "                            )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6udoRSe9NW7"
      },
      "source": [
        "## Create Pipeline and AutoMLStep\n",
        "\n",
        "Defining the outputs for the AutoMLStep using TrainingOutput."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-xCEtpOZOVS",
        "gather": {
          "logged": 1618618774592
        }
      },
      "source": [
        "from azureml.pipeline.core import PipelineData, TrainingOutput\n",
        "\n",
        "ds = ws.get_default_datastore()\n",
        "metrics_output_name = 'metrics_output'\n",
        "best_model_output_name = 'best_model_output'\n",
        "\n",
        "metrics_data = PipelineData(name='metrics_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=metrics_output_name,\n",
        "                           training_output=TrainingOutput(type='Metrics'))\n",
        "model_data = PipelineData(name='model_data',\n",
        "                           datastore=ds,\n",
        "                           pipeline_output_name=best_model_output_name,\n",
        "                           training_output=TrainingOutput(type='Model'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-DVjxDp9dFX"
      },
      "source": [
        "## Create the AutoMLStep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yDcosARZa7K",
        "gather": {
          "logged": 1618618778560
        }
      },
      "source": [
        "# Creating an AutoMLStep\n",
        "\n",
        "automl_step = AutoMLStep(\n",
        "    name='automl_module',\n",
        "    automl_config=automl_config,\n",
        "    outputs=[metrics_data, model_data],\n",
        "    allow_reuse=True\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8uIv-9iZjo3",
        "gather": {
          "logged": 1618618782340
        }
      },
      "source": [
        "# Creating a Pipeline\n",
        "\n",
        "from azureml.pipeline.core import Pipeline\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    description=\"pipeline_with_automlstep\",\n",
        "    workspace=ws,    \n",
        "    steps=[automl_step])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg-NU8vuZp6Z",
        "gather": {
          "logged": 1618618784846
        },
        "outputId": "1be08aff-48cc-4c7d-d6d5-98475b7ddb3f"
      },
      "source": [
        "print('Submitting AutoML experiment...')\n",
        "\n",
        "pipeline_run = automl_experiment.submit(pipeline)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Submitting AutoML experiment...\n",
            "Created step automl_module [4cdbc828][a5db87c7-e53c-4cd7-aca9-82f60eb6243e], (This step will run and generate new outputs)\n",
            "Submitted PipelineRun 540c3f3b-a22f-4e78-a250-e2b2c07ce409\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/540c3f3b-a22f-4e78-a250-e2b2c07ce409?wsid=/subscriptions/1b944a9b-fdae-4f97-aeb1-b7eea0beac53/resourcegroups/aml-quickstarts-142888/workspaces/quick-starts-ws-142888&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrTPvoOJb4Uq"
      },
      "source": [
        "# Run Details\n",
        "\n",
        "Using the RunDetails widget to show the different experiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wYnNdUEZ_7G",
        "gather": {
          "logged": 1618618786418
        },
        "colab": {
          "referenced_widgets": [
            "288bde079a694ec896843c326d2bfca8",
            "fa8c5ee0ca814d36937cae7b0c98427f",
            "af31c266763341118bdb9c7ee3109488"
          ]
        },
        "outputId": "b6155b2b-2abf-4c64-9a75-9b41cc3b1c2f"
      },
      "source": [
        "from azureml.widgets import RunDetails\n",
        "RunDetails(pipeline_run).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af31c266763341118bdb9c7ee3109488"
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/540c3f3b-a22f-4e78-a250-e2b2c07ce409?wsid=/subscriptions/1b944a9b-fdae-4f97-aeb1-b7eea0beac53/resourcegroups/aml-quickstarts-142888/workspaces/quick-starts-ws-142888&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\", \"run_id\": \"540c3f3b-a22f-4e78-a250-e2b2c07ce409\", \"run_properties\": {\"run_id\": \"540c3f3b-a22f-4e78-a250-e2b2c07ce409\", \"created_utc\": \"2021-04-17T00:19:43.003394Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-04-17T01:00:17.191456Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://mlstrg142888.blob.core.windows.net/azureml/ExperimentRun/dcid.540c3f3b-a22f-4e78-a250-e2b2c07ce409/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=ZyGD%2FNBk42fmnOz3DbJRln7uyJmGWFkPKq3Y0pONEtU%3D&st=2021-04-17T02%3A10%3A39Z&se=2021-04-17T10%3A20%3A39Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://mlstrg142888.blob.core.windows.net/azureml/ExperimentRun/dcid.540c3f3b-a22f-4e78-a250-e2b2c07ce409/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=dKsa4Di1XAfZxV8wn6%2Byt5iFOgp4xAJaa3kXg60aNgc%3D&st=2021-04-17T02%3A10%3A39Z&se=2021-04-17T10%3A20%3A39Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://mlstrg142888.blob.core.windows.net/azureml/ExperimentRun/dcid.540c3f3b-a22f-4e78-a250-e2b2c07ce409/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=EsrrugtmAoHTkrsbYqePEOZXLLXxn4AtMh0u1TMlAkg%3D&st=2021-04-17T02%3A10%3A39Z&se=2021-04-17T10%3A20%3A39Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:40:34\", \"run_number\": \"47\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"c21115fe-165c-45e9-83eb-82e4a3a21bbd\", \"name\": \"automl_module\", \"status\": \"Finished\", \"start_time\": \"2021-04-17T00:20:07.393118Z\", \"created_time\": \"2021-04-17T00:19:48.794259Z\", \"end_time\": \"2021-04-17T00:58:53.441325Z\", \"duration\": \"0:39:04\", \"run_number\": 48, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-04-17T00:19:48.794259Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-04-17 00:19:48Z] Submitting 1 runs, first five are: 4cdbc828:c21115fe-165c-45e9-83eb-82e4a3a21bbd\\n[2021-04-17 01:00:16Z] Completing processing run id c21115fe-165c-45e9-83eb-82e4a3a21bbd.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"945c0f74\": {\"node_id\": \"945c0f74\", \"name\": \"automl_data\"}}, \"module_nodes\": {\"4cdbc828\": {\"node_id\": \"4cdbc828\", \"name\": \"automl_module\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"c21115fe-165c-45e9-83eb-82e4a3a21bbd\"}}, \"edges\": [{\"source_node_id\": \"945c0f74\", \"source_node_name\": \"automl_data\", \"source_name\": \"data\", \"target_name\": \"training_data\", \"dst_node_id\": \"4cdbc828\", \"dst_node_name\": \"automl_module\"}], \"child_runs\": [{\"run_id\": \"c21115fe-165c-45e9-83eb-82e4a3a21bbd\", \"name\": \"automl_module\", \"status\": \"Finished\", \"start_time\": \"2021-04-17T00:20:07.393118Z\", \"created_time\": \"2021-04-17T00:19:48.794259Z\", \"end_time\": \"2021-04-17T00:58:53.441325Z\", \"duration\": \"0:39:04\", \"run_number\": 48, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-04-17T00:19:48.794259Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.26.0\"}, \"loading\": false}"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbk5-oAiaCvS",
        "gather": {
          "logged": 1618621219315
        },
        "outputId": "a6476728-6636-4b81-c129-9a430164c847"
      },
      "source": [
        "pipeline_run.wait_for_completion()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PipelineRunId: 540c3f3b-a22f-4e78-a250-e2b2c07ce409\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/540c3f3b-a22f-4e78-a250-e2b2c07ce409?wsid=/subscriptions/1b944a9b-fdae-4f97-aeb1-b7eea0beac53/resourcegroups/aml-quickstarts-142888/workspaces/quick-starts-ws-142888&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
            "PipelineRun Status: NotStarted\n",
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: c21115fe-165c-45e9-83eb-82e4a3a21bbd\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/c21115fe-165c-45e9-83eb-82e4a3a21bbd?wsid=/subscriptions/1b944a9b-fdae-4f97-aeb1-b7eea0beac53/resourcegroups/aml-quickstarts-142888/workspaces/quick-starts-ws-142888&tid=660b3398-b80e-49d2-bc5b-ac1dc93b5254\n",
            "StepRun( automl_module ) Status: NotStarted\n",
            "StepRun( automl_module ) Status: Running\n",
            "\n",
            "StepRun(automl_module) Execution Summary\n",
            "=========================================\n",
            "StepRun( automl_module ) Status: Finished\n",
            "{'runId': 'c21115fe-165c-45e9-83eb-82e4a3a21bbd', 'target': 'hypr-auto-clustr', 'status': 'Completed', 'startTimeUtc': '2021-04-17T00:20:07.393118Z', 'endTimeUtc': '2021-04-17T00:58:53.441325Z', 'properties': {'ContentSnapshotId': '64737d52-f8c4-45e0-baae-4837d2041144', 'StepType': 'AutoMLStep', 'azureml.moduleid': 'a5db87c7-e53c-4cd7-aca9-82f60eb6243e', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': '4cdbc828', 'azureml.pipelinerunid': '540c3f3b-a22f-4e78-a250-e2b2c07ce409', 'num_iterations': '1000', 'training_type': 'TrainFull', 'acquisition_function': 'EI', 'metrics': 'accuracy', 'primary_metric': 'norm_macro_recall', 'train_split': '0', 'MaxTimeSeconds': None, 'acquisition_parameter': '0', 'num_cross_validation': None, 'target': 'hypr-auto-clustr', 'RawAMLSettingsString': None, 'AMLSettingsJsonString': '{\"path\": null, \"name\": \"placeholder\", \"subscription_id\": \"1b944a9b-fdae-4f97-aeb1-b7eea0beac53\", \"resource_group\": \"aml-quickstarts-142888\", \"workspace_name\": \"quick-starts-ws-142888\", \"region\": \"southcentralus\", \"compute_target\": \"hypr-auto-clustr\", \"spark_service\": null, \"azure_service\": null, \"many_models\": false, \"pipeline_fetch_max_batch_size\": 1, \"enable_batch_run\": false, \"enable_run_restructure\": false, \"iterations\": 1000, \"primary_metric\": \"norm_macro_recall\", \"task_type\": \"classification\", \"data_script\": null, \"test_size\": 0.0, \"validation_size\": 0.0, \"n_cross_validations\": null, \"y_min\": null, \"y_max\": null, \"num_classes\": null, \"featurization\": \"auto\", \"_ignore_package_version_incompatibilities\": false, \"is_timeseries\": false, \"max_cores_per_iteration\": 1, \"max_concurrent_iterations\": 5, \"iteration_timeout_minutes\": null, \"mem_in_mb\": null, \"enforce_time_on_windows\": false, \"experiment_timeout_minutes\": 120, \"experiment_exit_score\": null, \"whitelist_models\": null, \"blacklist_algos\": null, \"supported_models\": [\"KNN\", \"TensorFlowDNN\", \"SGD\", \"ExtremeRandomTrees\", \"GradientBoosting\", \"DecisionTree\", \"LogisticRegression\", \"LightGBM\", \"TensorFlowLinearClassifier\", \"SVM\", \"RandomForest\", \"LinearSVM\", \"XGBoostClassifier\", \"BernoulliNaiveBayes\", \"MultinomialNaiveBayes\", \"AveragedPerceptronClassifier\"], \"private_models\": [], \"auto_blacklist\": true, \"blacklist_samples_reached\": false, \"exclude_nan_labels\": true, \"verbosity\": 20, \"_debug_log\": \"automl_errors.log\", \"show_warnings\": false, \"model_explainability\": true, \"service_url\": null, \"sdk_url\": null, \"sdk_packages\": null, \"enable_onnx_compatible_models\": false, \"enable_split_onnx_featurizer_estimator_models\": false, \"vm_type\": \"STANDARD_D2_V2\", \"telemetry_verbosity\": 20, \"send_telemetry\": true, \"enable_dnn\": false, \"scenario\": \"SDK-1.13.0\", \"environment_label\": null, \"save_mlflow\": false, \"force_text_dnn\": false, \"enable_feature_sweeping\": true, \"enable_early_stopping\": true, \"early_stopping_n_iters\": 10, \"metrics\": null, \"enable_metric_confidence\": false, \"enable_ensembling\": true, \"enable_stack_ensembling\": true, \"ensemble_iterations\": 15, \"enable_tf\": false, \"enable_subsampling\": null, \"subsample_seed\": null, \"enable_nimbusml\": false, \"enable_streaming\": false, \"force_streaming\": false, \"track_child_runs\": true, \"allowed_private_models\": [], \"label_column_name\": \"status_group\", \"weight_column_name\": null, \"cv_split_column_names\": null, \"enable_local_managed\": false, \"_local_managed_run_id\": null, \"cost_mode\": 1, \"lag_length\": 0, \"metric_operation\": \"maximize\", \"preprocess\": true}', 'DataPrepJsonString': '{\\\\\"training_data\\\\\": {\\\\\"datasetId\\\\\": \\\\\"eded2ff1-146c-49d5-97d5-46f1796232dc\\\\\"}, \\\\\"datasets\\\\\": 0}', 'EnableSubsampling': 'False', 'runTemplate': 'AutoML', 'Orchestrator': 'automl', 'ClientType': 'Others', '_aml_system_scenario_identification': 'Remote.Parent', 'root_attribution': 'azureml.StepRun', 'snapshotId': '64737d52-f8c4-45e0-baae-4837d2041144', 'SetupRunId': 'c21115fe-165c-45e9-83eb-82e4a3a21bbd_setup', 'SetupRunContainerId': 'dcid.c21115fe-165c-45e9-83eb-82e4a3a21bbd_setup', 'ClientSdkVersion': '1.26.0', 'FeaturizationRunJsonPath': 'featurizer_container.json', 'FeaturizationRunId': 'c21115fe-165c-45e9-83eb-82e4a3a21bbd_featurize', 'ProblemInfoJsonString': '{\"dataset_num_categorical\": 0, \"is_sparse\": true, \"subsampling\": false, \"dataset_classes\": 3, \"dataset_features\": 322, \"dataset_samples\": 42768, \"single_frequency_class_detected\": false}', 'ModelExplainRunId': 'c21115fe-165c-45e9-83eb-82e4a3a21bbd_ModelExplain'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlstrg142888.blob.core.windows.net/azureml/ExperimentRun/dcid.c21115fe-165c-45e9-83eb-82e4a3a21bbd/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=r%2BjaJPqd7H7INM2%2FUg83WQRsNB6ITcc1VoA99hfC%2BxE%3D&st=2021-04-17T00%3A09%3A53Z&se=2021-04-17T08%3A19%3A53Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlstrg142888.blob.core.windows.net/azureml/ExperimentRun/dcid.c21115fe-165c-45e9-83eb-82e4a3a21bbd/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=4wos9p76S%2BDeBnHzOD%2BoT3S1W%2B%2B8su7jZzdLnV3HlDo%3D&st=2021-04-17T00%3A09%3A53Z&se=2021-04-17T08%3A19%3A53Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlstrg142888.blob.core.windows.net/azureml/ExperimentRun/dcid.c21115fe-165c-45e9-83eb-82e4a3a21bbd/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=3QkX%2FZtSr8NJIGwGmf92fSZdWBI2jqm2Hc5uN1qlYwg%3D&st=2021-04-17T00%3A09%3A53Z&se=2021-04-17T08%3A19%3A53Z&sp=r'}, 'submittedBy': 'ODL_User 142888'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': '540c3f3b-a22f-4e78-a250-e2b2c07ce409', 'status': 'Completed', 'startTimeUtc': '2021-04-17T00:19:45.320548Z', 'endTimeUtc': '2021-04-17T01:00:17.191456Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://mlstrg142888.blob.core.windows.net/azureml/ExperimentRun/dcid.540c3f3b-a22f-4e78-a250-e2b2c07ce409/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=3EolFBG9%2BveN2cM5R2O%2FK9HP7jgCqELMR%2BtBQAPBq%2BM%3D&st=2021-04-17T00%3A10%3A04Z&se=2021-04-17T08%3A20%3A04Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://mlstrg142888.blob.core.windows.net/azureml/ExperimentRun/dcid.540c3f3b-a22f-4e78-a250-e2b2c07ce409/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=Ab1S7iMSIujn6HWpvWtPyVCpGJ3zuljS%2FsilmrCGcws%3D&st=2021-04-17T00%3A10%3A04Z&se=2021-04-17T08%3A20%3A04Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://mlstrg142888.blob.core.windows.net/azureml/ExperimentRun/dcid.540c3f3b-a22f-4e78-a250-e2b2c07ce409/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=9mtrgjhFJMr6E69%2FxdY3KJYT%2FHFkzA2jTFQNTYc5qV4%3D&st=2021-04-17T00%3A10%3A04Z&se=2021-04-17T08%3A20%3A04Z&sp=r'}, 'submittedBy': 'ODL_User 142888'}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Finished'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6onN6m69zUy"
      },
      "source": [
        "# Examine Results\n",
        "\n",
        "# Retrive the metrics of all child runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnfQf6xGabw7",
        "gather": {
          "logged": 1618621219689
        },
        "outputId": "55175c35-16b8-4fcd-daa7-2d718e1a6823"
      },
      "source": [
        "metrics_output = pipeline_run.get_pipeline_output(metrics_output_name)\n",
        "num_file_downloaded = metrics_output.download('.', show_progress=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading azureml/c21115fe-165c-45e9-83eb-82e4a3a21bbd/metrics_data\n",
            "Downloaded azureml/c21115fe-165c-45e9-83eb-82e4a3a21bbd/metrics_data, 1 files out of an estimated total of 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3D5X1aEaeT8",
        "gather": {
          "logged": 1618621219849
        },
        "outputId": "a774e36a-6b86-4fcb-f00f-2534bc7d2ff2"
      },
      "source": [
        "import json\n",
        "with open(metrics_output._path_on_datastore) as f:\n",
        "    metrics_output_result = f.read()\n",
        "    \n",
        "deserialized_metrics_output = json.loads(metrics_output_result)\n",
        "df = pd.DataFrame(deserialized_metrics_output)\n",
        "pd.set_option('display.max_rows', 100)\n",
        "df_t = df.T\n",
        "df_t['recall_score_micro'].sort_values()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_12    [0.5147306397306397]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_10    [0.5429292929292929]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_30    [0.5429292929292929]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_25    [0.5429292929292929]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_35    [0.5431397306397306]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_11    [0.5494528619528619]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_9     [0.5643939393939394]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_31    [0.5679713804713805]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_18     [0.586489898989899]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_15    [0.5892255892255892]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_14    [0.5955387205387206]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_2     [0.6047979797979798]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_4     [0.6094276094276094]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_24    [0.6121632996632996]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_19    [0.6317340067340067]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_5     [0.6662457912457912]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_17    [0.6744528619528619]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_21    [0.6900252525252525]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_33    [0.6988636363636364]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_34    [0.7001262626262627]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_29    [0.7041245791245792]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_28    [0.7072811447811448]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_39    [0.7095959595959596]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_6     [0.7102272727272727]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_3     [0.7110690235690236]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_43    [0.7117003367003367]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_7     [0.7167508417508418]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_8     [0.7186447811447811]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_32    [0.7232744107744108]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_38    [0.7272727272727273]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_13    [0.7289562289562289]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_20    [0.7293771043771043]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_16    [0.7306397306397306]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_36     [0.742003367003367]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_37    [0.7563131313131313]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_1     [0.7563131313131313]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_22    [0.7569444444444444]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_44    [0.7699915824915825]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_26    [0.7815656565656566]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_0     [0.7868265993265994]\n",
              "c21115fe-165c-45e9-83eb-82e4a3a21bbd_27    [0.7998737373737373]\n",
              "Name: recall_score_micro, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDq1Oeq_D-h5"
      },
      "source": [
        "As we can see, the last row in this list is the best result is Run ID: c21115fe-165c-45e9-83eb-82e4a3a21bbd_27, with a `recall_score_micro` of 0.799874. It is an XGBoost model, we will see it's hyperparameters shortly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C37uiNk-IHp"
      },
      "source": [
        "# Best Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618621221171
        },
        "id": "jYckr8AAaHB7"
      },
      "source": [
        "from azureml.train.automl.run import AutoMLRun\n",
        "best_recall_run_id = df_t['recall_score_micro'].str.get(0).idxmax() # get string for best recall_score_micro run\n",
        "automl_run = AutoMLRun(automl_experiment, run_id=best_recall_run_id)\n",
        "automl_run.download_files()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo4EdSyOae-b",
        "gather": {
          "logged": 1618621221281
        },
        "outputId": "9c79fac2-93fa-4e8b-f933-154498c41235"
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('outputs/model.pkl', \"rb\" ) as f:\n",
        "    best_model = pickle.load(f)\n",
        "best_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PipelineWithYTransformations(Pipeline={'memory': None,\n",
              "                                       'steps': [('datatransformer',\n",
              "                                                  DataTransformer(enable_dnn=None,\n",
              "                                                                  enable_feature_sweeping=None,\n",
              "                                                                  feature_sweeping_config=None,\n",
              "                                                                  feature_sweeping_timeout=None,\n",
              "                                                                  featurization_config=None,\n",
              "                                                                  force_text_dnn=None,\n",
              "                                                                  is_cross_validation=None,\n",
              "                                                                  is_onnx_compatible=None,\n",
              "                                                                  logger=None,\n",
              "                                                                  observer=None,\n",
              "                                                                  task=None,\n",
              "                                                                  working_dir=None))...\n",
              "                                                                    max_leaves=63,\n",
              "                                                                    min_child_weight=1,\n",
              "                                                                    missing=nan,\n",
              "                                                                    n_estimators=100,\n",
              "                                                                    n_jobs=1,\n",
              "                                                                    nthread=None,\n",
              "                                                                    objective='multi:softprob',\n",
              "                                                                    random_state=0,\n",
              "                                                                    reg_alpha=0.20833333333333334,\n",
              "                                                                    reg_lambda=1.9791666666666667,\n",
              "                                                                    scale_pos_weight=1,\n",
              "                                                                    seed=None,\n",
              "                                                                    silent=None,\n",
              "                                                                    subsample=1,\n",
              "                                                                    tree_method='auto',\n",
              "                                                                    verbose=-10,\n",
              "                                                                    verbosity=0))],\n",
              "                                       'verbose': False},\n",
              "                             y_transformer={},\n",
              "                             y_transformer_name='LabelEncoder')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RMLJGX_afA2",
        "gather": {
          "logged": 1618621221374
        },
        "outputId": "05df2679-044e-419c-900c-fef989b0b9de"
      },
      "source": [
        "# As we can see, XGboost performed the best on recall_score_micro\n",
        "best_model.steps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('datatransformer',\n",
              "  DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
              "                  feature_sweeping_config=None, feature_sweeping_timeout=None,\n",
              "                  featurization_config=None, force_text_dnn=None,\n",
              "                  is_cross_validation=None, is_onnx_compatible=None, logger=None,\n",
              "                  observer=None, task=None, working_dir=None)),\n",
              " ('SparseNormalizer',\n",
              "  <azureml.automl.runtime.shared.model_wrappers.SparseNormalizer at 0x7efc29a222e8>),\n",
              " ('XGBoostClassifier',\n",
              "  XGBoostClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "                    colsample_bynode=1, colsample_bytree=0.6, eta=0.3, gamma=0,\n",
              "                    learning_rate=0.1, max_delta_step=0, max_depth=9,\n",
              "                    max_leaves=63, min_child_weight=1, missing=nan,\n",
              "                    n_estimators=100, n_jobs=1, nthread=None,\n",
              "                    objective='multi:softprob', random_state=0,\n",
              "                    reg_alpha=0.20833333333333334, reg_lambda=1.9791666666666667,\n",
              "                    scale_pos_weight=1, seed=None, silent=None, subsample=1,\n",
              "                    tree_method='auto', verbose=-10, verbosity=0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTF4kXivEtdp"
      },
      "source": [
        "Here's our XGBoost model's hyperparameters:\n",
        "\n",
        "    base_score=0.5, \n",
        "    booster='gbtree', \n",
        "    colsample_bylevel=1,                    \n",
        "    colsample_bynode=1, \n",
        "    colsample_bytree=0.6, \n",
        "    eta=0.3, \n",
        "    gamma=0,\n",
        "    learning_rate=0.1, \n",
        "    max_delta_step=0, \n",
        "    max_depth=9,\n",
        "    max_leaves=63, \n",
        "    min_child_weight=1, \n",
        "    missing=nan,\n",
        "    n_estimators=100, \n",
        "    n_jobs=1, \n",
        "    nthread=None,\n",
        "    objective='multi:softprob', \n",
        "    random_state=0,\n",
        "    reg_alpha=0.20833333333333334, \n",
        "    reg_lambda=1.9791666666666667,\n",
        "    scale_pos_weight=1, \n",
        "    seed=None, \n",
        "    silent=None, \n",
        "    subsample=1,\n",
        "    tree_method='auto', \n",
        "    verbose=-10, \n",
        "    verbosity=0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0hjMqcq-Z1Y"
      },
      "source": [
        "# Test the model on the Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618621221552
        },
        "id": "sIFeLIraaHB8"
      },
      "source": [
        "# important because registering data with TabularDatasetFactory might change column names (it did in this case)\n",
        "# If column names change and you only registered X_train, there will be a mismatch unless you do the same with X_test\n",
        "X_testing = testing_data.to_pandas_dataframe() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkh8yPVAafGG",
        "gather": {
          "logged": 1618621228448
        },
        "outputId": "2f82438d-fdaa-44b0-9aa4-3e4184ee8686"
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Predict on the Test Set\n",
        "ypred = best_model.predict(X_testing)\n",
        "\n",
        "# Calculate recall\n",
        "recall = recall_score(y_test, ypred, average='micro')\n",
        "print('Recall Micro: %.3f' % recall)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Recall Micro: 0.794\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "NX9ORy10DEgr"
      },
      "source": [
        "As you can see, the score on `recall_score_micro` is higher with the XGBoost model than it was with the Random Forest HyperDrive model (which was 0.765).\n",
        "\n",
        "Therefore, we will be deploying the best model we got with AutoML."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxROfMr3BC-M"
      },
      "source": [
        "# Model Deployment\n",
        "\n",
        "Registering the model, creating an inference config and deploy the model as a web service.\n",
        "\n",
        "In other words, we are publishing the pipeline to enable a REST endpoint to rerun the pipeline from any HTTP library on any platform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hjn8heOhsIn",
        "gather": {
          "logged": 1618622226767
        },
        "outputId": "78d6159e-d0b2-4ed1-c7fa-7818908ab6cb"
      },
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "# Register model (with the best recall_score_micro performance)\n",
        "model = Model.register(model_path='outputs/model.pkl', \n",
        "                          model_name='automl_XGBoost',\n",
        "                          tags={'Training context':'Auto ML'},\n",
        "                          properties={'Recall_Micro': recall},\n",
        "                          workspace=ws)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Registering model automl_XGBoost\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618622228451
        },
        "id": "uhRFH1P7DEgs"
      },
      "source": [
        "# moving the AutoML model to base folder.\n",
        "!mv outputs/model.pkl ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618622232681
        },
        "id": "heTdujhwDEgt",
        "outputId": "0d33eb3e-bd95-4bdf-adef-80d95cd7c019"
      },
      "source": [
        "# Testing if prediction works in notebook before sending request to endpoint\n",
        "import json\n",
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "x_new = pd.DataFrame(X_testing.loc[10]).T # grabbing a random example for testing the webservice\n",
        "# x_new.columns = x_new.columns.str.replace(r\"[^a-zA-Z\\d_]+\", \"\")\n",
        "x_new = x_new.T.rename(columns={10: \"data\"})\n",
        "x_new = x_new.to_dict()\n",
        "x_new = {\"data\": [x_new['data']]}\n",
        "x_new\n",
        "\n",
        "model_path = Model.get_model_path('model.pkl')\n",
        "model_test = joblib.load(model_path)\n",
        "\n",
        "data = json.dumps(x_new)\n",
        "\n",
        "data_test = pd.DataFrame(json.loads(data)['data'])\n",
        "predictions_test = model_test.predict(data_test)\n",
        "\n",
        "# It works!\n",
        "predictions_test.tolist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['non functional']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XMcHSsRlLrK",
        "outputId": "89e554ca-6cb5-42d2-a5d0-98f5a5aea5da"
      },
      "source": [
        "%%writefile score.py\n",
        "\n",
        "import json\n",
        "import joblib\n",
        "import pandas as pd\n",
        "from azureml.core.model import Model\n",
        "\n",
        "# Called when the service is loaded\n",
        "def init():\n",
        "    global model\n",
        "    # Get the path to the registered model file and load it\n",
        "    model_path = Model.get_model_path('automl_XGBoost')\n",
        "    model = joblib.load(model_path)\n",
        "\n",
        "# Called when a request is received\n",
        "def run(data):\n",
        "    # Get the input data as a numpy array\n",
        "    data = pd.DataFrame(json.loads(data)['data'])\n",
        "    # Get a prediction from the model\n",
        "    predictions = model.predict(data)\n",
        "    # Return the predictions as any JSON serializable format\n",
        "    return predictions.tolist()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting score.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKk9sOBvleuA",
        "gather": {
          "logged": 1618622245708
        },
        "outputId": "678580bd-a6e7-4133-eaab-b98bf40ebd65"
      },
      "source": [
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "\n",
        "# Add the dependencies for your model\n",
        "# We need to include all of these packages for deployment of the automl model\n",
        "# Otherwise the deployment will not work\n",
        "myenv = CondaDependencies()\n",
        "myenv.add_conda_package(\"scikit-learn==0.22.1\")\n",
        "myenv.add_conda_package(\"pandas==0.25.1\")\n",
        "myenv.add_conda_package(\"numpy>=1.16.0,<1.19.0\")\n",
        "myenv.add_conda_package(\"py-xgboost<=0.90\")\n",
        "myenv.add_conda_package(\"fbprophet==0.5\")\n",
        "myenv.add_conda_package(\"holidays==0.9.11\")\n",
        "myenv.add_conda_package(\"psutil>=5.2.2,<6.0.0\")\n",
        "myenv.add_pip_package(\"azureml-interpret==1.20.0\")\n",
        "myenv.add_pip_package(\"azureml-train-automl-runtime==1.20.0\")\n",
        "myenv.add_pip_package(\"inference-schema\")\n",
        "\n",
        "# Save the environment config as a .yml file\n",
        "env_file = './env.yml'\n",
        "with open(env_file,\"w\") as f:\n",
        "    f.write(myenv.serialize_to_string())\n",
        "print(\"Saved dependency info in\", env_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved dependency info in ./env.yml\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_mlymGRikMG",
        "gather": {
          "logged": 1618622251087
        }
      },
      "source": [
        "# Create inference_config\n",
        "from azureml.core.model import InferenceConfig\n",
        "\n",
        "classifier_inference_config = InferenceConfig(runtime=\"python\",\n",
        "                                              source_directory = '.',\n",
        "                                              entry_script=\"score.py\",\n",
        "                                              conda_file=\"env.yml\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4iRvCgNoZ7m",
        "gather": {
          "logged": 1618622252454
        }
      },
      "source": [
        "from azureml.core.webservice import AciWebservice\n",
        "\n",
        "classifier_deploy_config = AciWebservice.deploy_configuration(cpu_cores = 1,\n",
        "                                                              memory_gb = 1,\n",
        "                                                              enable_app_insights=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuTYOuTko8EJ",
        "gather": {
          "logged": 1618623334610
        },
        "outputId": "b0af89dd-eaed-4b27-afac-8ae4455b10c5"
      },
      "source": [
        "from azureml.core.model import Model\n",
        "\n",
        "model = ws.models['automl_XGBoost']\n",
        "service = Model.deploy(workspace=ws,\n",
        "                       name = 'pump-it-up-deployed-service',\n",
        "                       models = [model],\n",
        "                       inference_config = classifier_inference_config,\n",
        "                       deployment_config = classifier_deploy_config)\n",
        "\n",
        "service.wait_for_deployment(show_output = True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
            "Running\n",
            "2021-04-17 01:17:49+00:00 Creating Container Registry if not exists.\n",
            "2021-04-17 01:17:49+00:00 Registering the environment.\n",
            "2021-04-17 01:17:51+00:00 Building image..\n",
            "2021-04-17 01:31:08+00:00 Generating deployment configuration.\n",
            "2021-04-17 01:31:09+00:00 Submitting deployment to compute..\n",
            "2021-04-17 01:31:12+00:00 Checking the status of deployment pump-it-up-deployed-service..\n",
            "2021-04-17 01:35:25+00:00 Checking the status of inference endpoint pump-it-up-deployed-service.\n",
            "Succeeded\n",
            "ACI service creation operation finished, operation \"Succeeded\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx1q8WHbpzvv",
        "gather": {
          "logged": 1618623335062
        },
        "outputId": "37745683-af0d-4c90-fd90-e592c5329daf"
      },
      "source": [
        "print(service.get_logs())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-04-17T01:35:22,290905700+00:00 - iot-server/run \n",
            "2021-04-17T01:35:22,296964400+00:00 - rsyslog/run \n",
            "2021-04-17T01:35:22,317092300+00:00 - gunicorn/run \n",
            "2021-04-17T01:35:22,329963700+00:00 - nginx/run \n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "rsyslogd: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libuuid.so.1: no version information available (required by rsyslogd)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libcrypto.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "/usr/sbin/nginx: /azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/libssl.so.1.0.0: no version information available (required by /usr/sbin/nginx)\n",
            "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
            "2021-04-17T01:35:22,804949800+00:00 - iot-server/finish 1 0\n",
            "2021-04-17T01:35:22,815865000+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
            "Starting gunicorn 19.9.0\n",
            "Listening at: http://127.0.0.1:31311 (49)\n",
            "Using worker: sync\n",
            "worker timeout is set to 300\n",
            "Booting worker with pid: 99\n",
            "SPARK_HOME not set. Skipping PySpark Initialization.\n",
            "Generating new fontManager, this may take some time...\n",
            "Failure while loading azureml_run_type_providers. Failed to load entrypoint automl = azureml.train.automl.run:AutoMLRun._from_run_dto with exception (azureml-dataset-runtime 1.26.0 (/azureml-envs/azureml_7084af439e955eb6815347fde2c0f0f6/lib/python3.6/site-packages), Requirement.parse('azureml-dataset-runtime~=1.20.0')).\n",
            "Initializing logger\n",
            "2021-04-17 01:35:27,545 | root | INFO | Starting up app insights client\n",
            "2021-04-17 01:35:27,546 | root | INFO | Starting up request id generator\n",
            "2021-04-17 01:35:27,546 | root | INFO | Starting up app insight hooks\n",
            "2021-04-17 01:35:27,546 | root | INFO | Invoking user's init function\n",
            "2021-04-17 01:35:31,331 | root | INFO | Users's init has completed successfully\n",
            "2021-04-17 01:35:31,334 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
            "2021-04-17 01:35:31,334 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
            "2021-04-17 01:35:31,339 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
            "2021-04-17 01:35:32,822 | root | INFO | Swagger file not present\n",
            "2021-04-17 01:35:32,823 | root | INFO | 404\n",
            "127.0.0.1 - - [17/Apr/2021:01:35:32 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "2021-04-17 01:35:34,462 | root | INFO | Swagger file not present\n",
            "2021-04-17 01:35:34,462 | root | INFO | 404\n",
            "127.0.0.1 - - [17/Apr/2021:01:35:34 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DF7As6zVBew1"
      },
      "source": [
        "# Test the Deployed Model\n",
        "\n",
        "Here we will send a request to the deployed model to test it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heGk6iM4ar9f",
        "gather": {
          "logged": 1618623377845
        },
        "outputId": "e1480ce5-a1b5-4f8f-be49-bcbaed88437d"
      },
      "source": [
        "endpoint = service.scoring_uri\n",
        "\n",
        "print(f'\\nservice state: {service.state}\\n')\n",
        "print(f'scoring URI: \\n{endpoint}\\n')\n",
        "print(f'swagger URI: \\n{service.swagger_uri}\\n')\n",
        "\n",
        "print(endpoint)\n",
        "print(service.swagger_uri)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "service state: Healthy\n",
            "\n",
            "scoring URI: \n",
            "http://e9aa61db-03ac-43db-ba8d-ed72245625b9.southcentralus.azurecontainer.io/score\n",
            "\n",
            "swagger URI: \n",
            "http://e9aa61db-03ac-43db-ba8d-ed72245625b9.southcentralus.azurecontainer.io/swagger.json\n",
            "\n",
            "http://e9aa61db-03ac-43db-ba8d-ed72245625b9.southcentralus.azurecontainer.io/score\n",
            "http://e9aa61db-03ac-43db-ba8d-ed72245625b9.southcentralus.azurecontainer.io/swagger.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618624786710
        },
        "id": "NMRU1q9XDEgw",
        "outputId": "d1518b49-26a9-43f2-bfa0-91c293b95002"
      },
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "# Convert the array to a serializable list in a JSON document\n",
        "input_data = json.dumps(x_new)\n",
        "\n",
        "with open('data.json', 'w') as file:\n",
        "    file.write(input_data)\n",
        "\n",
        "# Set the content type in the request headers\n",
        "request_headers = { \"Content-Type\":\"application/json\"}\n",
        "\n",
        "# Call the service\n",
        "response = requests.post(url = endpoint,\n",
        "                         data = input_data,\n",
        "                         headers = request_headers)\n",
        "\n",
        "print(response)\n",
        "print(\"Prediction Results:\", response.json())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Response [200]>\n",
            "Prediction Results: ['non functional']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "id": "5srs0f_DDEgw"
      },
      "source": [
        "It works!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpGC1i6LasBZ",
        "gather": {
          "logged": 1618623392357
        },
        "outputId": "6d134318-12b5-415b-f97c-32162a60e3cc"
      },
      "source": [
        "response.status_code"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAIMxK1RB9iC"
      },
      "source": [
        "# Deleting the Service and the Compute Target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618625644237
        },
        "id": "WgA7Eu1EDEgx"
      },
      "source": [
        "# Delete computer target in order to avoid incurring additional charges.\n",
        "\n",
        "AmlCompute.delete(cpu_cluster)\n",
        "service.delete()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}